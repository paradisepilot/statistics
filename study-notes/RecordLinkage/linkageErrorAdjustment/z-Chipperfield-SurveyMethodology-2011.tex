
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Chipperfield \textit{et al.}, 2011, \cite{Chipperfield2011}}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{MLE's for contingency tables under perfect linkage}
Suppose
$\left(\Omega,\mathcal{A},\mu\right)$ is a probability space and
$n, p, G, C \in \N$ are natural numbers.
Suppose
\begin{itemize}
\item
	$X^{(1)}, \ldots, X^{(n)} : \Omega \longrightarrow \left[\,G\,\right] := \left\{1,2,\ldots,G\right\}$
	are categorical random variables,
\item
	$Y^{(1)}, \ldots, Y^{(n)} : \Omega \longrightarrow \left[\,C\,\right] := \left\{1,2,\ldots,C\right\}$
	are categorical random variables, and
\item
	the $\left(\,\left[\,G\,\right] \times \left[\,C\,\right]\,\right)$-valued random variables
	$Z^{(i)} := \left(\,X^{(i)},Y^{(i)}\,\right)$, $i = 1, 2, \ldots, n$, are independent and identically distributed.
\end{itemize}
%Then, the joint probability distribution of $X,Y$ can be expressed as follows:
%\begin{equation*}
%P\!\left(X = x,Y=y\right) \;\;=\;\; P_{Y \vert X}\!\left(\,Y = y \,\vert X = x\right) \cdot P_{X}\!\left(X = x\right).
%\end{equation*}
%We seek to estimate $P_{Y \vert X}\!\left(\,Y = y \,\vert X = x\right)$,
%for each $(x,y) \in \left[\,G\,\right] \times \left[\,C\,\right]$,
%based on the observed data
%$\left(X^{(1)},Y^{(1)}\right)$, $\left(X^{(2)},Y^{(2)}\right)$, $\ldots$\,, $(X^{(n)},Y^{(n)})$.
Then, the joint probability distribution of
$\left(X^{(1)},Y^{(1)}\right)$, $\left(X^{(2)},Y^{(2)}\right)$, $\ldots$\,, $(X^{(n)},Y^{(n)})$
can be expressed as follows:
\begin{eqnarray*}
&&
	P\!\left(X^{(1)} = x_{1},Y^{(1)}=y_{1}, \;\ldots\; ,X^{(n)} = x_{n},Y^{(n)}=y_{n}\right)
\\
&=&
	P\!\left(X^{(1)} = x_{1},Y^{(1)}=y_{1}\right) \times \cdots \times P\!\left(X^{(n)} = x_{n},Y^{(n)}=y_{n}\right)
\\
&=&
	P_{Y \vert X}\!\left(\left.Y^{(1)} = y_{1} \,\right\vert X^{(1)} = x_{1}\right) \cdot P_{X}\!\left(X^{(1)} = x_{1}\right)
	\times \cdots \times
	P_{Y \vert X}\!\left(\left.Y^{(n)} = y_{n} \,\right\vert X^{(n)} = x_{n}\right) \cdot P_{X}\!\left(X^{(n)} = x_{n}\right)
\\
&=&
	\overset{G}{\underset{g=1}{\prod}} \;\;\; \overset{C}{\underset{c=1}{\prod}} \;
	\left(\,\pi_{c\,\vert\,g} \overset{{\color{white}\vert}}{\cdot} p_{g}\,\right)
	^{\overset{n}{\underset{i=1}{\sum}}\,I\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}}
%\;\; = \;\;
%	\overset{G}{\underset{g=1}{\prod}}
%		\left(\,\overset{{\color{white}-}}{p}_{g}\,\right)^{\overset{n}{\underset{i=1}{\sum}}\,I\left\{X^{(i)}=g\right\}}
%	\,\cdot\,
%	\overset{C}{\underset{c=1}{\prod}}
%	\left(\,\overset{{\color{white}\vert}}{\pi}_{c\,\vert\,g}\,\right)
%	^{\overset{n}{\underset{i=1}{\sum}}\,I\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}},
\end{eqnarray*}
where
$\pi_{c\,\vert\,g} \,:=\, P_{Y \vert X}\!\left(\left.Y = c \,\right\vert X = g\right)$
and
$p_{g} \,:=\, P_{X}\!\left(X = g\right)$.
First, note that we have the identities:
\begin{equation*}
\overset{C}{\underset{c=1}{\sum}}\;\pi_{c\vert g} \; = \; 1
\;\;\quad\textnormal{and}\quad\quad
\overset{G}{\underset{g=1}{\sum}}\;p_{g} \; = \; 1.
\end{equation*}
We seek to estimate $\pi_{c\,\vert\,g}$\,,
%$P_{Y \vert X}\!\left(\,Y = c \,\vert X = g\right)$,
for each $(g,c) \in \left[\,G\,\right] \times \left[\,C\,\right]$,
based on the observed data.
Now, the logarithm of the above joint probability is:
\begin{eqnarray*}
&&
	\log\,P\!\left(X^{(1)} = x_{1},Y^{(1)}=y_{1}, \;\ldots\; ,X^{(n)} = x_{n},Y^{(n)}=y_{n}\right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
	\cdot
	\left(\,\log\,\pi_{c\,\vert\,g} \,\overset{{\color{white}\vert}}{+}\, \log\,p_{g}\,\right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
	\cdot
	\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
	\;\; + \;\;
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
	\cdot
	\left(\,\log\,p_{g}\,\right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
	\cdot
	\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
	\;\; + \;\;
	\overset{G}{\underset{g=1}{\sum}} \, \left(\,\log\,p_{g}\,\right)
	\cdot
	\left(\,
		\overset{n}{\underset{i=1}{\sum}} \;
		\overset{C}{\underset{c=1}{\sum}} \,
		I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}
	\right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
	\cdot
	\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
	\;\; + \;\;
	\overset{G}{\underset{g=1}{\sum}} \, \left(\,\log\,p_{g}\,\right)
	\cdot
	\left(\, \overset{n}{\underset{i=1}{\sum}} \; I\!\left\{X^{(i)}=g\right\} \right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;\,
	n_{gc} \cdot \left(\,\log\,\pi_{c\,\vert\,g}\,\right)
	\;\; + \;\;
	\overset{G}{\underset{g=1}{\sum}} \;\, n_{g} \cdot \left(\,\log\,p_{g}\,\right)
\\
&=&
	\overset{G}{\underset{g=1}{\sum}} \;
	\left\{\,
		n_{gC}
		\cdot
		\log\left(\,1 - \overset{C-1}{\underset{c=1}{\sum}}\pi_{c\,\vert\,g}\,\right)
		\; + \;
		\overset{C-1}{\underset{c=1}{\sum}} \; n_{gc}
		\cdot
		\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
	\,\right\}
	\; + \;
	\left\{\,
		n_{G}
		\cdot
		\log\left(\,1 - \overset{G-1}{\underset{g=1}{\sum}}\;p_{g}\,\right)
		\, + \,
		\overset{G-1}{\underset{g=1}{\sum}} \; n_{g}
		\cdot
		\left(\,\log\,p_{g}\,\right)
	\,\right\}
\end{eqnarray*}
%Similarly, the joint probability distribution of $X^{(1)}$, $X^{(2)}$, $\ldots$\,, $X^{(n)}$
%can be expressed as:
%\begin{eqnarray*}
%P\!\left(X^{(1)} = x_{1}, X^{(2)} = x_{2}, \;\ldots\; ,X^{(n)} = x_{n}\right)
%&=&
%	P\!\left(X^{(1)} = x_{1}\right) \times P\!\left(X^{(2)} = x_{2}\right) \times \cdots \times P\!\left(X^{(n)} = x_{n}\right)
%\\
%&=&
%	\overset{G}{\underset{g=1}{\prod}}
%	\left(\,\overset{{\color{white}\vert}}{p}_{g}\,\right)
%	^{\overset{n}{\underset{i=1}{\sum}}\,I\left\{X^{(i)}=g\right\}},
%\end{eqnarray*}
%with logarithm:
%\begin{eqnarray*}
%\log\, P\!\left(X^{(1)} = x_{1}, X^{(2)} = x_{2}, \;\ldots\; ,X^{(n)} = x_{n}\right)
%&=&
%	\overset{G}{\underset{g=1}{\sum}}
%	\left(\overset{n}{\underset{i=1}{\sum}}\,I\left\{X^{(i)}=g\right\}\right)
%	\cdot
%	\left(\,\log\,\overset{{\color{white}\vert}}{p}_{g}\,\right)
%\end{eqnarray*}
%We therefore obtain this expression for the following logarithm of conditional probability:
%\begin{eqnarray*}
%&&
%	\log\,P\!\left(\,\left.Y^{(1)}=y_{1},Y^{(2)}=y_{2},\,\ldots\,,Y^{(n)}=y_{n}\;\right\vert\,X^{(1)}=x_{1},X^{(2)}=x_{2},\ldots,X^{(n)}=x_{n}\right)
%\\
%&=&
%	\overset{G}{\underset{g=1}{\sum}} \;\; \overset{C}{\underset{c=1}{\sum}} \;
%	\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
%	\cdot
%	\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
%\\
%&=&
%	\overset{G}{\underset{g=1}{\sum}} \;
%	\left\{\,
%		\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=C\right\}\right)
%		\cdot
%		\log\left(\,1 - \overset{C-1}{\underset{c=1}{\sum}}\pi_{c\,\vert\,g}\,\right)
%		\; + \;
%		\overset{C-1}{\underset{c=1}{\sum}} \;
%		\left(\overset{n}{\underset{i=1}{\sum}}\,I\!\left\{X^{(i)}=g,\,Y^{(i)}=c\right\}\right)
%		\cdot
%		\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
%	\,\right\}
%\\
%&=&
%	\overset{G}{\underset{g=1}{\sum}} \;
%	\left\{\,
%		n_{gC}
%		\cdot
%		\log\left(\,1 - \overset{C-1}{\underset{c=1}{\sum}}\pi_{c\,\vert\,g}\,\right)
%		\; + \;
%		\overset{C-1}{\underset{c=1}{\sum}} \; n_{gc}
%		\cdot
%		\left(\,\log\,\pi_{c\,\vert\,g}\,\right)
%	\,\right\}
%\end{eqnarray*}
For each $g \in \{1,2,\ldots,G\}$ and $c \in \{1,2,\ldots,C-1\}$, differentiating with respect to \,$\pi_{c \vert g}$\, yields:
\begin{eqnarray*}
\dfrac{\partial}{\partial\,\pi_{c \vert g}}\,
\log\,P\!\left(X^{(1)} = x_{1},Y^{(1)}=y_{1}, \;\ldots\; ,X^{(n)} = x_{n},Y^{(n)}=y_{n}\right)
&=&
	\dfrac{n_{gC}\cdot(\,-1\,)}{1 - \overset{C-1}{\underset{y=1}{\sum}}\pi_{y\,\vert\,g}}
	\; + \;
	\dfrac{n_{gc}}{\pi_{c\,\vert\,g}}
\\
&=&
	\dfrac{n_{gc}}{\pi_{c\,\vert\,g}}
	\; - \;
	\dfrac{n_{gC}}{\pi_{C\,\vert\,g}}
\end{eqnarray*}
For each $g \in \{1,2,\ldots,G-1\}$, differentiating with respect to \,$p_{g}$\, yields:
\begin{eqnarray*}
\dfrac{\partial}{\partial\,p_{g}}\,
\log\,P\!\left(X^{(1)} = x_{1},Y^{(1)}=y_{1}, \;\ldots\; ,X^{(n)} = x_{n},Y^{(n)}=y_{n}\right)
&=&
	\dfrac{n_{G}\cdot(\,-1\,)}{1 - \overset{G-1}{\underset{x=1}{\sum}}\,p_{x}}
	\; + \;
	\dfrac{n_{g}}{p_{g}}
\\
&=&
	\dfrac{n_{g}}{p_{g}}
	\; - \;
	\dfrac{n_{G}}{p_{G}}
\end{eqnarray*}
Setting the L.H.S.'s of the above two equations to zero yields:
There exists $\beta \in \Re$ and, 
for each $g \in \{1,2,\ldots,G\}$, there exists $\alpha_{g} \in \Re$ such that
\begin{equation*}
	\begin{array}{ccl}
	\left(\,\pi_{1\vert g},\,\pi_{2\vert g}, \,\ldots\,, \,\pi_{C\vert g}\,\right)
	& = & \alpha_{g} \cdot \left(\,n_{g1},\,n_{g2}, \,\ldots\,,\, n_{gC}\,\right)
	\\
	\left(\,p_{1},\,p_{2}, \,\ldots\,, \,p_{G}\,\right)
	& \overset{{\color{white}\vert}}{=} & \beta \cdot \left(\,n_{1},\,n_{2}, \,\ldots\,,\, n_{G}\,\right)
	\end{array}
\end{equation*}
Recall now that we also have
\,$\overset{G}{\underset{g=1}{\sum}}\,p_{g} = 1$\, and
\,$\overset{C}{\underset{c=1}{\sum}}\,\pi_{c\vert g} = 1$.
Hence,
\begin{equation*}
\alpha_{g} \cdot \overset{C}{\underset{c=1}{\sum}}\;n_{gc}
\;\; = \;\; \overset{C}{\underset{c=1}{\sum}}\;\pi_{c\vert g}
\;\; = \;\; 1
\quad\Longrightarrow\quad
\alpha_{g} \;\;=\;\; \dfrac{1}{\overset{C}{\underset{c=1}{\sum}}\;n_{gc}}.
\end{equation*}
And,
\begin{equation*}
\beta \cdot \overset{G}{\underset{g=1}{\sum}}\;n_{g}
\;\; = \;\; \overset{G}{\underset{g=1}{\sum}}\;p_{g}
\;\; = \;\; 1
\quad\Longrightarrow\quad
\beta \;\;=\;\; \dfrac{1}{\overset{G}{\underset{g=1}{\sum}}\;n_{g}}.
\end{equation*}
We may now conclude that the maximum likelihood estimators of the parameters
\,$\left(\,\pi_{1\vert g},\,\pi_{2\vert g}, \,\ldots\,, \,\pi_{C\vert g}\,\right)$\,
and\\
$\left(\,p_{1},\,p_{2}, \,\ldots\,, \,p_{G}\,\right)$\,
are given by:
\begin{equation*}
	\begin{array}{ccccc}
	\left(\,\widehat{\pi}_{1\vert g}\,,\,\widehat{\pi}_{2\vert g}\,, \,\ldots\,, \,\widehat{\pi}_{C\vert g}\,\right)
	& = & \dfrac{1}{\sum^{C}_{c=1}n_{gc}} \cdot \left(\,n_{g1},\,n_{g2}, \,\ldots\,,\, n_{gC}\,\right)
	& = & \dfrac{1}{n_{g}} \cdot \left(\,n_{g1},\,n_{g2}, \,\ldots\,,\, n_{gC}\,\right),
	\\ \\
	\left(\,\widehat{p}_{1}\,,\,\widehat{p}_{2}\,, \,\ldots\,, \,\widehat{p}_{G}\,\right)
	& = & \dfrac{1}{\sum^{G}_{g=1}n_{g}} \cdot \left(\,n_{1},\,n_{2}, \,\ldots\,,\, n_{G}\,\right)
	& = & \dfrac{1}{n} \cdot \left(\,n_{1},\,n_{2}, \,\ldots\,,\, n_{G}\,\right).
	\end{array}
\end{equation*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{MLE's for contingency tables under imperfect linkage}

Suppose
$\left(\Omega,\mathcal{A},\mu\right)$ is a probability space and
$n, p, G, C \in \N$ are natural numbers.

\vskip 0.3cm
\noindent
Suppose:
\begin{itemize}
\item
	$X^{(1)}, \,\ldots\,,\, X^{(n)} : \Omega \longrightarrow \left[\,G\,\right] := \left\{1,2,\ldots,G\right\}$
	are categorical random variables,
\item
	$Y^{(1)}, \,\ldots\,,\, Y^{(n)} : \Omega \longrightarrow \left[\,C\,\right] := \left\{1,2,\ldots,C\right\}$
	are categorical random variables,
\item
	$\widetilde{Y}^{(1)}, \,\ldots\,,\, \widetilde{Y}^{(n)} : \Omega \longrightarrow \left[\,C\,\right] := \left\{1,2,\ldots,C\right\}$
	are categorical random variables, and
\item
	$M^{(1)}, \,\ldots\,,\, M^{(n)} : \Omega \longrightarrow \left\{0,1\right\}$
	are Bernoulli random variables.
\item
	$J^{(1)}, \,\ldots\,,\, J^{(n)} : \Omega \longrightarrow \left\{0,1\right\}$
	are Bernoulli random variables.
%\item
%	$W^{(1)}_{c \vert g}, \ldots, W^{(n)}_{c \vert g} : \Omega \longrightarrow \left\{\,0,1\,\right\}$
%	are Bernoulli random variables,
%\item
%	$\widetilde{W}^{(1)}_{c \vert g}, \ldots, \widetilde{W}^{(n)}_{c \vert g} : \Omega \longrightarrow \left\{\,0,1\,\right\}$
%	are Bernoulli random variables,
\end{itemize}

\vskip 0.3cm
\noindent
Suppose the following are true:
\begin{itemize}
\item
	The $\left(\,\left[\,G\,\right] \times \left[\,C\,\right] \times \left[\,C\,\right] \times \left[\,1\,\right]\,\right)$-valued
	random variables
	$Z^{(i)} := \left(\,X^{(i)},Y^{(i)},\widetilde{Y}^{(i)},M^{(i)}\,\right)$,
	$i = 1, 2, \ldots, n$, are independent and identically distributed.
\item
	The collections of random variables
	\,$\left\{\,Z^{(i)} := \left(\,X^{(i)},Y^{(i)},\widetilde{Y}^{(i)},M^{(i)}\right)\,\right\}_{i=1}^{n}$\,
	and
	\,$\left\{\,J^{(i)}\,\right\}_{i=1}^{n}$\,
	are independent, in the sense that, for all
	\,$z_{1}, \ldots, z_{n} \in \left[\,G\,\right] \times \left[\,C\,\right] \times \left[\,C\,\right] \times \left[\,1\,\right]$\,
	and
	\,$j_{1}, \ldots, j_{n} \in \{0,1\}$,\,
	\begin{eqnarray*}
	&&
		P\!\left(\,Z^{(1)}=z_{1},\,\ldots\,,Z^{(n)}=z_{n},\;J^{(1)}=j_{1},\,\ldots\,,J^{(n)}=j_{n}\,\right)
	\\
	& = &
		P\!\left(\,Z^{(1)}=z_{1},\,\ldots\,,Z^{(n)}=z_{n}\,\right)
		\cdot
		P\!\left(\,J^{(1)}=j_{1},\,\ldots\,,J^{(n)}=j_{n}\,\right)
	\end{eqnarray*}
\item
	For each $i \in \{1,2,\ldots,n\}$, the random variables $Y^{(i)}$ and $M^{(i)}$
	are conditionally independent given $X^{(i)}$, i.e.
	\begin{equation*}
	P\!\left(\,X^{(i)},Y^{(i)},M^{(i)}\right)
	\;\; = \;\;
	P\!\left(\,Y^{(i)}\;\vert\;X^{(i)}\right) \cdot
	P\!\left(\,M^{(i)}\;\vert\;X^{(i)}\right) \cdot
	P\!\left(\,X^{(i)}\right)
	\end{equation*}
\item
	For each $i\in\{1,2,\ldots,n\}$, we have:
	\begin{equation*}
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,M^{(i)}=0,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
	\;\; = \;\;
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,X^{(i)}=g\,\right)
	\end{equation*}
\item
	For each $i\in\{1,2,\ldots,n\}$, we have:
	\begin{equation*}
	M^{(i)} \; = \; 1
	\quad\Longrightarrow\quad
	Y^{(i)} \; = \; \widetilde{Y}^{(i)},
	\end{equation*}
	which, in particular, implies $P\!\left(\,\left.Y^{(i)} = \widetilde{Y}^{(i)}\;\right\vert\;M^{(i)}=1\,\right)\,=\,1$.
\end{itemize}
Define
\begin{equation*}
\begin{array}{ccccl}
	W^{(i)}_{c \vert g} &:& \Omega \longrightarrow \{0,1\} &:& \omega\;\longmapsto\,
	\left\{
		\begin{array}{cl}
		1, & \textnormal{if}\;\; X^{(i)}(\omega) = g \,\;\textnormal{and}\;\, Y^{(i)}(\omega) = c,
		\\
		\overset{{\color{white}-}}{0}, & \textnormal{otherwise}
		\end{array}
	\right.
\\ \\
	\widetilde{W}^{(i)}_{c \vert g} &:& \Omega \longrightarrow \{0,1\} &:& \omega\;\longmapsto\,
	\left\{
		\begin{array}{cl}
		1, & \textnormal{if}\;\; X^{(i)}(\omega) = g \,\;\textnormal{and}\;\, \widetilde{Y}^{(i)}(\omega) = c,
		\\
		\overset{{\color{white}-}}{0}, & \textnormal{otherwise}
		\end{array}
	\right.
%\\ \\
%	M^{(i)} &:& \Omega \longrightarrow \{0,1\} &:& \omega\;\longmapsto\,
%	\left\{
%		\begin{array}{cl}
%		1, & \textnormal{if}\;\; Y^{(i)}(\omega) \,=\, \widetilde{Y}^{(i)}(\omega),
%		\\
%		\overset{{\color{white}-}}{0}, & \textnormal{otherwise}
%		\end{array}
%	\right.
\end{array}
\end{equation*}

$\rho_{gc} \;:=\; P\!\left(M=1\;\vert\;X=g,\widetilde{Y}=c\right)$

\begin{equation*}
\begin{array}{lcl}
E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=0\;\right]
&=& 
\\ \\
E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=1,M^{(i)}=1\;\right]
&=& \widetilde{W}^{(i)}_{c \vert g}
\\ \\
E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=1,M^{(i)}=0\;\right]
&=& \pi_{c \vert g}
\end{array}
\end{equation*}

\begin{eqnarray*}
&&
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=0\;\right]
\;\;=\;\;
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y\;\right]
\\
&=&
	1 \cdot P\!\left(\left.W^{(i)}_{c \vert g} = 1\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
	\;\;+\;\;
	0 \cdot P\!\left(\left.W^{(i)}_{c \vert g} = 0\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&=&
	P\!\left(\left.W^{(i)}_{c \vert g} = 1\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\;\; = \;\;
	P\!\left(\left.X^{(i)} = g\,,Y^{(i)} = c\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
& = &
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,,M^{(i)}=0\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
	\; + \; P\!\left(\left.Y^{(i)} = c\,,M^{(i)}=1\,\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,M^{(i)}=0,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
	\,\cdot\,
	P\!\left(\left.M^{(i)}=0\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&&
	+ \;\;
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,M^{(i)}=1,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
	\,\cdot\,
	P\!\left(\left.M^{(i)}=1\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\,X^{(i)}=g\,\right)
	\,\cdot\,
	P\!\left(\left.M^{(i)}=0\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\\
&&
	+ \;\;
	\delta_{cy}
	\,\cdot\,
	P\!\left(\left.M^{(i)}=1\;\right\vert\,X^{(i)}=g,\widetilde{Y}^{(i)}=y\,\right)
\end{eqnarray*}

\begin{eqnarray*}
&&
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=1,M^{(i)}=1\;\right]
\;\;=\;\;
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=1\;\right]
\\
&=&
	P\!\left(\left.W^{(i)}_{c \vert g}=1\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=1\,\right)
\;\;=\;\;
	P\!\left(\left.X^{(i)} = g\,,Y^{(i)} = c\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=1\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=1\,\right)
	\;\; = \;\; \delta_{cy}
\end{eqnarray*}

\begin{eqnarray*}
&&
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,J^{(i)}=1,M^{(i)}=0\;\right]
\;\;=\;\;
	E\!\left[\;\left.W^{(i)}_{c \vert g}\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=0\;\right]
\\
&=&
	P\!\left(\left.W^{(i)}_{c \vert g}=1\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=0\,\right)
\;\;=\;\;
	P\!\left(\left.X^{(i)} = g\,,Y^{(i)} = c\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=0\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\;X^{(i)}=g,\widetilde{Y}^{(i)}=y,M^{(i)}=0\,\right)
\\
&=&
	P\!\left(\left.Y^{(i)} = c\,\;\right\vert\;X^{(i)}=g\,\right)
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
