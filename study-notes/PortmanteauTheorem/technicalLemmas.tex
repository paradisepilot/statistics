
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Technical Lemmas}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

\begin{lemma}\label{LemmaRho}
\quad
Suppose $\left(S,\rho\right)$ is a metric space, and $A \subset S$ is an arbitrary non-empty subset.
Define
\begin{equation*}
\rho(\,\cdot\,,A) \;:\; S \;\longrightarrow\; \Re \;:\; x \;\longmapsto\; \inf_{y\in A}\left\{\,\rho(x,y)\,\right\}
\end{equation*}
Then,
\begin{enumerate}
\item	$\rho(\,\cdot\,,A)$ is a continuous $\Re$-valued function on $S$.
\item	For each $x \in S$, $\rho(x,A) = 0$ if and only if $x \in \overline{A}$.
\end{enumerate}
\end{lemma}
\proof
\begin{enumerate}
\item
	Suppose $x_{n} \longrightarrow x$. We need to prove $\rho(x_{n},A) \longrightarrow \rho(x,A)$,
	which follows immediately from the following two Claims:
	\vskip 0.8cm
	\begin{center}
	\begin{minipage}{6.5in}
	\noindent
	\textbf{Claim 1:}\quad$\rho(x,A) \;\leq\; \underset{n\rightarrow\infty}{\liminf}\;\rho(x_{n},A)$.
	\vskip 0.2cm
	\textbf{Claim 2:}\quad$\underset{n\rightarrow\infty}{\limsup}\;\rho(x_{n},A) \;\leq\; \rho(x,A)$.
	\end{minipage}
	\end{center}
	\vskip 0.3cm
	\noindent
	\underline{Proof of Claim 1:}\quad
	For each $y \in S$, we have:
	\begin{equation*}
	\rho(x,y) \;\leq\; \rho(x,x_{n}) \;+\; \rho(x_{n},y).
	\end{equation*}
	Hence,
	\begin{equation*}
	\rho(x,A) \;=\; \inf_{y \in A}\,\rho(x,y) \;\leq\; \rho(x,x_{n}) \;+\; \inf_{y \in A}\,\rho(x_{n},y) \;=\; \rho(x,x_{n}) \;+\; \rho(x_{n},A).
	\end{equation*}
	Since $\rho(x,x_{n}) \longrightarrow 0$, the preceding inequality implies
	\begin{equation*}
	\rho(x,A) \;\leq\; \liminf_{n\rightarrow\infty}\,\rho(x_{n},A).
	\end{equation*}
	This proves Claim 1.
	\vskip 0.5cm
	\noindent
	\underline{Proof of Claim 2:}\quad
	For each $y \in S$, we have:
	\begin{equation*}
	\rho(x_{n},y) \;\leq\; \rho(x_{n},x) \;+\; \rho(x,y).
	\end{equation*}
	Hence,
	\begin{equation*}
	\rho(x_{n},A) \;=\; \inf_{y \in A}\,\rho(x_{n},y) \;\leq\; \rho(x_{n},x) \;+\; \inf_{y \in A}\,\rho(x,y) \;=\; \rho(x_{n},x) \;+\; \rho(x,A).
	\end{equation*}
	Since $\rho(x,x_{n}) \longrightarrow 0$, the preceding inequality implies
	\begin{equation*}
	\limsup_{n\rightarrow\infty}\,\rho(x_{n},A) \;\leq\; \rho(x,A).
	\end{equation*}
	This proves Claim 2.

\item
	\begin{eqnarray*}
	\rho(x,A) = 0
	&\Longleftrightarrow& \inf_{y\in A}\,\rho(x,y) = 0
	\\
	&\Longleftrightarrow& \textnormal{For each $\varepsilon > 0$, there exists $y \in A$ such that $\rho(x,y) < \varepsilon$}
	\\
	&\Longleftrightarrow& y \in \overline{A}
	\end{eqnarray*}
\qed
\end{enumerate}

\begin{lemma}
\label{LemmaAEpsilon}
\quad
Suppose $\left(S,\rho\right)$ is a metric space, and $A \subset S$ is an arbitrary non-empty subset.
For each $\varepsilon > 0$, define
\begin{equation*}
A^{\varepsilon} \;:=\;
\left\{\;
s \in S
\;\left\vert\;\;
\rho(s,A) < \varepsilon
\right.
\;\right\}.
\end{equation*}
Then the following are true:
\begin{enumerate}
\item
	$A^{\varepsilon}$ is an open subset of $S$. In particular, $A^{\varepsilon}$ is a $\mathcal{B}(S)$-measurable subset of $S$.
\item
	$A^{\varepsilon}\,\downarrow\,\overline{A}$, as $\varepsilon \downarrow 0$.
\item
	There exists a bounded continuous $\Re$-valued function $f : S \longrightarrow \Re$
	such that
	\begin{equation*}
	I_{\bar{A}}(x) \;\leq\; f(x) \;\leq\; I_{A^{\varepsilon}}(x)\,,
	\quad\textnormal{for each $x \in S$}.
	\end{equation*}
\end{enumerate}	
\end{lemma}
\proof
\begin{enumerate}
\item
	Let $x \in A^{\varepsilon}$. Let $\delta := \varepsilon - \rho(x,A) > 0$.
	Let $U := \left\{\,y \in S \;\vert\; \rho(x,y) < \delta/2 \,\right\}$.
	Then, for each $y \in U$ and $a \in A$, we have
	\begin{equation*}
	\rho(y,a) \;\leq\; \rho(y,x) + \rho(x,a)
	\;\;\Longrightarrow\;\;
	\rho(y,A) \;\leq\; \rho(y,x) + \rho(x,A) \;\leq\; \dfrac{\delta}{2} + \varepsilon - \delta \;=\; \varepsilon - \dfrac{\delta}{2},
	\end{equation*}
	which implies $\rho(y,A) \;\leq\; \varepsilon - \dfrac{\delta}{2} \; < \; \varepsilon$.
	Hence $U \subset A^{\varepsilon}$.
	Since $U$ is an open subset of $S$, we may now conclude that $A^{\varepsilon}$ is indeed an open subset of $S$.
\item
\item
	Define $f : S \longrightarrow \Re$ as follows:
	\begin{equation*}
	f(x) \; := \;
	\max\left\{\;
	0\,,\,
	1 - \dfrac{\rho(x,A)}{\varepsilon}
	\;\right\}.
	\end{equation*}
	Then, by Lemma \ref{LemmaRho}, $f$ is continuous $\Re$-valued function on $S$.
	Clear, $0 \leq f(x) \leq 1$, for each $x \in S$.
	By Lemma \ref{LemmaRho}, we have
	\begin{equation*}
	x \;\in\; \overline{A}
	\quad\Longleftrightarrow\quad
	\rho(x,F) \;=\; 0
	\quad\Longleftrightarrow\quad
	f(x) \; = \; 1.
	\end{equation*}
	This proves $I_{\bar{A}}(x) \leq 1 = f(x)$, for each $x \in \overline{A}$, and hence for each $x \in S$
	(since $I_{\bar{A}}(x) = 0$ for $x \in S\,\backslash\,\overline{A}$, and the inequality holds trivially).
	On the other hand,
	\begin{equation*}
	x \;\in\; S\,\backslash\,A^{\varepsilon}
	\quad\Longleftrightarrow\quad
	\varepsilon \;\leq\; \rho(x,A)
	\quad\Longleftrightarrow\quad
	1 - \dfrac{\rho(x,A)}{\varepsilon} \;\leq\; 0
	\quad\Longrightarrow\quad
	f(x) \;=\; 0.
	\end{equation*}
	This proves $f(x) = 0 \leq I_{A^{\varepsilon}}(x)$, for each $x \in S\,\backslash\,A^{\varepsilon}$,
	and hence for each $x \in S$ (since $I_{A^{\varepsilon}}(x) = 1$ for each $x \in A^{\varepsilon}$
	and the inequality holds trivially).
	This completes the proof of (ii).
\end{enumerate}
\qed

\begin{lemma}
\label{LemmaMomentsAndTails}
\mbox{}
\vskip 0.1cm
\noindent
Let $\left(\,\Omega,\mathcal{A},P\,\right)$ be any probability space.
Then, for each $p > 0$ and
for each non-negative random variable (i.e. measurable function) $f : \Omega \longrightarrow [0,\infty)$,
we have:
\begin{equation*}
E\!\left[\,f^{p}\,\right]
\;\; = \;\; p\,\int_{0}^{\infty}\,P\!\left(\,f > t\,\right)\cdot t^{p-1}\,\d t
\;\; = \;\; p\,\int_{0}^{\infty}\,P\!\left(\,f \geq t\,\right)\cdot t^{p-1}\,\d t\,.
\end{equation*}
\end{lemma}

\proof
\vskip 0.1cm
\noindent
We first prove the first equality:
By elementary Calculus (change of variable formula) and Fubini's Theorem, we have
\begin{eqnarray*}
E\!\left[\,f^{p}\,\right]
&:=& \int_{\Omega}\,f(\omega)^{p}\,\d P(\omega)
\;\;=\;\; \int_{\Omega}\,\left[\;\int_{0}^{f(\omega)^{p}}\,1\,\d s\;\right]\,\d P(\omega)
\;\;=\;\; \int_{\Omega}\,\left[\;\int_{0}^{\infty}\,1_{\left\{\,0\,<\,s\,<\,f(\omega)^{p}\right\}}(s)\,\d s\;\right]\,\d P(\omega)
\\
&=& \int_{\Omega}\,\left[\;\int_{0}^{\infty}\,1_{\left\{\,0 \,\leq\, s^{1/p} \,<\, f(\omega)\,\right\}}\,\d s\;\right]\,\d P(\omega)
\;\;=\;\; \int_{\Omega}\,\left[\;\int_{0}^{\infty}\,1_{\left\{\,0 \,\leq\, t \,<\, f(\omega)\,\right\}}\cdot p \cdot t^{p-1} \,\d t\;\right]\,\d P(\omega)
\\
&=& \int_{0}^{\infty}\,\left[\;\int_{\Omega}\,1_{\left\{\,0 \,\leq\, t \,<\, f(\omega)\,\right\}}\cdot p \cdot t^{p-1} \,\d P(\omega)\;\right]\,\d t
\;\;=\;\; p \cdot \int_{0}^{\infty}\,\left[\;\int_{\Omega}\,1_{\left\{\,0 \,\leq\, t \,<\, f(\omega)\,\right\}}\,\d P(\omega)\;\right] \cdot t^{p-1} \,\d t
\\
&=& p \cdot \int_{0}^{\infty}\, P\!\left(\,f > t\,\right)\cdot t^{p-1} \,\d t.
\end{eqnarray*}
The proof of the second inequality is analogous.
\qed

\begin{lemma}
\label{LemmaUncountablePartition}
\mbox{}
\vskip 0.1cm
\noindent
Suppose
\begin{itemize}
\item	$\left(S,\rho\right)$ is a metric space, and $\mathcal{B}(S)$ is its Borel $\sigma$-algebra.
\item	$S = \underset{\gamma\in\Gamma}{\bigsqcup}\,F_{\gamma}$ is a partition of $S$ into
		pairwise disjoint $\mathcal{B}(S)$-measurable subsets $F_{\gamma} \in \mathcal{B}(S)$.\\
		Note that here the index set $\Gamma$ may be uncountable.
\end{itemize}
Then, for any probability measure $\mu \in \mathcal{M}_{1}\!\left(S,\mathcal{B}(S)\right)$, we have:
\begin{equation*}
\mu\!\left(F_{\gamma}\right) \; = \; 0,
\;\;\textnormal{for all but countably many $\gamma \in \Gamma$}.
\end{equation*}
\end{lemma}
\proof
Define
$\Gamma_{0} := \left\{\,\gamma\in\Gamma\;\,\left\vert\;\,\mu(F_{\gamma}) = 0\right.\,\right\}$,
and for each $n \in \N$, define
$\Gamma_{n} := \left\{\,\gamma\in\Gamma\;\,\left\vert\;\,\mu(F_{\gamma}) \geq \dfrac{1}{n}\right.\,\right\}$.
Clearly,
\begin{equation*}
\Gamma \;\; = \;\; \Gamma_{0}\;\bigsqcup\left(\;\bigcup_{n=1}^{\infty}\,\Gamma_{n}\;\right).
\end{equation*}
Thus, the Lemma follows immediately from the following

	\begin{center}
	\begin{minipage}{6.5in}
	\vskip 0.1cm
	\noindent
	\textbf{Claim:}\;\;For each $n \geq 1$, $\Gamma_{n}$ is a finite set with $\left\vert\,\Gamma_{n}\,\right\vert \leq n$.
	\vskip 0.2cm
	\noindent
	Proof of Claim:\quad
	If the Claim were false, there would exist $n \in \N$ such that $\Gamma_{n}$ contained at least $n+1$ distinct elements,
	say $\gamma_{1}, \gamma_{2}, \ldots, \gamma_{n+1} \in \Gamma_{n}$.
	It would follow that:
	\begin{equation*}
	\mu\!\left(\;\bigsqcup_{i=1}^{n+1} F_{\gamma_{i}}\,\right)
	\;\;=\;\; \sum_{i=1}^{n+1}\,\mu\!\left(F_{\gamma_{i}}\right)
	\;\;\geq\;\; \sum_{i=1}^{n+1}\,\dfrac{1}{n}
	\;\;=\;\;\dfrac{n+1}{n}
	\;\;>\;\; 1,
	\end{equation*}
	which would contradict that hypothesis that $\mu$ is a probability measure.
	Thus, the Claim must be true. \qed
	\end{minipage}
	\end{center}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
