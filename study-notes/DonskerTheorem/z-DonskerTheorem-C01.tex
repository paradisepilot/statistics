 
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Donsker's Theorem for $\left(\,C[0,1]\,,\,\Vert\cdot\Vert_{\infty}\,\right)$}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

\begin{proposition}
\mbox{}\vskip 0cm
\begin{itemize}
\item	Let $\xi_{1}, \xi_{2}, \ldots\, : \Omega \longrightarrow \Re$ be a sequence of
		independent and identically distributed $\Re$-valued random variables
		defined on the probability space $(\Omega,\mathcal{A},\mu)$,
		with expectation value zero and common finite variance $\sigma^{2} > 0$.
\item	Define the random variables:
		\begin{equation*}
		\left\{\begin{array}{ccccll}
		S_{0}
		&:&\overset{{\color{white}1}}{\Omega} \longrightarrow \Re
		&:& \omega \;\longmapsto\; 0,
		& \textnormal{and}
		\\ \\
		S_{n}
		&:&	\Omega \longrightarrow \Re
		&:&	\omega \;\longmapsto\; \overset{n}{\underset{i=1}{\textnormal{\Large$\sum$}}}\;\xi_{i}(\omega),
		& \textnormal{for each $n \in \N$}.
		\end{array}\right.
		\end{equation*}
\item	For each $n \in \N$, define \,$X^{(n)} \,:\, \Omega \;\longrightarrow\;C[0,1]$\, as follows:
		\begin{equation*}
		X^{(n)}(\omega)(t)
		\;\; := \;\;
		\dfrac{1}{\sigma\cdot\sqrt{n}}
		\left\{\;
		S_{i-1}(\omega) \;+\; n\left(t - \dfrac{i-1}{n}\right)\xi_{i}(\omega)
		\,\right\},
		\;\;
		\textnormal{for each $\omega \in \Omega$, \;$t \in \left[\frac{i-1}{n},\frac{i}{n}\right]$, \;$i = 1,2,3,\ldots,n$}.
		\end{equation*}
\item	For each $n \in \N$ and each $t \in [0,1]$, define
		\;$X^{(n)}_{t} : \,\Omega \, \longrightarrow \, \Re$\;
		as follows:
		\begin{equation*}
		X^{(n)}_{t}(\omega) \;\; := \;\; X^{(n)}(\omega)(t),
		\quad
		\textnormal{for each $\omega \in \Omega$}.
		\end{equation*}
\end{itemize}
Then, the following statements are true:
\begin{enumerate}
\item	For each $\omega \in \Omega$ and each $n \in \N$,
		\begin{equation*}
		X^{(n)}(\omega)\left(\dfrac{i}{n}\right) \;\; = \;\; \dfrac{1}{\sigma\cdot\sqrt{n}}\cdot S_{i}(\omega),
		\quad
		\textnormal{for $i = 0, 1, 2, \ldots, n$}.
		\end{equation*}
\item	For each $\omega \in \Omega$ and each $n \in \N$, 
		\begin{center}
		$X^{(n)}(\omega)(t)$\; is the linear interpolation
		from \;$\dfrac{1}{\sigma\cdot\sqrt{n}}\,S_{i-1}(\omega)$\;
		to \;$\dfrac{1}{\sigma\cdot\sqrt{n}}\,S_{i}(\omega)$\;
		over \;$t \in \left[\dfrac{i-1}{n},\dfrac{i}{n}\right]$,
		\end{center}
		where $i = 1, 2, \ldots, n$.
\item	For any \;$0 \,\leq\, t_{0} \,<\, t_{1} \,<\, t_{2} \,<\, \cdots \,<\, t_{k} \,\leq\, 1$,
		\begin{equation*}
		\left(\;X^{(n)}_{t_{1}} - X^{(n)}_{t_{0}}, \;\ldots\;,\; X^{(n)}_{t_{k}} - X^{(n)}_{t_{k-1}}\;\right)
		\;\; \overset{d}{\longrightarrow} \;\;
		N\!\left(\;
		\mathbf{\mu} = \mathbf{0}\,,\,
		\overset{{\color{white}1}}{\Sigma} = \diag\!\left(\,t_{1}-t_{0},\; \ldots\; ,\; t_{k}-t_{k-1}\,\right)
		\;\right),
		\;\;
		\textnormal{as \;$n \longrightarrow \infty$}.
		\end{equation*}
\item	For any \;$0 \;\leq\; t_{1},\; t_{2}, \;\cdots\;,\; t_{k} \leq 1$,
		\begin{equation*}
		\left(\;X^{(n)}_{t_{1}},\; X^{(n)}_{t_{2}}, \;\ldots\;,\; X^{(n)}_{t_{k}}\;\right)
		\;\; \overset{d}{\longrightarrow} \;\;
		N\!\left(\;
		\mathbf{\mu} = \mathbf{0}\,,\,
		\Sigma = \left[\;\min\{\overset{{\color{white}1}}{t}_{i},t_{j}\}\;\right]_{1\leq i,j\leq k}
		\;\right),
		\;\;\textnormal{as \;$n \longrightarrow \infty$}.
		\end{equation*}
\end{enumerate}
\end{proposition}
\proof
\begin{enumerate}
\item	Obvious.
\item	Obvious.
\item	First, note that, for each $\omega \in \Omega$, $n \in\N$, and $t \in [0,1]$, we have
		\begin{equation*}
		X^{(n)}_{t}(\omega)
		\;\; = \;\;
		\dfrac{1}{\sigma\cdot\sqrt{n}}
		\left\{\;
		S_{\lfloor nt \rfloor}(\omega) \;+\; \left(\overset{{\color{white}1}}{nt} - \lfloor nt \rfloor\right)\cdot\xi_{\lfloor nt \rfloor+1}(\omega)
		\,\right\},
		\end{equation*}
		where $\lfloor\,\cdot\,\rfloor\,:\,\Re\;\longrightarrow\;\Z$, defined by
		\begin{equation*}
		\lfloor\,x\,\rfloor
		\;\;:=\;\;
		\max\left\{
		\left. k \in \overset{{\color{white}1}}{\Z} \,\;\right\vert\; k \leq x
		\,\right\},
		\quad
		\textnormal{for each $x \in \Re$},
		\end{equation*}
		is the round-down function.
		We next state three Claims, whose proofs will be given below.
		We note that the desired conclusion follows readily from Claim 3 and
		the Cram\'{e}r-Wold Theorem (Theorem 1.9, p.56, \cite{Shao2003});
		hence the present proof is complete once we establish the three
		Claims below.

		\vskip 0.5cm
		\begin{center}
		\begin{minipage}{6.0in}
		\noindent
		\textbf{Claim 1:}\quad
		If \;$\{\,a_{n}\,\}_{n\in\N}$\; is a sequence of non-negative integers and
		\;$\{\,b_{n}\,\}_{n\in\N} \;\subset\; \N$\; a sequence of positive integers
		satisfying:
		\begin{equation*}
		a_{n} \;<\; b_{n}, \;\textnormal{for sufficiently large $n\in\N$},
		\quad\quad
		\textnormal{and}
		\quad\quad
		\lim_{n\rightarrow\infty}\dfrac{b_{n} - a_{n}}{n} \;=\; c \;>\; 0,
		\end{equation*}
		then
		\begin{equation*}
		\dfrac{1}{\sigma\cdot\sqrt{n}}\cdot\sum_{i\,=\,1+a_{n}}^{b_{n}}\xi_{i}
		\;\; \overset{d}{\longrightarrow} \;\;
		\sqrt{c}\cdot Z,
		\quad
		\textnormal{where $Z\,\sim\,N(0,1)$}.
		\end{equation*}
		\end{minipage}
		\end{center}

		\vskip 0.5cm
		\begin{center}
		\begin{minipage}{6.0in}
		\noindent
		\textbf{Claim 2:}
		\quad For each fixed $t \in [0,1]$,
		\begin{equation*}
		W(t)_{n} \;\; := \;\;
		\dfrac{1}{\sigma\cdot\sqrt{n}}
		\cdot
		\left(\overset{{\color{white}1}}{nt} - \lfloor nt \rfloor\right)
		\cdot
		\xi_{\lfloor nt \rfloor + 1}
		\;\; \overset{d}{\longrightarrow} \;\;
		0.
		\end{equation*}
		\end{minipage}
		\end{center}

		\vskip 0.5cm
		\begin{center}
		\begin{minipage}{6.0in}
		\noindent
		\textbf{Claim 3:}\quad
		For $0 \,\leq\, t_{0} \,<\, t_{1} \,<\, t_{2} \,<\, \cdots \,<\, t_{k} \,\leq\, 1$,
		and arbitrary $c_{1}, c_{2}, \ldots, c_{k} \in \Re$,
		\begin{equation*}
		\sum_{i\,=\,1}^{k}\,c_{i}\left(\,X^{(n)}_{t_{i}} - X^{(n)}_{t_{i-1}}\,\right)
		\;\; \overset{d}{\longrightarrow} \;\;
		N\!\left(\,0\;,\;\sum_{i\,=\,1}^{k}\,c_{i}^{2}\,(t_{i} - t_{i-1})\;\right),
		\quad
		\textnormal{as \;$n \longrightarrow\infty$}.
		\end{equation*}
		\end{minipage}
		\end{center}

		\vskip 0.5cm
		\noindent
		\underline{Proof of Claim 1:}\quad
		Note that, for sufficiently large $n \in \N$, we may write
		\begin{equation*}
		\dfrac{1}{\sigma\cdot\sqrt{n}} \cdot \sum_{i\,=\,1+a_{n}}^{b_{n}}\xi_{i}
		\;\; = \;\;
		\dfrac{\sqrt{b_{n} - a_{n}}}{\sqrt{n}}\cdot
		\left(\;\dfrac{1}{\sigma\cdot\sqrt{b_{n} - a_{n}}} \cdot \sum_{i\,=\,1+a_{n}}^{b_{n}}\xi_{i}\;\right).
		\end{equation*}
		Since, by hypothesis, that
		\begin{equation*}
		\lim_{n\rightarrow\infty}\dfrac{b_{n} - a_{n}}{n} \;=\; c \;>\; 0,
		\end{equation*}
		Claim 1 follows by Slutsky's Theorem (Example 6, p.40, \cite{Ferguson1996}),
		once we establish the following:
		\begin{equation*}
		\dfrac{1}{\sigma\cdot\sqrt{b_{n} - a_{n}}} \cdot \sum_{i\,=\,1+a_{n}}^{b_{n}}\xi_{i}
		\;\; \overset{d}{\longrightarrow} \;\; N(0,1),
		\quad
		\textnormal{as $n \longrightarrow \infty$}.
		\end{equation*}
		We establish the above convergence by invoking
		the Lindeberg Central Limit Theorem (Theorem 1.15, \S1.5.5, p.67, \cite{Shao2003}).
		In the present context, the Lindeberg Condition is the following:
		\begin{eqnarray*}
		\lim_{n\rightarrow\infty}\,
		\dfrac{1}{B_{n}^{2}}\cdot
		E\!\left[\;
		\underset{i\,=\,1+a_{n}}{\overset{b_{n}}{\sum}}\xi_{i}^{2}
		\cdot
		I_{\left\{\vert\,\overset{{\color{white}.}}{\xi}_{i}\,\vert\,\geq\,\varepsilon\,S_{n}\right\}}
		\;\right]
		\;\; = \;\; 0,
		\quad
		\textnormal{for each $\varepsilon > 0$},
		\end{eqnarray*}
		where
		\begin{equation*}
		B_{n}^{2}
		\;\;:=\;\; \Var\!\left[\;\underset{i\,=\,1+a_{n}}{\overset{b_{n}}{\sum}}\xi_{i}\;\right]
		\;\; =\;\; (b_{n} - a_{n})\,\sigma^{2} \;\;>\;\; 0.
		\end{equation*}
		The last equality used the hypothesis that \,$\xi_{1}$,\, $\xi_{2}$,\, $\ldots$\, are independent
		and identically distributed with common finite variance $0 < \sigma^{2} < \infty$.
		Hence, for each $\varepsilon > 0$,
		\begin{eqnarray*}
		\dfrac{1}{B_{n}^{2}}\cdot
		E\!\left[\;
		\underset{i\,=\,1+a_{n}}{\overset{b_{n}}{\sum}}\xi_{i}^{2}
		\cdot
		I_{\left\{\vert\,\overset{{\color{white}.}}{\xi}_{i}\,\vert\,\geq\,\varepsilon\,B_{n}\right\}}
		\;\right]
		&=&
		\dfrac{1}{(b_{n} - a_{n})\,\sigma^{2}}
		\cdot
		(b_{n}-a_{n})
		\cdot
		E\!\left[\;
		\xi_{1}^{2}
		\cdot
		I_{\left\{\vert\,\overset{{\color{white}.}}{\xi}_{1}\,\vert\,\geq\,\varepsilon\sigma\,\sqrt{b_{n}-a_{n}}\right\}}
		\;\right]
		\\	
		&=&
		\dfrac{1}{\sigma^{2}}
		\cdot
		E\!\left[\;
		\xi_{1}^{2}
		\cdot
		I_{\left\{\vert\,\overset{{\color{white}.}}{\xi}_{1}\,\vert/\varepsilon\sigma\;\geq\;\sqrt{b_{n}-a_{n}}\right\}}
		\;\right]
		\;\; \longrightarrow \;\; 0,
		\;\;\;\textnormal{as \;$n \longrightarrow \infty$},
		\end{eqnarray*}
		since $\underset{n\rightarrow\infty}{\lim}\,\sqrt{b_{n} - a_{n}} \,=\, \infty$
		\;and\; $\sigma^{2} \,=\, E\!\left[\;\xi_{1}^{2}\;\right]$ is finite.
		This verifies that the Lindeberg Condition indeed holds in the present context,
		and completes the proof of Claim 1.

		\vskip 0.5cm
		\noindent
		\underline{Proof of Claim 2:}\quad
		First, note that $E\!\left[\;W(t)_{n}\;\right] = 0$.
		We now argue that $W(t)_{n} \overset{p}{\longrightarrow} 0$.
		To this end, let $\varepsilon > 0$ be given.
		Then,
		\begin{eqnarray*}
		\varepsilon^{2} \cdot P\!\left(\,\vert\,W(t)_{n}\,\vert\,\geq\,\varepsilon\,\right)
		&\leq& E\!\left[\;W(t)_{n}^{2} \cdot I_{\{\,\vert\,W(t)_{n}\,\vert\,\geq\,\varepsilon\,\}}\;\right]
		\\
		&\leq& E\!\left[\;W(t)_{n}^{2}\;\right]
		\;\;=\;\; \Var\!\left(\;W(t)_{n}\;\right)
		\;\;=\;\;
			\Var\!\left[\;
				\dfrac{1}{\sigma\cdot\sqrt{n}}
				\cdot
				\left(\overset{{\color{white}1}}{nt} - \lfloor nt \rfloor\right)
				\cdot
				\xi_{\lfloor nt \rfloor + 1}
			\;\right]
		\\
		&=&
			\dfrac{1}{n\cdot\sigma^{2}}
			\cdot
			\left(\overset{{\color{white}1}}{nt} - \lfloor\,nt\,\rfloor\right)^{2}
			\cdot
			\Var\!\left(\;\xi_{\lfloor nt \rfloor + 1}\;\right)
		\;\;=\;\;
			\dfrac{1}{n\cdot\sigma^{2}}
			\cdot
			\left(\overset{{\color{white}1}}{nt} - \lfloor\,nt\,\rfloor\right)^{2}
			\cdot
			\sigma^{2}
		\\
		&\leq& \dfrac{1}{n},
		\end{eqnarray*}
		which implies
		\begin{equation*}
		\lim_{n\rightarrow\infty}\,P\!\left(\;\vert\,W(t)_{n}\,\vert\,\geq\,\varepsilon\;\right) \; = \; 0,
		\;\;
		\textnormal{for each $\varepsilon > 0$},
		\end{equation*}
		i.e. $W(t)_{n}\overset{p}{\longrightarrow}0$, as $n\longrightarrow\infty$
		(Definition 2, Chapter 1, \cite{Ferguson1996}),
		which is equivalent to $W(t)_{n}\overset{d}{\longrightarrow}0$, as $n\longrightarrow\infty$
		(by Theorem 1, Chapter 1 and Theorem 2, Chapter 2, \cite{Ferguson1996}).
		This proves Claim 2.

		\vskip 0.5cm
		\noindent
		\underline{Proof of Claim 3:}\quad
		Let $0 \,\leq\, t_{0} \,<\, t_{1} \,<\, t_{2} \,<\, \cdots \,<\, t_{k} \,\leq\, 1$,
		and $c_{1}, c_{2}, \ldots, c_{k} \in \Re$ be arbitrary.
		Observe that:
		\begin{eqnarray*}
		&& \overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i}\left(\,X^{(n)}_{t_{i}} - X^{(n)}_{t_{i-1}}\,\right)
		\\
		&=&
		\overset{k}{\underset{i\,=\,1}{\sum}} \; \dfrac{c_{i}}{\sigma\cdot\sqrt{n}}
		\left\{\,
			\overset{{\color{white}1}}{S}_{\lfloor nt_{i} \rfloor} \,-\, S_{\lfloor nt_{i-1} \rfloor}
		\,\right\}
		\;+\;
		\overset{k}{\underset{i\,=\,1}{\sum}} \; \dfrac{c_{i}}{\sigma\cdot\sqrt{n}}
		\left\{\,
			\left(\overset{{\color{white}1}}{n}t_{i} - \lfloor nt_{i} \rfloor\right)\cdot\overset{{\color{white}1}}{\xi}_{\lfloor nt_{i} \rfloor+1}
			\;-\; \left(\overset{{\color{white}1}}{n}t_{i-1} - \lfloor nt_{i-1} \rfloor\right)\cdot\xi_{\lfloor nt_{i-1} \rfloor+1}
		\,\right\}
		\\
		&=&
		\overset{k}{\underset{i\,=\,1}{\sum}} \; \dfrac{c_{i}}{\sigma\cdot\sqrt{n}}
		\left\{\,
			\overset{\lfloor nt_{i} \rfloor}{\underset{j\,=\,1+\lfloor nt_{i-1} \rfloor}{\sum}}\,\xi_{j}
		\,\right\}
		\;+\;
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i} \left\{\,\overset{{\color{white}.}}{W}(t_{i})_{n} \;-\; W(t_{i-1})_{n}\,\right\}
		\\
		&=&
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i}\,Y^{(n)}_{i}
		\;+\;
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i} \left\{\,\overset{{\color{white}.}}{W}(t_{i})_{n} \;-\; W(t_{i-1})_{n}\,\right\}
		%\\
		%&\overset{d}{\longrightarrow}&
		%N\!\left(\;0\;,\;\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i}^{2}\,(t_{i} - t_{i-1})\;\right),
		%\;\;\textnormal{as \;$n \,\longrightarrow\, \infty$},
		\end{eqnarray*}
		By Claim 2 and Slutsky's Theorem (Corollary, p.40, \cite{Ferguson1996}),
		\begin{equation}\label{cBconvergesToZeroInProbability}
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i} \left\{\,\overset{{\color{white}.}}{W}(t_{i})_{n} \;-\; W(t_{i-1})_{n}\,\right\}
		\;\;\overset{d}{\longrightarrow}\;\; 0,
		\;\;\textnormal{as \;$n \,\longrightarrow\, \infty$}.				
		\end{equation}
		Next, note that since \,$\xi_{1},\, \xi_{2},\, \xi_{3},\, \ldots$\, are independent,
		we see that, for each fixed $n \in \N$,
		\begin{equation*}
		Y^{(n)}_{i}
		\;\; := \;\;
		\dfrac{1}{\sigma\cdot\sqrt{n}}
		\cdot
		\overset{\lfloor nt_{i} \rfloor}{\underset{j\,=\,1+\lfloor nt_{i-1} \rfloor}{\sum}}\,\xi_{j},
		\quad
		i \,=\, 1,\, 2,\, 3,\, \ldots,\, k,
		\end{equation*}
		are independent.
		Now, since $0 \leq t_{i-1} < t_{i} \leq 1$, it follows that
		\,$\lfloor nt_{i-1} \rfloor \,<\, \lfloor nt_{i} \rfloor$\,
		for sufficiently large $n \in \N$.
		In addition,
		\begin{eqnarray*}
		\dfrac{\lfloor n t_{i} \rfloor - \lfloor n t_{i-1} \rfloor}{n}
		& = & \dfrac{\lfloor n t_{i} \rfloor}{n} - \dfrac{\lfloor n t_{i-1} \rfloor}{n}
		\;\; = \;\; \left(\dfrac{n t_{i}}{n} + \dfrac{\lfloor n t_{i} \rfloor - n t_{i}}{n}\right)
			\;-\; \left(\dfrac{n t_{i-1}}{n} + \dfrac{\lfloor n t_{i-1} \rfloor - n t_{i-1}}{n}\right)
		\\
		&=& t_{i} \;-\; t_{i-1} \;+\;  \dfrac{\lfloor nt_{i} \rfloor - nt_{i}}{n} - \dfrac{\lfloor nt_{i-1} \rfloor - nt_{i-1}}{n},
		\end{eqnarray*}
		which implies
		\begin{equation*}
		\left\vert\; \dfrac{\lfloor n t_{i} \rfloor - \lfloor n t_{i-1} \rfloor}{n} \;-\; (t_{i}-t_{i-1}) \;\right\vert
		\;\;=\;\;
		\left\vert\; \dfrac{\lfloor nt_{i} \rfloor - nt_{i}}{n} - \dfrac{\lfloor nt_{i-1} \rfloor - nt_{i-1}}{n} \;\right\vert
		\;\; \leq \;\;
		\dfrac{2}{n}
		\;\; \longrightarrow \;\; 0,
		\quad
		\textnormal{as \;$n \longrightarrow \infty$}.
		\end{equation*}
		Thus,
		\begin{equation*}
		\lim_{n\rightarrow\infty}\,\dfrac{\lfloor n t_{i} \rfloor - \lfloor n t_{i-1} \rfloor}{n} \;\;=\;\; t_{i} \,-\, t_{i-1} \;\;>\;\; 0.
		\end{equation*}
		Thus, by Claim 1, we see that, for each \,$i \,=\, 1,\, 2,\, \ldots,\, k$,
		\begin{equation}\label{YniGaussianDistributionalLimit}
		Y^{(n)}_{i}
		\;\; := \;\;
		\dfrac{1}{\sigma\cdot\sqrt{n}}
		\cdot
		\overset{\lfloor nt_{i} \rfloor}{\underset{j\,=\,1+\lfloor nt_{i-1} \rfloor}{\sum}}\,\xi_{j}
		\;\; \overset{d}{\longrightarrow} \;\; \sqrt{t_{i}-t_{i-1}} \cdot N(0,1)
		\;\; = \;\; N\!\left(\,\overset{{\color{white}.}}{0}\,,\,t_{i}-t_{i-1}\,\right),
		\quad
		\textnormal{as \;$n \longrightarrow \infty$}.
		\end{equation}
		By \eqref{cBconvergesToZeroInProbability},
		\eqref{YniGaussianDistributionalLimit},
		Proposition \ref{GaussianDistributionLimit},
		and Slutsky's Theorem (Corollary, p.40, \cite{Ferguson1996}), we now see that
		\begin{equation*}
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i}\left(\,X^{(n)}_{t_{i}} - X^{(n)}_{t_{i-1}}\,\right)
		\;\;=\;\;
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i}\,Y^{(n)}_{i}
		\;+\;
		\overset{k}{\underset{i\,=\,1}{\sum}} \; c_{i} \left\{\,\overset{{\color{white}.}}{W}(t_{i})_{n} \;-\; W(t_{i-1})_{n}\,\right\}
		\;\;\overset{d}{\longrightarrow}\;\;
		N\!\left(\,0\;,\;\sum_{i\,=\,1}^{k}c_{i}^{2}(t_{i}-t_{i-1})\;\right).
		\end{equation*}		
		This completes the proof of Claim 3.

\end{enumerate}
\qed

%		First, recall that, by the Central Limit Theorem, we have:
%		\begin{equation*}
%		\dfrac{1}{\sigma\sqrt{n}} \cdot S_{n}
%		\;\; \overset{d}{\longrightarrow} \;\;
%		N(0,1),
%		\quad
%		\textnormal{as $n \longrightarrow \infty$}.
%		\end{equation*}
%		By Theorem 2.6, \cite{Billingsley1999}, the above convergence is equivalent to:
%		\begin{center}
%		For each subsequence $\left\{\,n_{i}\right\}_{i\in\N}$ of $\{\,1,2,\ldots\,\}$, there exists a further subsequence
%		$\left\{\,n_{i(k)}\right\}_{k\in\N}$ such that
%		\begin{equation*}
%		\dfrac{1}{\sigma\sqrt{n_{i(k)}}} \cdot S_{n_{i(k)}}
%		\;\; \overset{d}{\longrightarrow} \;\;
%		N(0,1),
%		\quad
%		\textnormal{as $k \longrightarrow \infty$}.
%		\end{equation*}		
%		\end{center}
%		Note that $\lfloor\,\cdot\,\rfloor$ is non-decreasing over all of $\Re$.
%		Hence, for each fixed $t \in (0,1]$, $\left\{\,\lfloor\,nt\,\rfloor\,\right\}_{n\in\N}$
%		is a non-decreasing sequence of non-negative integers satisfying
%		$\lfloor\,nt\,\rfloor \longrightarrow \infty$ as $n \longrightarrow \infty$.

%		\begin{eqnarray*}
%		E\!\left[\,X^{(n)}_{t}\,\right]
%		&=&
%		E\!\left[\;\,
%		\dfrac{1}{\sigma\cdot\sqrt{n}}
%		\left\{\;
%		S_{i-1} \;+\; n\left(t - \dfrac{i-1}{n}\right)\xi_{i}
%		\,\right\}
%		\;\right]
%		\\
%		& = &
%		\dfrac{1}{\sigma\cdot\sqrt{n}}
%		\left\{\;
%		E\!\left[\, S_{i-1}\,\right] \;+\; n\left(t - \dfrac{i-1}{n}\right)\cdot E\!\left[\;\xi_{i}\;\right]
%		\;\right\}
%		\;\; = \;\; 0.
%		\end{eqnarray*}
%		And, for each $n \in \N$, and each $t \in \left[\dfrac{i-1}{n},\dfrac{i}{n}\right]$, $i = 1,2,\ldots,n$, 
%		\begin{eqnarray*}
%		\Var\!\left[\,X^{(n)}_{t}\,\right]
%		&=&
%		\Var\!\left[\;\,
%		\dfrac{1}{\sigma\cdot\sqrt{n}}
%		\left\{\;
%		S_{i-1} \;+\; n\left(t - \dfrac{i-1}{n}\right)\xi_{i}
%		\,\right\}
%		\;\right]
%		\\
%		& = &
%		\dfrac{1}{n\,\sigma^{2}}
%		\left\{\;
%		\Var\!\left[\, S_{i-1}\,\right] \;+\; n^{2}\left(t - \dfrac{i-1}{n}\right)^{2}\cdot \Var\!\left[\;\xi_{i}\;\right]
%		\;\right\}
%		\\
%		& = &
%		\dfrac{1}{n\,\sigma^{2}}
%		\left\{\;
%		(i-1)\cdot\sigma^{2} \;+\; n^{2}\left(t - \dfrac{i-1}{n}\right)^{2}\cdot\sigma^{2}
%		\;\right\}
%		\\
%		& = &
%		\dfrac{1}{n}\cdot
%		\left\{\;
%		(i-1) \;+\; n^{2}\left(t - \dfrac{i-1}{n}\right)^{2}
%		\;\right\}.
%		\end{eqnarray*}

%\vskip 0.5cm
%\begin{remark}
%\mbox{}
%\vskip 0.0cm
%\noindent
%By the Central Limit Theorem,
%\begin{equation*}
%X^{(n)}_{t}
%\end{equation*}
%\end{remark}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
