
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{BLUEs with arbitrary covariance matrix}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{definition}[Linear unbiased estimators and BLUEs]
\mbox{}\vskip 0.1cm\noindent
Suppose:
\begin{itemize}
\item
	$X \in \Re^{n \times p}$.
\item
	$\Lambda : \Re^{p} \longrightarrow \Re^{q}$ is an $X$-estimable linear map,
	i.e. there exists there exists $\Gamma \in \Re^{n \times q}$ such that
	$\Lambda(\beta) \;\; =\;\; \Gamma^{T} \cdot X \cdot \beta$,
	for each $\beta \in \Re^{p}$.
\item
	$Y = \left\{\;
		\left.
		\overset{{\color{white}.}}{Y}_{\beta} : (\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta}) \longrightarrow \Re^{n}
		\;\;\right\vert\;
		\beta \in \Re^{p}
		\;\right\}$
	is a family, indexed by $\beta \in \Re^{p}$,
	of $\Re^{n}$-valued random variables defined respectively on the
	probability spaces $(\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta})$.
\end{itemize}
Then,
\begin{enumerate}
\item
	A linear map $L : \Re^{n} \longrightarrow \Re^{q}$ is called a
	{\color{red}\textbf{linear unbiased estimator of
	$\Lambda : \Re^{p} \longrightarrow \Re^{q}$
	in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$}} if
	$E\!\left[\,L(Y_{\beta})\,\right] = \Lambda(\beta)$, for each $\beta \in \Re^{p}$.
\item
	A linear unbiased estimator $L : \Re^{n} \longrightarrow \Re^{q}$
	of $\Lambda : \Re^{p} \longrightarrow \Re^{q}$
	in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$
	is called a
	{\color{red}\textbf{best linear unbiased estimator (BLUE) of
	$\Lambda : \Re^{p} \longrightarrow \Re^{q}$ in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$}}
	if, for every linear unbiased estimator $L^{\prime} : \Re^{n} \longrightarrow \Re^{q}$
	in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$, we have:
	\begin{equation*}
	\Var\!\left(\,\xi^{T} \cdot L(Y_{\beta})\,\right)
	\;\; \leq \;\;
		\Var\!\left(\,\xi^{T} \cdot L^{\prime}(Y_{\beta})\,\right)\,,
	\quad
	\textnormal{for every \,$\beta \in \Re^{p}$\, and \,$\xi \in \Re^{q \times 1}$}\,.
	\end{equation*}
\end{enumerate}
\end{definition}

\begin{proposition}
\mbox{}\vskip 0.1cm\noindent
Suppose:
\begin{itemize}
\item
	$X \in \Re^{n \times p}$\, and 
	\,$\mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{n}$ is left multiplication by $X \in \Re^{n \times p}$.
\item
	$A \in \Re^{n \times n}$\, and 
	\,$\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n}$ is left multiplication by $A \in \Re^{n \times n}$.
\item
	$Y = \left\{\;
		\left.
		\overset{{\color{white}.}}{Y}_{\beta} : (\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta}) \longrightarrow \Re^{n}
		\;\;\right\vert\;
		\beta \in \Re^{p}
		\;\right\}$
	is a family, indexed by $\beta \in \Re^{p}$,
	of $\Re^{n}$-valued random variables defined respectively on the
	probability spaces $(\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta})$.
\item
	$E\!\left[\;Y_{\beta}\,\right] \,=\, X \cdot \beta$, for each $\beta \in \Re^{p}$
\end{itemize}
Then, \vskip -0.5cm
\begin{equation*}
\begin{array}{c}
	\textnormal{$\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n}$ is a BLUE of}
	\\
	\textnormal{$\overset{{\color{white}+}}{\mathcal{L}}_{X} : \Re^{p} \longrightarrow \Re^{n}$}
	\\
	\textnormal{in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$}
		{\color{white}\overset{+}{\Re}}
	\end{array}
\quad\Longleftrightarrow\quad
\begin{array}{c}
	\textnormal{$\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{1}$ is a BLUE of}
	\\
	\textnormal{$\overset{{\color{white}+}}{\mathcal{L}}_{\,\gamma^{T}} \circ \mathcal{L}_{X} :
		\Re^{p} \longrightarrow \Re^{1}$}
	\\
	\textnormal{in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$\,,}
		{\color{white}\overset{+}{\Re}}
	\\
	\textnormal{for every $\gamma \in \Re^{n \times 1}$\,.}
	\end{array}
\end{equation*}
\end{proposition}
\proof
\vskip 0.1cm
\noindent
\textbf{\underline{(\,$\Longrightarrow$\,)}}\quad
Suppose
\,$\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n}$\,
is a BLUE of
\,$\mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{n}$\,
in terms of
\,$Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$.

\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad
$\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{1}$\,
is a linear unbiased estimator of
\,$\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{1}$\,
in terms of \,$Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$.
\vskip 0.1cm
\noindent
Proof of Claim 1:\quad
First, note that, for each $\beta\in\Re^{p}$, we have $E\!\left[\; \mathcal{L}_{A}(Y_{\beta})\;\right] = X \cdot \beta$.
Hence,
$E\!\left[\;\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{A}(Y_{\beta})\;\right]$
\,$=$\, $E\!\left[\;\gamma^{T} \cdot \mathcal{L}_{A}(Y_{\beta})\;\right]$
\,$=$\, $\gamma^{T} \cdot E\!\left[\; \mathcal{L}_{A}(Y_{\beta})\;\right]$
\,$=$\, $\gamma^{T} \cdot X \cdot \beta$
\,$=$\, $\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{X}(\,\beta\,)$,\,
for each $\beta\in\Re^{p}$.
This proves Claim 1.

\vskip 0.5cm
\noindent
Next, let
\,$L : \Re^{n} \longrightarrow \Re^{1}$\,
be an arbitrary linear unbiased estimator of
\,$\mathcal{L}_{\,\gamma^{T}} \circ \mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{1}$\,
in terms of \,$Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$.
The proof of the forward implication will be complete once we show that
\begin{equation*}
\Var\!\left(\,\xi\cdot\mathcal{L}_{\gamma^{T}}\circ\mathcal{L}_{A}(Y_{\beta})\,\right)
\;\; \leq \;\;
	\Var\!\left(\,\xi \cdot L(Y_{\beta})\,\right),
\quad
\textnormal{for each \,$\xi \in \Re^{1}$, \,$\beta\in\Re^{p}$}\,.
\end{equation*}
However, the preceding inequality is equivalent to Claim 3 below, since
\,$\Var\!\left(\,\xi\cdot\mathcal{L}_{\gamma^{T}}\circ\mathcal{L}_{A}(Y_{\beta})\,\right)$
\,$=$\, $\xi^{2}\cdot\Var\!\left(\,\mathcal{L}_{\gamma^{T}}\circ\mathcal{L}_{A}(Y_{\beta})\,\right)$
and
\,$\Var\!\left(\,\xi \cdot L(Y_{\beta})\,\right)$
\,$=$\, $\xi^{2} \cdot \Var\!\left(\,L(Y_{\beta})\,\right)$.

\vskip 0.5cm
\noindent
Now, since \,$L : \Re^{n} \longrightarrow \Re^{1}$\,
is a linear map, it has the following form:
there exists $v \in \Re^{n \times 1}$ such that
\,$L(y) \,=\, v^{T} \cdot y$,\,
for each \,$y \in \Re^{n}$.

\vskip 0.5cm
\noindent
\textbf{Claim 2:}\quad
$v \,=\, \gamma + w$,\, where \,$w \,\in\, \Col(X)^{\perp}$.
\vskip 0.1cm
\noindent
Proof of Claim 2:\quad
Note that, for each $\beta \in \Re^{p}$, we have
\,$v^{T}\cdot X \cdot \beta$
\,$=$\, $v^{T} \cdot E\!\left[\;Y_{\beta}\,\right]$
\,$=$\, $E\!\left[\,v^{T} \cdot Y_{\beta}\,\right]$
\,$=$\, $E\!\left[\,L(Y_{\beta})\,\right]$
\,$=$\, $\gamma^{T} \cdot X \cdot \beta$.
Hence,
\,$(v - \gamma)^{T} \cdot X \cdot \beta \,=\, 0$,\,
for each $\beta\in\Re^{p}$\,;
equivalently, $v - \gamma \in \Col(X)^{\perp}$.
Claim 2 now follows immediately.

\vskip 0.5cm
\noindent
\textbf{Claim 3:}\quad
$\Var\!\left(\,\mathcal{L}_{\gamma^{T}}\circ\mathcal{L}_{A}(Y_{\beta})\,\right)
\,\leq\,
	\Var\!\left(\,L(Y_{\beta})\,\right)$,\,
for each \,$\beta\in\Re^{p}$.
\vskip 0.1cm
\noindent
Proof of Claim 3:\quad
First, observe that
\,$E\!\left[\,\mathcal{L}_{I_{n}}(Y_{\beta})\,\right]$
\,$=$\, $E\!\left[\,I_{n} \cdot Y_{\beta}\,\right]$
\,$=$\, $E\!\left[\;Y_{\beta}\,\right]$
\,$=$\, $X \cdot \beta$
\,$=$\, $\mathcal{L}_{X}(\beta)$,\,
i.e. $\mathcal{L}_{I_{n}}$ is a linear unbiased estimator of $\mathcal{L}_{X}$
in terms of $Y = \{\,Y_{\beta}\,\}$.
Thus, by the hypothesis that $\mathcal{L}_{A}$ is a BLUE of $\mathcal{L}_{X}$ in terms of $Y = \{\,Y_{\beta}\,\}$,
we have
$\Var\!\left(\,\xi^{T} \cdot A \cdot Y_{\beta}\,\right)$
\,$\leq$\, $\Var\!\left(\,\xi^{T} \cdot I_{n} \cdot Y_{\beta}\,\right)$
\,$=$\, $\Var\!\left(\,\xi^{T} \cdot Y_{\beta}\,\right)$,\,
for each $\xi \in \Re^{n}$, $\beta\in\Re^{p}$.
Consequently,
\begin{eqnarray*}
\Var\!\left(\; \mathcal{L}_{\gamma^{T}} \circ \mathcal{L}_{A}(Y_{\beta}) \;\right)
&=&
	\Var\!\left(\; \gamma^{T} \cdot \mathcal{L}_{A}(Y_{\beta}) \;\right)
\;\; = \;\;
	\Var\!\left(\; \gamma^{T} \cdot A \cdot Y_{\beta} \;\right)
\;\; \leq \;\;
	\Var\!\left(\; \gamma^{T} \cdot Y_{\beta} \;\right)
\\
&\leq&
	\Var\!\left(\; \gamma^{T} \cdot Y_{\beta} \;\right)
	\; + \;
	\Var\!\left(\; w^{T} \cdot Y_{\beta} \;\right)
\;\;=\;\;
	\Var\!\left(\; (\gamma + w)^{T} \cdot Y_{\beta} \;\right)
\;\; = \;\;
	\Var\!\left(\; v^{T} \cdot Y_{\beta} \;\right)
\\
&=&
	\Var\!\left(\; L(Y_{\beta}) \;\right),
\quad
\textnormal{for each \,$\beta\in\Re^{p}$}\,.
\end{eqnarray*}
This proves Claim 3, and completes the proof of the forward implication.

\vskip 0.5cm
\noindent
\textbf{\underline{(\,$\Longleftarrow$\,)}}\quad

\qed

\begin{proposition}
\mbox{}\vskip 0.1cm\noindent
Suppose:
\begin{itemize}
\item
	$X \in \Re^{n \times p}$\, and 
	\,$\mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{n}$ is left multiplication by $X \in \Re^{n \times p}$.
\item
	$\Lambda : \Re^{p} \longrightarrow \Re^{q}$ is an $X$-estimable linear map, i.e.
	there exists $\Gamma \in \Re^{n \times q}$ such that
	$\Lambda(\beta) = \Gamma^{T} \cdot X \cdot \beta$, for each $\beta \in \Re^{p}$.
\item
	$A \in \Re^{n \times n}$\, and 
	\,$\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n}$ is left multiplication by $A \in \Re^{n \times n}$.
\item
	$Y = \left\{\;
		\left.
		\overset{{\color{white}.}}{Y}_{\beta} : (\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta}) \longrightarrow \Re^{n}
		\;\;\right\vert\;
		\beta \in \Re^{p}
		\;\right\}$
	is a family, indexed by $\beta \in \Re^{p}$,
	of $\Re^{n}$-valued random variables defined respectively on the
	probability spaces $(\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta})$.
\item
	$E\!\left[\;Y_{\beta}\,\right] \,=\, X \cdot \beta$, for each $\beta \in \Re^{p}$
\end{itemize}
Then, \vskip -0.5cm
\begin{equation*}
\begin{array}{c}
	\textnormal{$\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n}$ is a BLUE of}
	\\
	\textnormal{$\overset{{\color{white}+}}{\mathcal{L}}_{X} : \Re^{p} \longrightarrow \Re^{n}$}
	\\
	\textnormal{in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$}
		{\color{white}\overset{+}{\Re}}
	\end{array}
\quad\Longrightarrow\quad
\begin{array}{c}
	\textnormal{$\mathcal{L}_{\,\Gamma^{T}} \circ \mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{1}$ is a BLUE of}
	\\
	\textnormal{$\mathcal{L}_{\Lambda} = \overset{{\color{white}+}}{\mathcal{L}}_{\,\Gamma^{T}} \circ \mathcal{L}_{X} :
		\Re^{p} \longrightarrow \Re^{1}$}
	\\
	\textnormal{in terms of $Y = \{\,Y_{\beta}\,\}_{\beta\in\Re^{p}}$\,.}
		{\color{white}\overset{+}{\Re}}
	\end{array}
\end{equation*}
\end{proposition}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
