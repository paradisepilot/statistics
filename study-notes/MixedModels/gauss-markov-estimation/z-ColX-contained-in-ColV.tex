
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Estimation for the case $\Col(X) \subset \Col(V)$}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{theorem}[Theorem 10.1.2, p.239, \cite{Christensen2011}]
\mbox{}
\vskip 0.1cm
\noindent
Suppose:
\begin{itemize}
\item
	$\sigma^{2} > 0$,
	$X \in \Re^{n \times p}$.
\item
	$V \in \Re^{n \times n}$ is a symmetric positive semi-definite matrix, and
	\,$r \,:=\, \rank(V) \,\in\, \{1,2,\ldots,n\}$.
\item
	{\color{red}$\Col(X) \,\subset\, \Col(V)$}.
\item
	$Y = \left\{\;
		\left.
		\overset{{\color{white}.}}{Y}_{\beta} : (\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta}) \longrightarrow \Re^{n}
		\;\;\right\vert\;
		\beta \in \Re^{p}
		\;\right\}$
	is a family, indexed by $\beta \in \Re^{p}$,
	of $\Re^{n}$-valued random variables defined respectively on the
	probability spaces $(\Omega_{\beta},\mathcal{A}_{\beta},\mu_{\beta})$.
\item
	For each $\beta \in \Re^{p}$, the following hold:
	\begin{equation*}
	\begin{array}{rclcl}
	E\!\left[\;Y_{\beta}\,\right] &  \overset{{\color{white}\vert}}{=} & X \cdot \beta & \in & \Re^{n}
	\\
	\Cov\!\left(\,Y_{\beta}\,\right) & \overset{{\color{white}\vert}}{=} & \sigma^{2} \cdot V & \in & \Re^{n \times n}
	\end{array}
	\end{equation*}
\end{itemize}
Then, the following statements hold:
\begin{enumerate}
\item\label{XtVdaggerX}
	For any two generalized inverses
	\,$V^{\dagger},\, \widetilde{V}^{\dagger} \in \Re^{n \times n}$\,
	of \,$V \in \Re^{n \times n}$,\, we have
	\begin{equation*}
	X^{T} \cdot V^{\dagger} \cdot X
	\;\; = \;\;
	X^{T} \cdot \widetilde{V}^{\dagger} \cdot X
	\;\; \in \;\; \Re^{p \times p}
	\end{equation*}
\item\label{XtVdaggerY}
	For any \,$y \in \Col(V)$,\, we have
	\begin{equation*}
	X^{T} \cdot V^{\dagger} \cdot y
	\;\; = \;\;
	X^{T} \cdot \widetilde{V}^{\dagger} \cdot y
	\;\; \in \;\; \Re^{p \times 1}\,,
	\quad
	\textnormal{for any two generalized inverses
	\,$V^{\dagger},\, \widetilde{V}^{\dagger} \in \Re^{n \times n}$\,
	of \,$V \in \Re^{n \times n}$}.
	\end{equation*}	
\item\label{XXtVdaggerXXtVdaggerY}
	For any \,$y \in \Col(V)$,\, the vector
	\begin{equation*}
	X \cdot \left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y \;\; \in \;\; \Re^{n}
	\end{equation*}
	is independent of the particular choices of
	\,$V^{\dagger} \in \Re^{n \times n}$\,
	and
	\,$\left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \in \Re^{p \times p}$.
\item
	The map
	\begin{equation*}
	\Re^{n} \longrightarrow \Re^{n}
	\; : \; y \; \longmapsto \;
	X \cdot \left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y
	\end{equation*}
	is a BLUE of
	\begin{equation*}
	\mathcal{L}_{X} \; : \; \Re^{p} \longrightarrow \Re^{n} \; : \; y \; \longmapsto \; X \cdot y
	\end{equation*}
	in terms of
	\,$Y = \{\,Y_{\beta}\,\}$,
	where
	\,$V^{\dagger} \in \Re^{n \times n}$\, is any generalized inverse of \,$V \in \Re^{n \times n}$,\,
	and
	\,$\left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \in \Re^{p \times p}$\,
	is any generalized inverse of
	\,$X^{T} \cdot V^{\dagger} \cdot X \in \Re^{p \times p}$.
\item
	$E\!\left[\;Q^{\dagger} \cdot Y_{\beta}\;\right] \; = \; Q^{\dagger} \cdot X \cdot \beta$\,,
	\,and\,
	\,$\Var\!\left(\,Q^{\dagger} \cdot Y_{\beta}\,\right) \; = \; \sigma^{2} \cdot I_{r}$\,,
	for each \,$\beta \in \Re^{p}$.
\item
	The map
	\begin{equation*}
	\mathcal{L}_{\,\Pi_{Q^{\dagger}X}}
	\;\; : \;\; \Re^{r} \; \longrightarrow \; \Re^{r}
	\;\; : \;\; \zeta \; \longmapsto \;
		(Q^{\dagger} \cdot X)
		\cdot
		\left[\;(Q^{\dagger} \cdot X)^{T} \cdot Q^{\dagger} \cdot X \,\right]^{\dagger}
		\cdot
		(Q^{\dagger} \cdot X)^{T} \cdot \zeta
	\end{equation*}
	is a BLUE of
	\begin{equation*}
	\mathcal{L}_{\,Q^{\dagger}X}
	\;\; : \;\; \Re^{p} \; \longrightarrow \; \Re^{r}
	\;\; : \;\; \beta \; \longmapsto \; Q^{\dagger} \cdot X \cdot \beta
	\end{equation*}
	in terms of
	\,$Q^{\dagger}(\,Y\,) = \{\;Q^{\dagger} \cdot Y_{\beta}\;\}$.
\item
	For any \,$A \in \Re^{n \times n}$,\, we have:
	\begin{equation*}
	\begin{array}{c}
		\mathcal{L}_{A} : \Re^{n} \longrightarrow \Re^{n} : y \longmapsto A \cdot y
		\\{\color{white}\overset{.}{\vert}}
		\textnormal{is \, a \, BLUE \, of}
		\\{\color{white}\overset{.}{\vert}}
		\mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{n} : \beta \longmapsto X \cdot \beta
		\\{\color{white}\overset{.}{\vert}}
		\textnormal{in terms of \,$Y = \{\,Y_{\beta}\,\}$}
		\end{array}
	\quad\Longleftrightarrow\quad
		\begin{array}{c}
		\mathcal{L}_{AQ} : \Re^{\color{red}r} \longrightarrow \Re^{n} : \zeta \longmapsto A \cdot Q \cdot \zeta
		\\{\color{white}\overset{.}{\vert}}
		\textnormal{is \, a \, BLUE \, of}
		\\{\color{white}\overset{.}{\vert}}
		\mathcal{L}_{X} : \Re^{p} \longrightarrow \Re^{n} : \beta \longmapsto X \cdot \beta
		\\{\color{white}\overset{.}{\vert}}
		\textnormal{in terms of \,$Q^{\dagger}(\,Y\,) = \{\,Q^{\dagger} \cdot Y_{\beta}\;\}$}
	\end{array}
	\end{equation*}
\end{enumerate}
\end{theorem}
\proof
\begin{enumerate}
\item
	By hypothesis, we have $\Col(X) \subset \Col(V)$.
	Hence, $X = V \cdot C$, for some $C \in \Re^{n \times p}$.
	Hence, for any generalized inverse $V^{\dagger} \in \Re^{n \times n}$,
	we have
	\begin{equation*}
	X^{T} \cdot V^{\dagger} \cdot X
	\;\; = \;\;
		C^{T} \cdot V^{T} \cdot V^{\dagger} \cdot V \cdot C
	\;\; = \;\;
		C^{T} \cdot V \cdot V^{\dagger} \cdot V \cdot C
	\;\; = \;\;
		C^{T} \cdot V \cdot C
	\end{equation*}
\item
	Again, since $\Col(X) \subset \Col(V)$, we may write
	$X = V \cdot C$, for some $C \in \Re^{n \times p}$.
	Similarly, since $y \in \Col(V)$, we have $y = V \cdot \eta$,
	for some $\eta \in \Re^{n \times 1}$.
	Hence, for any generalized inverse $V^{\dagger} \in \Re^{n \times n}$,
	we have
	\begin{equation*}
	X^{T} \cdot V^{\dagger} \cdot y
	\;\; = \;\;
		C^{T} \cdot V^{T} \cdot V^{\dagger} \cdot V \cdot \eta
	\;\; = \;\;
		C^{T} \cdot V \cdot V^{\dagger} \cdot V \cdot  \eta
	\;\; = \;\;
		C^{T} \cdot V \cdot \eta
	\end{equation*}
\item
	By \eqref{XtVdaggerX} above, we see that
	\,$X \in \Re^{n \times p}$\, and \,$V \in \Re^{n \times n}$\,
	unambiguously determine
	\,$W_{X,V} \, := \, X^{T} \cdot V^{\dagger} \cdot X \, \in \, \Re^{p \times p}$\,;\,
	in other words, \,$W_{X,V} \in \Re^{p \times p}$\, depends only on $X$ and $V$,
	but it does not depend on the particular choice of the generalized inverse
	\,$V^{\dagger} \in \Re^{n \times n}$\, of \,$V \in \Re^{n \times n}$.
	
	We need to show that
	\begin{equation*}
	X \cdot \left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y
	\;\; = \;\;
		X \cdot \left(\,W_{X,V}\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y
	\;\; \in \;\; \Re^{n \times 1}
	\end{equation*}
	is in fact independent of the particular choices of the two generalized inverses
	\,$V^{\dagger} \in \Re^{n \times n}$\, and \,$(W_{X,V})^{\dagger} \in \Re^{p \times p}$\,
	of \,$V \in \Re^{n \times n}$\, and \,$W_{X,V} \in \Re^{p \times p}$\, respectively.

	By \eqref{XtVdaggerY} above, it follows immediately that the vector
	\,$X \cdot \left(\,W_{X,V}\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y \in \Re^{n \times 1}$\,
	is independent of the particular choice of
	\,$V^{\dagger} \in \Re^{n \times n}$\, in \,$X^{T} \cdot V^{\dagger} \cdot y$.\,
	So, it remains only to show that the vector
	\,$X \cdot \left(\,W_{X,V}\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y$\,
	is also independent of the particular choice of the generalized inverse
	\,$\left(\,W_{X,V}\,\right)^{\dagger}  \in \Re^{p \times p}$\,
	of \,$W_{X,V} \in \Re^{p \times p}$.

	To this end, let $Q \in \Re^{n \times r}$\, and \,$Q^{\dagger} \in \Re^{r \times n}$\,
	be the matrices determined (non-uniquely) by $V \in \Re^{n \times n}$
	as described in Corollary \ref{corollaryRealSpectralTheorem}.
	Then, \,$(Q^{\dagger})^{T} \cdot Q^{\dagger} \in \Re^{n \times n}$\,
	is a generalized inverse of \,$V \in \Re^{n \times n}$.

	By \eqref{XtVdaggerX} and \eqref{XtVdaggerY} above,
	we may take both occurrences of \,$V^{\dagger}$\, in
	\,$X \cdot \left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y$\,
	to be	 \,$(Q^{\dagger})^{T} \cdot Q^{\dagger}$.\,
	In addition, since \,$\Col(X) \subset \Col(V)$,\, we have
	\,$X \,=\, \Pi_{V} \cdot X \,=\, Q \cdot Q^{\dagger} \cdot X$.\,
	Hence,
	\begin{eqnarray*}
	X \cdot \left(\,W_{X,V}\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y
	&=&
		X \cdot \left(\,X^{T} \cdot V^{\dagger} \cdot X\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y
	\\
	&=&
		\left(\,Q \cdot Q^{\dagger} \cdot X\,\right)
		\cdot
		\left(\,X^{T} \cdot (Q^{\dagger})^{T} \overset{{\color{white}\vert}}{\cdot} Q^{\dagger} \cdot X\,\right)^{\dagger}
		\cdot
		X^{T} \cdot (Q^{\dagger})^{T} \cdot Q^{\dagger} \cdot y
	\\
	&=&
		Q \cdot
		\left(\,Q^{\dagger} \cdot X\,\right)
		\cdot
		\left(\,(\,Q^{\dagger} \cdot X\,)^{T} \overset{{\color{white}\vert}}{\cdot} (\,Q^{\dagger} \cdot X\,)\,\right)^{\dagger}
		\cdot
		\left(\,Q^{\dagger} \cdot X\,\right)^{T}
		\cdot
		Q^{\dagger} \cdot y
	\\
	&=&
		Q \cdot
		\left(\,\Pi_{\,Q^{\dagger} \cdot X}\,\right)
		\cdot
		Q^{\dagger} \cdot y
	\end{eqnarray*}
	But now observe that
	\begin{equation*}
	\left(\,Q^{\dagger} \cdot X\,\right)
	\cdot
	\left(\,(\,Q^{\dagger} \cdot X\,)^{T} \overset{{\color{white}\vert}}{\cdot} (\,Q^{\dagger} \cdot X\,)\,\right)^{\dagger}
	\cdot
	\left(\,Q^{\dagger} \cdot X\,\right)^{T}
	\;\; = \;\;
		\Pi_{\,Q^{\dagger} \cdot X}
	\;\; = \;\;
		\proj_{\,\Col(Q^{\dagger} \cdot X)}
	\end{equation*}
	is the orthogonal projection matrix onto the column space
	\,$\Col(\,Q^{\dagger} \cdot X\,)$\, of \,$Q^{\dagger} \cdot X$,\,
	which is independent of the particular choice of the generalized inverse
	\begin{equation*}
	\left(\,(\,Q^{\dagger} \cdot X\,)^{T} \overset{{\color{white}\vert}}{\cdot} (\,Q^{\dagger} \cdot X\,)\,\right)^{\dagger}
	\;\; = \;\;
	\left(\,X^{T} \cdot (Q^{\dagger})^{T} \overset{{\color{white}\vert}}{\cdot} Q^{\dagger} \cdot X\,\right)^{\dagger}
	\;\; = \;\;
	\left(\,X^{T} \overset{{\color{white}\vert}}{\cdot} V^{\dagger} \cdot X\,\right)^{\dagger}
	\;\; = \;\;
	\left(\,W_{X,V}\,\right)^{\dagger}\,.
	\end{equation*}
	This implies that
	\,$X \cdot \left(\,W_{X,V}\,\right)^{\dagger} \cdot X^{T} \cdot V^{\dagger} \cdot y \in \Re^{n \times 1}$\,
	is indeed independent of the particular choice of the generalized inverse
	\,$\left(\,W_{X,V}\,\right)^{\dagger} \in \Re^{p \times p}$\,
	of \,$W_{X,V} \in \Re^{p \times p}$.\,
	This completes the proof of \eqref{XXtVdaggerXXtVdaggerY}.
\item
	As above, let $Q \in \Re^{n \times r}$\, and \,$Q^{\dagger} \in \Re^{r \times n}$\,
	be the matrices determined (non-uniquely) by $V \in \Re^{n \times n}$
	as described in Corollary \ref{corollaryRealSpectralTheorem}.
	Let $\widetilde{X} \,:=\, Q^{\dagger} \cdot X \,\in\, \Re^{r \times p}$.
	For each \,$\beta \in \Re^{p}$,\, let \,$\widetilde{Y}_{\beta} \,:=\, Q^{\dagger} \cdot Y_{\beta}$.
	
	\vskip 0.5cm
	\noindent
	\textbf{Claim 1:}\quad
	$E\!\left[\;\widetilde{Y}_{\beta}\;\right] \; = \; \widetilde{X} \cdot \beta$\,,
	\,and\,
	\,$\Var\!\left(\,\widetilde{Y}_{\beta}\,\right) \; = \; \sigma^{2} \cdot I_{r}$\,,
	for each \,$\beta \in \Re^{p}$.
	\vskip 0.0cm
	\noindent
	Proof of Claim 1:\quad
	$E\!\left[\;\widetilde{Y}_{\beta}\;\right]$
	\,$=$\, $E\!\left[\;Q^{\dagger} \cdot Y_{\beta}\;\right]$
	\,$=$\, $Q^{\dagger} \cdot E\!\left[\;Y_{\beta}\;\right]$
	\,$=$\, $Q^{\dagger} \cdot X \cdot \beta$
	\,$=$\, $\widetilde{X} \cdot \beta$.
	On the other hand,
	\,$\Var\!\left(\,\widetilde{Y}_{\beta}\,\right)$
	\,$=$\, $\Var\!\left(\,Q^{\dagger} \cdot Y_{\beta}\,\right)$
	\,$=$\, $Q^{\dagger} \cdot \Var\!\left(\,Y_{\beta}\,\right) \cdot (Q^{\dagger})^{T}$
	\,$=$\, $Q^{\dagger} \cdot (\sigma^{2} \cdot V) \cdot (Q^{\dagger})^{T}$
	\,$=$\, $\sigma^{2} \cdot Q^{\dagger} \cdot V \cdot (Q^{\dagger})^{T}$
	\,$=$\, $\sigma^{2} \cdot I_{r}$,
	where the last equality follows from
	Corollary \ref{corollaryRealSpectralTheorem} \eqref{QdaggerVQdaggerTransposeEqIr}.
	This proves Claim 1.

	\vskip 0.5cm
	\noindent
	\textbf{Claim 2:}\quad
	$\mathcal{L}_{\,\Pi_{\widetilde{X}}} : \Re^{r} \longrightarrow \Re^{r}$\,
	is a BLUE of 
	\,$\mathcal{L}_{\,\widetilde{X}} : \Re^{p} \longrightarrow \Re^{r}$\,
	in terms of
	\,$\widetilde{Y} \,:=\, \left\{\;\widetilde{Y}_{\beta}\;\right\}$,
	where
	\,$\Pi_{\widetilde{X}}$
	\,$:=$\, $\widetilde{X} \cdot (\,\widetilde{X}^{T} \cdot \widetilde{X}\,)^{\dagger} \cdot \widetilde{X}^{T}$.
	\vskip 0.0cm
	\noindent
	Proof of Claim 2:\quad
	Immediate by the Gauss-Markov Theorem.

	\vskip 0.5cm
	\noindent
	\textbf{Claim 3:}\quad
	$\mathcal{L}_{Q} \circ \mathcal{L}_{\,\Pi_{\widetilde{X}}} : \Re^{r} \longrightarrow \Re^{n}$\,
	is a BLUE of 
	\,$\mathcal{L}_{Q} \circ \mathcal{L}_{\,\widetilde{X}} : \Re^{p} \longrightarrow \Re^{n}$\,
	in terms of
	\,$\widetilde{Y} \,:=\, \left\{\;\widetilde{Y}_{\beta}\;\right\}$.
	\vskip 0.0cm
	\noindent
	Proof of Claim 3:\quad
	Immediate by the Gauss-Markov Theorem.

	\vskip 0.5cm
	\noindent
	$E\!\left[\;\widetilde{Y}_{\beta}\;\right] \; = \; \widetilde{X} \cdot \beta$\,,
	\,and\,
	\,$\Var\!\left(\,\widetilde{Y}_{\beta}\,\right) \; = \; \sigma^{2} \cdot I_{r}$\,,
	for each \,$\beta \in \Re^{p}$.

	$E\!\left[\;Q^{\dagger} \cdot Y_{\beta}\;\right] \; = \; Q^{\dagger} \cdot X \cdot \beta$\,,
	\,and\,
	\,$\Var\!\left(\,Q^{\dagger} \cdot Y_{\beta}\,\right) \; = \; \sigma^{2} \cdot I_{r}$\,,
	for each \,$\beta \in \Re^{p}$.	
\end{enumerate}
This completes the proof of the Theorem.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
