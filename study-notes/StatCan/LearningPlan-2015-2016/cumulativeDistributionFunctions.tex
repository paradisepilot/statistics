
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Cumulative distribution functions}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\begin{definition}\quad
Let $X : \left(\,\Omega,\mathcal{A},\mu\,\right) \longrightarrow \Re$ be a $\Re$-valued random variable.
The \textbf{cumulative distribution function} of $X$ is, by definition, the function
$F_{X} : \Re \longrightarrow [0,1]$ defined as follows:
\begin{equation*}
F_{X}(x) \; := \; P\!\left(\,X \leq x\,\right) \; = \; \mu\!\left(\left\{\,\omega \in \Omega \;\vert\; X(\omega) \leq x \,\right\}\right),
\quad
\textnormal{for each $x \in \Re$}.
\end{equation*}
\end{definition}

\begin{definition}\quad
A function $f : D \subseteq \Re \longrightarrow \Re$ is said to be 
\begin{itemize}
\item	\textbf{non-decreasing} if $f(x) \leq f(y)$, for any $x, y \in D$ with $x \leq y$.
\item	\textbf{non-increasing} if $f(x) \geq f(y)$, for any $x, y \in D$ with $x \leq y$.
\item	\textbf{monotone} if $f$ is either non-decreasing or non-increasing.
\end{itemize}
\end{definition}

\begin{theorem}[Theorem 4.29, \cite{Rudin1976}]
\label{ThmMonotoneFunctions}
\mbox{}\vskip 0.2cm
\noindent
Let $f : (a,b) \subseteq \Re \longrightarrow \Re$ be a non-decreasing function.
Then,
\begin{equation*}
f(x-) := \lim_{t \rightarrow x^{-}} f(t)
\quad\textnormal{and}\quad
f(x+) := \lim_{t \rightarrow x^{+}} f(t)
\end{equation*}
exist for every $x \in (a,b)$.
More precisely,
\begin{equation*}
f(x-)
\; = \; \sup_{a < t < x}\,f(t)
\;\leq\; f(x)
\;\leq\; \inf_{x < t < b}\,f(t)
\;=\; f(x+).
\end{equation*}
Furthermore, if $a < x < y < b$, then
\begin{equation*}
f(x+) \;\;\leq\;\; f(y-).
\end{equation*}
\end{theorem}

\proof
First note that, since $f$ is non-decreasing, it immediately follows that:
\begin{equation*}
\sup_{a < t < x}\,f(t)
\;\leq\; f(x)
\;\leq\; \inf_{x < t < b}\,f(t).
\end{equation*}
Next, we show that $f(x-) := \lim_{t\rightarrow x^{-}}f(t)$ exists and equals $A := \sup_{a<t<x}f(t)$.
Let $\varepsilon > 0$ be given. We need to find $\delta > 0$ such that
\begin{equation*}
\vert\, f(t) - A \,\vert < \varepsilon,
\quad
\textnormal{for every $t \in (x-\delta,x)$}.
\end{equation*}
By definition of the supremum, there exists $\delta > 0$ with $x-\delta \in (a,x)$ such that
\begin{equation*}
A - \varepsilon \;<\; f(x-\delta) \;\leq\; A.
\end{equation*}
Since $f$ is non-decreasing, we have
\begin{equation*}
f(x-\delta) \; \leq \; f(t) \; \leq \; A \, := \, \sup_{\xi\in(x-\delta,x)}f(\xi),
\quad
\textnormal{for every $t \in (x-\delta,x)$}.
\end{equation*}
We therefore see that
\begin{equation*}
\vert\, f(t) - A \,\vert \; < \; \varepsilon,
\end{equation*}
as desired. This proves that $f(x-) := \lim_{t\rightarrow x^{-}}f(t)$ indeed exists and equals $A := \sup_{t\in(a,x)}f(t)$.
The proof that $f(x+)$ exists and equals $\inf_{t\in(x,b)}f(t)$ is analogous.
Lastly, let $a < x < y < b$. Then, choose some $z \in (x,y) = (x,b) \,\bigcap\, (a,y)$.
Hence, we have
\begin{equation*}
f(x+) = \inf_{t\in(x,b)}f(t)
\;\leq\; f(z)
\;\leq\; \sup_{t\in(a,y)}f(t)
\;=\; f(y-).
\end{equation*}
This proof the Theorem is complete.
\qed

\begin{remark}\quad
The analogous results of the preceding Theorem for non-increasing functions hold, obviously.
\end{remark}

\begin{definition}\quad
Let $f : D \subseteq \Re \longrightarrow \Re$.
A point $a \in \textnormal{interior}(D)$ is a \textbf{jump discontinuity} of $f$ if both
\begin{equation*}
\lim_{x \rightarrow a^{-}} f(x)
\quad\textnormal{and}\quad
\lim_{x \rightarrow a^{+}} f(x)
\end{equation*}
exist but they are unequal.
\end{definition}

\begin{corollary}\label{CorollaryMonotoneJumpDiscontinuities}\quad
A monotone $\Re$-valued function defined on an interval of $\Re$ can have only jump discontinuities.
\end{corollary}

\begin{theorem}\label{ThmCharacterizationCDF}\quad
A function $F : \Re \longrightarrow [0,1]$ is a cumulative distribution function of some
$\Re$-valued random variable if and only if each of following four conditions holds:
\begin{itemize}
\item	$F$ is non-decreasing.
\item	$F$ is right-continuous.
\item	$\lim_{x\rightarrow-\infty}F(x) = 0$.
\item	$\lim_{x\rightarrow+\infty}F(x) = 1$.
\end{itemize}
\end{theorem}

\proof
If $F : \Re \longrightarrow [0,1]$ is a cumulative distribution function of some
$\Re$-valued random variable $X : \left(\,\Omega,\mathcal{A},\mu\,\right) \longrightarrow \Re$,
then the four conditions follow immediately from the property of the probability measure $\mu$.
Conversely, suppose the four conditions hold. Let $\Omega := [0,1]$ and $\mathcal{B}(\Omega)$ the Borel subsets of $\Omega$.
Let $\mu$ be the Lebesgue measure on $(\Omega,\mathcal{B}(\Omega))$, i.e. $\mu$ is determined by:
\begin{equation*}
\mu\!\left(\,[0,\omega]\,\right) \; := \; \omega,
\quad
\textnormal{for each $\omega \in \Omega = [0,1]$}.
\end{equation*}
Define the random variable $X : (\Omega,\mathcal{B}(\Omega),\mu) \longrightarrow \Re$ by:
\begin{equation*}
X(\omega) \; := \; \inf \left\{\,x \in \Re \;\vert\; \omega \leq F(x)\,\right\},
\quad
\textnormal{for each $\omega \in \Omega = [0,1]$}.
\end{equation*}
Note that $X$ is simply the quantile function of $F$.
\vskip 0.2cm
\begin{center}
\begin{minipage}{6in}
\noindent
\textbf{Claim:}\;\; Suppose $G : \Re \longrightarrow [0,1]$ is non-decreasing and right-continuous.
Then, for any $\omega \in [0,1]$ and $x \in \Re$,
\begin{equation*}
\inf\left\{\,\xi \in \Re \;\vert\; \omega \leq G(\xi) \,\right\} \leq x
\;\; \Longleftrightarrow \;\;
\omega \leq G(x).
\end{equation*}
Proof of Claim:\;\; Suppose $\omega \leq G(x)$.
Then, $x \in \left\{\,\xi \in \Re \;\vert\; \omega \leq G(\xi) \,\right\}$.
Hence, $\inf\left\{\,\xi \in \Re \;\vert\; \omega \leq G(\xi) \,\right\} \leq x$.
Conversely, suppose $\inf\left\{\,\xi \in \Re \;\vert\; \omega \leq G(\xi) \,\right\} \leq x$.
Since $G$ is non-decreasing and right-continuous, we have:
\begin{eqnarray*}
\inf\left\{\,\xi \in \Re \;\vert\; \omega \leq G(\xi) \,\right\} \leq x
&\Longrightarrow&
\textnormal{for any $\varepsilon > 0$, $\exists \;\; \xi \in \Re$, satisfying $\omega \leq G(\xi)$, such that $\xi \leq x + \varepsilon$}
\\
&\Longrightarrow&
\textnormal{for any $\varepsilon > 0$, $\exists \;\; \xi \in \Re$, satisfying $\omega \leq G(\xi)$ and $G(\xi) \leq G(x + \varepsilon)$}
\\
&\Longrightarrow&
\textnormal{for any $\varepsilon > 0$, $\omega \leq G(x + \varepsilon)$}
\\
&\Longrightarrow&
\omega \;\leq\; \lim_{\varepsilon\rightarrow 0^{+}}G(x + \varepsilon) \;=\; G(x).
\end{eqnarray*}
This completes the proof of the Claim.
\end{minipage}
\end{center}
Noting that, by hypothesis, $F$ is non-decreasing right-continuous, and invoking the Claim above, we see that
\begin{eqnarray*}
P\!\left(\,X \leq x\,\right)
&=& P\!\left(\left\{\,\omega\in\Omega\;\vert\; X(\omega) \leq x\,\right\}\right)
\;\;=\;\; P\!\left(\left\{\,\omega\in\Omega\;\vert\; \inf \left\{\,\xi \in \Re \;\vert\; \omega \leq F(\xi)\,\right\} \leq x\,\right\}\right)
\\
&=& P\!\left(\left\{\,\omega\in\Omega\;\vert\; \omega \leq F(x)\,\right\}\right)
\;\;=\;\; \mu\!\left(\left\{\,\omega\in [0,1] \;\vert\; \omega \leq F(x)\,\right\}\right)
\;\;=\;\; \mu\!\left(\,[0,F(x)]\,\right)
\\
&=& F(x)
\end{eqnarray*}
This shows that if $F$ satisfies the four conditions, then $F$ is the cumulative distribution function of the random variable $X$ constructed above.
The proof of the Theorem is now complete.
\qed

\begin{theorem}[Darboux-Froda, Theorem 4.30, \cite{Rudin1976}]
\label{Thm:DarbouxFroda}
\mbox{}\vskip 0.1cm
\noindent
The set of discontinuities of a monotone $\Re$-valued function defined on an interval of $\Re$ is at most countable.
\end{theorem}

\proof
We give the proof for non-decreasing functions; the proof for non-increasing functions is analogous.
Let $f : (a,b) \longrightarrow \Re$ be non-decreasing, and let $\mathcal{D}(f) \subset (a,b)$ be the
set of discontinuities of $f$.
By Corollary \ref{CorollaryMonotoneJumpDiscontinuities}, each $x \in \mathcal{D}(f)$ is a jump discontinuity of $f$,
i.e. both one-sided limits $\lim_{t\rightarrow x^{-}}f(t)$ and $\lim_{t\rightarrow x^{+}}f(t)$ exist, and
\begin{equation*}
\lim_{t\rightarrow x^{-}}f(t)
\;\;<\;\;
\lim_{t\rightarrow x^{+}}f(t)
\end{equation*}
Thus, for each $x \in \mathcal{D}(f)$, we may choose a rational number $r(x) \in \Q$ such that
\begin{equation*}
\lim_{t\rightarrow x^{-}}f(t)
\;\;<\;\; r(x)
\;\;<\;\; \lim_{t\rightarrow x^{+}}f(t).
\end{equation*}
This defines a function $r : \mathcal{D}(f) \longrightarrow \Q$.
Note that this function is injective.
Indeed, let $x, y \in \mathcal{D}(f)$ with $x < y$.
Then, by Theorem \ref{ThmMonotoneFunctions},
\begin{equation*}
r(x)
\;\;<\;\; \lim_{t\rightarrow x^{+}}f(t)
\;\;=\;\; f(x+)
\;\;\leq\;\; f(y-)
\;\;=\;\; \lim_{t\rightarrow y^{-}}f(t)
\;\;<\;\; r(y)
\end{equation*}
This shows $r : \mathcal{D}(f) \longrightarrow \Q$ is indeed injective.
Since $\Q$ is countable, we may now conclude that $\mathcal{D}(f)$ is at most countable.
\qed

\begin{corollary}\quad
The cumulative distribution function of an $\Re$-valued random variable can have only jump discontinuities,
and its set of (jump) discontinuities is at most countable.
\end{corollary}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
