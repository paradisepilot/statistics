          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Predictive powers of $(X_{1}, \ldots ,X_{5})$ for $Y$, hence for NAPCS}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

To demonstrate directly the predictive powers possessed by the variables
$(X_{1}, \ldots ,X_{5})$ for $Y$ (Retailer A's internal product category code),
and hence for NAPCS itself, we re-ran the training code that ESD used, but
feeding it with a number of different subcollections of features.
For each such subcollection of features, we computed the prediction accuracy of
the respective trained models based on the Retailer A training data set,
the Retailer B testing data set, as well as the Retailer B testing data set.
We report also the respective sizes of the vocabulary.
The following table summarizes the results from these experiments:

\vskip 0.5cm
\begin{center}
\textbf{Accuracy \& Vocabulary Size}
\vskip 0.1cm
\begin{tabular}{|c|c|c|c|c|}
\hline
&&&&\\
& Product & & Product & $Y$ + \\
& Descriptions & $(X_{1}, \ldots ,X_{5})$ & Descriptions & Description \\
& + & Only & Only & of $Y$ \\
& $(X_{1}, \ldots ,X_{5})$ & & & Only \\
&&&&\\
\hline\hline
$\overset{{\color{white}-}}{\underset{{\color{white}-}}{\textnormal{Training (Retailer A)}}}$ &
	99.95\% & 95.98\% & 98.13\% & 99.62\% \\
\hline
$\overset{{\color{white}-}}{\underset{{\color{white}-}}{\textnormal{Testing (Retailer A)}}}$ &
	99.10\% & 94.77\% & 86.96\% & 98.85\% \\
\hline
$\overset{{\color{white}-}}{\underset{{\color{white}-}}{\textnormal{Testing (Retailer B)}}}$ &
	81.33\% & 56.09\% & 75.95\% & 38.21\% \\
\hline
$\overset{{\color{white}-}}{\underset{{\color{white}-}}{\textnormal{Size (Vocabulary)}}}$ &
  202,077 & 6,352 & 192,748 & 1,183 \\
\hline
\end{tabular}
\end{center}

\vskip 0.5cm
\noindent
Explanation of the preceding table:
\begin{itemize}
\item
	First column:\;\;
	These are the replications of ESD's results, where the two variables of
	product textual descriptions as well as $X_{1}, X_{2}, \ldots , X_{5}$
	(Retailer A's product category descriptions) were used as features.

	\vskip 0.1cm
	The accuracy estimates of our replication experiments were noticeably
	lower than those reported in \cite{Hatko20180302}, though only very
	slightly.

	\vskip 0.1cm
	This is probably attributable to a slight modification to the code introduced
	by ESD between the time the results in \cite{Hatko20180302} were generated
	and the time when the code was transferred to Methodology for the purpose
	of the present methodology review.
	This fact was communicated to Methodology by Stan Hatko via e-mail on
	April 9, 2018.

\item
	Second column:\;\;
	Only the product category description variables $(X_{1}, \ldots ,X_{5})$
	were used (in particular, no product-specific descriptions).
	The Retailer A training and testing accuracies remain stunningly high,
	at 95.98\% and 94.77\%, respectively, especially given the very small
	corresponding vocabulary size of 6,352 ($n$-grams).

	\vskip 0.1cm
	However, the trained model now generalizes poorly to Retailer B testing
	data, giving here only an accuracy of 56.09\%. This suggests that, while
	the variables $X_{1}, X_{2}, \ldots , X_{5}$ together might be extremely
	powerful predictors of $Y$ (hence, of NAPCS), they alone may have little
	relevance beyond Retailer A's data.

\item
	Third column:\;\;
	Only the two product textual description variables were used.
	The training accuracy dropped only slightly to 98.13\% (from 99.95\%),
	while the Retailer A testing accuracy dropped more significantly
	to 86.96\% (from 99.10\%).

	\vskip 0.1cm
	The large discrepancy between these two accuracy estimates (both based on
	Retailer A data) suggests some degree of overfitting might be happening,
	now that the highly predictive product category description variables
	$(X_{1}, \ldots ,X_{5})$ have been removed from the set of features.

	\vskip 0.1cm
	The Retailer B testing accuracy dropped to 75.95\% (from 81.33\%).

	\vskip 0.1cm
	Note, however, that the lower Retailer A and Retailer B testing accuracies here
	are still promising. And, they are now more in line with what one would expect
	from common supervised machine learning scenarios, now that the unusually
	predictive variables $(X_{1}, \ldots ,X_{5})$ have been removed.

\item
	Fourth column:\;\;
	This pushes the scenario in the second column to the extreme, namely,
	instead of using the powerful $Y$-predictors $(X_{1}, \ldots ,X_{5})$
	as features for NAPCS prediction, we use $Y$ itself (plus a textual description
	of $Y$) as features. Note how the Retailer A training and testing accuracies
	improve upon those of the second column, while the vocabulary size drops to
	only 1,183. Compare these with the very poor generalization accuracy of
	merely 38.12\% to the Retailer B testing data.

\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
