
%%%%%%%%%%

\begin{frame}{\vskip -0.35cm \large Techniques communes\vskip -0.05cm d'apprentissage automatique supervis\'e}

{\scriptsize
\begin{itemize}
\item
	r\'egression logistique
\item
	voisin le plus proche {\scriptsize (une technique d'imputation)}
\item
	arbres de d\'ecision {\scriptsize (utilis\'ees pour former des groupes homog\`enes de r\'eponse)}
\item
	for\^{e}ts al\'eatoires
\item
	machines \`a vecteurs de support
\item
	r\'eseaux neuronaux artificiels
\end{itemize}}

\large
\begin{center}
\pause
Plusieurs techniques d'apprentissage automatique supervis\'e poss\`edent
une complexit\'e de mod\`ele \'elev\'ee,
\pause ou un espace de param\`etres de grande dimension.
\pause
\vskip 0.05cm
{\normalsize c.-\`a-d.\, \#(observations) \;$\not\gg$\; \#(param\`etres du mod\`ele)}

\vskip 0.4cm
\pause
\textbf{Avertissement:} Elles peuvent \^{e}tre \textit{trop} complexes!

\pause
\vskip 0.4cm
%\begin{center}
\large
\begin{minipage}{4.0cm} \begin{center} complexit\'e du mod\`ele \vskip 0.01cm excessive \end{center} \end{minipage}
\;\;$\leadsto$\;\;
\begin{minipage}{4.5cm} \begin{center} \textbf{\Large\color{red}surapprentissage} \vskip 0.1cm {\scriptsize variance \'elev\'ee \vskip -0.175cm erreur de g\'en\'eralisation importante} \end{center} \end{minipage}
%\end{center}
%Risk:\; \textbf{\color{red}Overfitting}
\end{center}

\end{frame}
\normalsize

%%%%%%%%%%
