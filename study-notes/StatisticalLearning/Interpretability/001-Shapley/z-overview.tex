
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Overview}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{itemize}
\item
	Background (interpretability of linear models):
	
	Linear models have the following form:
	\begin{equation*}
	f(\,x\,;\,\beta\,)
	\;\; = \;\;
		f(\,x_{1},\ldots,x_{p}\,;\,\beta_{0},\beta_{1},\ldots,\beta_{p}\,)
	\;\; = \;\;
		\beta_{0} \,+\, \beta_{1}\cdot x_{1} \,+\, \cdots \,+\, \beta_{p}\cdot x_{p}
	\end{equation*}
	Linear models are deemed ``interpretable'' in at least two ways:
	\begin{enumerate}
	\item
		\label{additiveModelDecomposition}
		The quantity
		\,$\left(\,f(x;\beta) \overset{{\color{white}.}}{-} \beta_{0}\,\right)$\,
		--- the prediction made by the model $f$ on the unlabelled observation $x$
		minus the intercept term $\beta_{0}$ --- is a sum of $p$ summands,
		with each summand $\beta_{i}\cdot x_{i}$ being interpreted as the contribution to 
		\,$\left(\,f(x;\beta) \overset{{\color{white}.}}{-} \beta_{0}\,\right)$\,
		due to the $i^{\textnormal{th}}$ predictor variable, for $i = 1,\ldots,p$.
	\item
		\label{beteInterpretability}
		$\beta_{0} = f(\,0,\ldots,0\,;\,\beta\,)$ is the prediction by $f$ on $x = (0,\ldots,0)$,
		while each $\beta_{i}$ can be interpreted as the change in $f(\,x\,;\,\beta\,)$
		caused by each unit change in $x_{i}$, for $i = 1,\ldots,p$.
	\end{enumerate}
\item
	What about nonlinear models?
	
	For a model $f(\,x\,;\,\beta\,)$ nonlinear in $\beta$, interpretability in the sense of
	\eqref{beteInterpretability} above is obviously highly nontrivial, if not impossible.
	
	But, it begs the question: Even for nonlinear models, can \eqref{additiveModelDecomposition}
	be achieved in some (satisfying/useful) sense?

\item
	An example of using the Shapley decomposition to achieve \eqref{additiveModelDecomposition}
	for arbitrary models (including nonlinear models):
	
	\v{S}trumbelj-Kononenko \cite{Strumbelj2010}
	introduced a method to {\color{red}explain individual predictions}:
	\begin{itemize}
	\item
		Given a trained prediction model $f(X_{1},\ldots,X_{p})$
		based on a set of predictor variables $(X_{1},\ldots,X_{p})$, and
		an unlabelled observation $x = (x_{1},\ldots,x_{p})$,
		\v{S}trumbelj-Kononenko \cite{Strumbelj2010} shows that
		one can assign a ``contribution score'' $R_{i}(x;f)$
		to each predictor variable $X_{i}$
		such that the following equality holds:
		\begin{equation*}
		f(x) \, - \, A_{0}(f)
		\;\; = \;\;
			\overset{p}{\underset{i=1}{\sum}}\;
			R_{i}(x;f)\,,
		\end{equation*}
		where $A_{0}(f)$ is the average of the predictions by $f$
		over all possible combinations of predictor values.

		\vskip 0.2cm
		\textbf{Thus, the contribution score $R_{i}(x;f)$ can be interpreted
		as the ``{\color{red}contribution}'' to the quantity \,$\left(\,f(x) - A_{0}(f)\,\right)$\,
		 --- the prediction made by $f$ on $x$ minus the average prediction of $f$ ---
		due to the $i^{\textnormal{th}}$ predictor value $X_{i} = x_{i}$,
		in relation to all the other predictor values
		$X_{1} = x_{1}$, \,$\ldots$\;, $X_{p} = x_{p}$.}
		\vskip 0.2cm
		
	\item
		The $i^{\textnormal{th}}$ contribution score $R_{i}(x;f)$ above
		turns out to be the $i^{\textnormal{th}}$ {\color{red}Shapley value} of
		a certain {\color{red}Shapley decomposition}.
		See Definition \eqref{definition:ShapleyDecomposition}.
	\end{itemize}

\item
	The Shapley decomposition is a notion
	in game theory\footnote{more precisely, cooperative game theory, a.k.a. coalitional game theory}
	first introduced in \cite{Shapley1953}.
	Its underlying intuitive idea is as follows:

	Suppose:
	\begin{itemize}
	\item
		$U$ is a finite population of ``players''.
	\item
		A \textit{coalition} is a subset of players from $U$.
		(Think: a coalition is just a team of players chosen from $U$.)
	\item
		There is a (coalition-level) \textit{score} assigned to every possible coalition
		and the score of the ``empty coalition'' (the coalition with zero players) is zero.
	\end{itemize}
	
	The objective of the Shapley decomposition is to ``distribute'' the population score
	(the coalition-level score for the whole population of players)
	to each of the individual players such that
	\begin{itemize}
	\item
		the individual scores always simply just {\color{red}add back up} to the population score, and
	\item
		all the (possibly extremely complicated) {\color{red}interactions}
		among the players are taken into account.
	\end{itemize}
	
	Shapley proves in \cite{Shapley1953} the following (rather remarkable) result:
	If we insist that the Shapley decomposition should possess
	certain ``natural/desirable'' properties
	(see Definition \ref{definition:ShapleyDecomposition}),
	then, given any coalition-level score, its Shapley decomposition exists and is unique
	(or, intuitively speaking, there is {\color{red}one and only one} way to distribute
	the population score to the individual players in a ``natural'' manner).
	See Theorem \ref{theorem:ShapleyDecompositionExistenceUniqueness}
	(for the existence, uniqueness, and explicit formula of the Shapley decomposition).

	The explicit formula in
	Theorem \ref{theorem:ShapleyDecompositionExistenceUniqueness}
	shows that the Shapley decomposition takes into account
	the interactions among all players by,
	for each given player, {\color{red}suitably averaging} his/her {\color{red}marginal scores}
	over all possible coalitions containing that given player
	(in other words, the Shapley decomposition does this by very clever bookkeeping).

\item
	We now give an outline of \v{S}trumbelj-Kononenko \cite{Strumbelj2010}:

	\begin{itemize}
	\item
		\v{S}trumbelj-Kononenko \cite{Strumbelj2010} applies
		the Shapley decomposition %to these choices of $U$ and $\nu(S;x,f)$ 
		to define their contribution scores $R_{i}(x,f)$.
		
		More precisely, \v{S}trumbelj-Kononenko \cite{Strumbelj2010}
		chooses the population $U$ of players to be the set of features (predictor variables),
		i.e. $U = \{X_{1},\ldots,X_{p}\}$.
		A coalition is thus a (sub-)selection $S$ of features from $U$.
		By Theorem \ref{theorem:ShapleyDecompositionExistenceUniqueness},
		the Shapley decomposition $\varphi$ on $U$ exists and is unique.

		It now remains only to choose a suitable coalition-level score $\nu(S;x,f)$.
		Once that choice is made, we can define the $i^{\textnormal{th}}$ contribution score
		$R_{i}(x;f)$ simply to be the $i^{\textnormal{th}}$ Shapely value of
		$\varphi\left(\,\nu(\,\cdot\,;\,x,f)\,\right)$.

	\item
		Choice of coalition-level score $\nu(S;x,f)$:
		
		In \cite{Strumbelj2010},
		each feature is assumed to be a categorical variable
		with finitely many levels;
		in particular, the entire feature space is finite.

		
		The coalition-level score $\nu(S;x,f)$ is chosen to be the difference
		$A(S;x,f) - A_{0}(f)$
		of two averages of predictions, where $A_{0}(f)$ is as before
		the average of the predictions by $f$ over all possible combinations of feature values,
		while $A(S;x,f)$ is the average of the predictions by $f$ over only those combinations
		$(z_{1},\ldots,z_{p})$ such that $z_{i} = x_{i}$ for each $i \in S$.
		%\v{S}trumbelj-Kononenko \cite{Strumbelj2010} applies
		%the Shapley decomposition to these choices of $U$ and $\nu(S;x,f)$ 
		%in order to obtain their contribution scores $R_{i}(x,f)$.
		%See \cite{Strumbelj2010} for precise mathematical formulation.

	\item
		For completeness, we show the definition of $\nu(S;f,x)$ here:
		\begin{equation*}
		\nu(S;f,x)
		\;\; := \;\;
			\dfrac{1}{{\color{white}.}\vert\,\mathcal{F_{\,U\,\backslash S}}\,\vert{\color{white}.}}
			\cdot
			\underset{\xi\,\in\,\mathcal{F}_{U \backslash S}}{\sum}f(\tau(x,\xi;S))
			\; - \;
			\dfrac{1}{{\color{white}.}\vert\,\mathcal{F}\,\vert{\color{white}.}}
			\cdot
			\underset{\xi \in \mathcal{F}}{\sum}\;f(y)
		\end{equation*}
		where $\mathcal{F}$ is the feature space, and
		\begin{equation*}
		\tau(x,\xi;S) \;\; = \;\; (z_{1},\ldots,z_{p})\,,
		\quad\quad
		z_{i}
		\; = \;
			\left\{\begin{array}{cl}
			x_{i}, & i \in S
			\\
			\xi_{i}, & i \notin S
			\end{array}\right.
		\end{equation*}
		However, we omit the definition of $\mathcal{F}_{U\,\backslash S}$ above and
		refer the reader to \cite{Strumbelj2010} for full mathematical details.

	\item
		The explicit formula in
		Theorem \ref{theorem:ShapleyDecompositionExistenceUniqueness}
		reveals that a straightforward implementation of the Shapley decomposition
		requires exponential computation time.
		One of the main contributions in \cite{Strumbelj2010} is
		an effective and efficient procedure to approximate
		the Shapley decomposition in the given context.

	\item
		The {\color{red}R package} 
		\texttt{iml} \cite{Molnar2018} %(\texttt{https://CRAN.R-project.org/package=iml})
		provides implementations for a number of interpretability methods,
		including that of \v{S}trumbelj-Kononenko \cite{Strumbelj2010}.

	\end{itemize}

\item
	There are, of course, variations to the interpretability method described in \cite{Strumbelj2010};
	see for example, \cite{Lipovestsky2001} and \cite{Lundberg2017}. 

\item
	For a more comprehensive discussion on interpretable machine learning
	(including approaches other than those based on the Shapley decomposition),
	see the {\color{red}online book} \cite{Molnar2019}.

\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
