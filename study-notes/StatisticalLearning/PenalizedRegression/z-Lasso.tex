
\section{Lasso (Least Absolute Shrinkage and Selection Operator)}
\setcounter{theorem}{0}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.3cm
\subsection{Lasso -- general formulation}
\vskip 0.0cm
\noindent
Suppose that
\,$Y = (y_{1},\ldots,y_{n})^{T} \in \Re^{n}$,\,
\,$X = \left(\,\overset{{\color{white}-}}{x_{ij}}\,\right)\in\Re^{n \times p}$\, and
\,$\tau > 0$.\,
The \textbf{Lasso estimator} is given by:
\begin{equation*}
\widehat{Y}^{\textnormal{(Lasso)}}
\;\; := \;\;
	X \cdot \widehat{\beta}^{\,\textnormal{(Lasso)}}\,,
\end{equation*}
where
\begin{eqnarray*}
\widehat{\beta}^{\,\textnormal{(Lasso)}}
& \in &
	\underset{(\beta_{0},\beta)\,\in\,\Re\times\Re^{p}}{\argmin}\;
	\left\{\;\;
		\left.
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} \beta_{0}\cdot\mathbf{1}_{n} - X\cdot\beta \,\;\right\Vert_{2}^{2}
		\;\;\,\right\vert\;\;
		\Vert\;\beta\,\Vert_{1} \, - \, \tau \, \leq \, 0
		\;\;\right\}
\\
& = &
	\underset{(\beta_{0},\beta)\,\in\,\Re\times\Re^{p}}{\argmin}\;
	\left\{\;\;
		\left.
		\dfrac{1}{2}
		\cdot
		\overset{n}{\underset{i=1}{\sum}}
		\left(\; y_{i} - \beta_{0} - \overset{p}{\underset{j=1}{\sum}}\; x_{ij}\cdot\beta_{j}\,\right)^{2}
		\;\;\,\right\vert\;\;
		\overset{p}{\underset{j=1}{\sum}}\;
		\vert\;\beta_{j}\,\vert
		\, - \,
		\tau \, \leq \, 0
		\;\;\right\}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\subsection{Lasso -- with centered variables and without intercept term}
\vskip 0.0cm
\noindent
By Theorem \ref{CanCenterAndRemoveIntercept}, upon centering variables if necessary,
we may assume \,$y \,\in\, \Re^{n}$\, and
\,$X \,=\, \left(\,\overset{{\color{white}-}}{x_{ij}}\,\right) \,\in\, \Re^{n \times p}$\,
satisfy
\begin{equation*}
\overset{n}{\underset{i=1}{\sum}}\;y_{i} \; = \; 0\,,
\quad\textnormal{and}\quad\quad
\overset{n}{\underset{i=1}{\sum}}\;x_{ij} \; = \; 0\,,
\;\;
\textnormal{for each \,$j = 1,\ldots,p$}
\end{equation*}
The Lasso optimization then becomes:
\begin{equation}
\label{PrimalLassoCenteredVariablesNoIntercept}
	\underset{\beta\,\in\,\Re^{p}}{\argmin}
	\left\{\;\;
		\left.
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\;\;\,\right\vert\;\;
		\Vert\;\beta\,\Vert_{1} \, - \, \tau \, \leq \, 0
		\;\;\right\}
\end{equation}
\textbf{Observations}
\begin{itemize}
\item
	The minimization problem \eqref{PrimalLassoCenteredVariablesNoIntercept}
	has a compact domain and continuous objective function.
	Hence, the infimum of its objective function over its domain is finite,
	and the infimum value is attained at some point(s) in its domain.
\item
	The collection of least-squares solutions of the corresponding unconstrained problem is
	\begin{eqnarray*}
	\mathcal{LS}(X,y)
	& := &
		\underset{\beta\,\in\,\Re^{p}}{\argmin}
		\left\{\;\;
			\dfrac{1}{2}
			\cdot
			\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
			\;\;\right\}
	\\
	& = &
		\left\{\;
			\left.
			\overset{{\color{white}.}}{\beta} \in \Re^{p}
			\;\;\right\vert\;
			X^{T} \cdot (\,y - X\cdot\beta\,) \,=\, 0
			\,\;\right\}
		\;\; = \;\;
		\left\{\;
			\left.
			\overset{{\color{white}.}}{\beta} \in \Re^{p}
			\;\;\right\vert\;
			X^{T} \cdot X \cdot \beta \, = \, X^{T} \cdot y
			\,\;\right\}
	\end{eqnarray*}
\item
	Consider the case where \,{\color{red}$p \,>\, n$}.
	
	\vskip 0.2cm
	The unconstrained least-squares solution is then non-unique;
	in other words, \,$\mathcal{LS}(X,y)$\, contains more than one element.

	\vskip 0.2cm
	Recall that
	\,$\ker(X^{T} \cdot X) \,=\, \ker(X)$.\,
	Indeed, it is immediate that
	\,$\ker(X) \,\subset\, \ker(X^{T} \cdot X)$.\,
	Conversely, \,$v \,\in\, \ker(X^{T} \cdot X)$\,
	\,$\Longleftrightarrow$\, \,$X^{T} \cdot X \cdot v \,=\, 0$\,
	\,$\Longrightarrow$\, \,$\Vert\,X \cdot v\,\Vert^{2} \,=\, v^{T} \cdot X^{T} \cdot X \cdot v \,=\, 0$\,
	\,$\Longrightarrow$\, \,$X \cdot v \,=\, 0$,\,
	i.e. \,$v \in \ker(X)$.
	This proves the reverse inclusion that
	\,$\ker(X^{T} \cdot X) \subset \ker(X)$.

	\vskip 0.2cm
	Next, note that
	\begin{equation*}
	\mathcal{LS}(X,y)
	\;\; = \;\;
		\beta^{*} \,+\, \ker(X^{T}\cdot X)
	\;\; = \;\;
		\beta^{*} \,+\, \ker(X),
	\quad
	\textnormal{for each \,$\beta^{*} \,\in\, \mathcal{LS}(X,y)$}
	\end{equation*}
	We thus see that
	\,{\color{red}$\mathcal{LS}(X,y) \,\subset\, \Re^{p}$\,
	is a translate of the subspace
	\,$\ker(X) \,\subset\, \Re^{p}$.}
	
\item
	Consider still the case where \,{\color{red}$p \,>\, n$}.
	
	\vskip 0.2cm
	Define:
	\begin{equation*}
	\tau_{0}
	\;\; := \;\;
		\underset{\beta\,\in\,\mathcal{LS}(X,y)}{\min}
		\left\{\;
			\Vert\; \overset{{\color{white}.}}{\beta} \;\Vert_{1}
			\;\right\}
	\;\; = \;\;
		\underset{\beta\,\in\,\ker(X)}{\min}
		\left\{\;
			\Vert\; \beta^{*} + \overset{{\color{white}.}}{\beta} \;\Vert_{1}
			\;\right\},
	\end{equation*}
	where \,$\beta^{*}$\, is an arbitrary element of \,$\mathcal{LS}(X,y)$.
	
	\vskip 0.2cm
	We see that, for \,$\tau \,\geq\, \tau_{0}$,\, the minimization problem
	\,\eqref{PrimalLassoCenteredVariablesNoIntercept}\,
	is equivalent to its unconstrained counterpart.

	\vskip 0.2cm
	On the other hand, for \,$\tau \,<\, \tau_{0}$,\, each solution of the minimization problem
	\,\eqref{PrimalLassoCenteredVariablesNoIntercept}\,
	must lie on the boundary of its domain,
	since \,$\tau \,<\, \tau_{0}$\, implies that
	all critical points of the objective function lie strictly outside
	of the domain of \,\eqref{PrimalLassoCenteredVariablesNoIntercept}.
	In other words,
	{\color{red}\begin{equation*}
	\tau \,<\, \tau_{0}
	\quad\Longrightarrow\quad
		\underset{\beta\,\in\,\Re^{p}}{\argmin}
		\left\{\;\,
			\left.
			\dfrac{1}{2}
			\cdot
			\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
			\;\;\,\right\vert\;\;
			\Vert\;\beta\,\Vert_{1} \, - \, \tau \, \leq \, 0
			\,\;\right\}
		\;\;\textnormal{\large$\subset$}\;\;
		\left\{\;
			\left.
			\overset{{\color{white}1}}{\beta} \in \Re^{p}
			\;\,\right\vert\;\,
			\Vert\;\beta\,\Vert_{1} \, = \, \tau
			\;\right\}
	\end{equation*}}
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{Dual Problem of the Lasso with centered variables and without intercept term}
\vskip 0.0cm
\noindent
By standard nonlinear programming duality theory, the Dual Problem
of \eqref{PrimalLassoCenteredVariablesNoIntercept} is:
\begin{equation}
\label{DualLassoCenteredVariablesNoIntercept}
	\underset{\lambda\,\geq\,0}{\argmax}\,
	\left\{\;
		\underset{\beta\,\in\,\Re^{p}}{\inf}\,
		\left\{\;\,
			\dfrac{1}{2}
			\cdot
			\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
			\; + \,
			\lambda
			\cdot
			\left(\, \Vert\;\beta\,\Vert_{1} \, \overset{{\color{white}.}}{-} \, \tau \,\right)
			\,\right\}
		\;\right\}
\end{equation}
Observe that
\begin{eqnarray*}
&&
	\underset{\beta\,\in\,\Re^{p}}{\inf}
	\left\{\;\;
		\left.
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\;\;\,\right\vert\;\;
		\Vert\;\beta\,\Vert_{1} \, - \, \tau \, \leq \, 0
		\;\;\right\}
\\
& = &
	\underset{\beta\,\in\,\Re^{p}}{\inf}
	\left\{\;
		\underset{\lambda\,\geq\,0}{\sup}\,
		\left\{\;\,
			\dfrac{1}{2}
			\cdot
			\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
			\; + \,
			\lambda
			\cdot
			\left(\, \Vert\;\beta\,\Vert_{1} \, \overset{{\color{white}.}}{-} \, \tau \,\right)
			\,\right\}
		\;\right\}
\\
& \geq &
	\underset{\lambda\,\geq\,0}{\sup}\,
	\left\{\;
		\underset{\beta\,\in\,\Re^{p}}{\inf}\,
		\left\{\;\,
			\dfrac{1}{2}
			\cdot
			\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
			\; + \,
			\lambda
			\cdot
			\left(\, \Vert\;\beta\,\Vert_{1} \, \overset{{\color{white}.}}{-} \, \tau \,\right)
			\,\right\}
		\;\right\},
	\quad
	\textnormal{by Weak Duality}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{theorem}[Strong Duality holds for the Lasso]
\label{LassoStrongDuality}
\mbox{}
\vskip 0.1cm
\noindent
Strong Duality holds for \eqref{PrimalLassoCenteredVariablesNoIntercept}
and there exists at least one geometric multiplier.
\end{theorem}
\proof
First, note:
\begin{itemize}
\item
	As mentioned previously, the minimization problem \eqref{PrimalLassoCenteredVariablesNoIntercept}
	has a continuous objection function and a compact domain.
	Hence, the infimum of its objective function over its domain is finite,
	and the infimum value is attained at some point(s) in the domain.
\item
	The domain of the objective function of \eqref{PrimalLassoCenteredVariablesNoIntercept},
	\,$\Re^{p} \,\longrightarrow\, \Re$
	$:$
	$\beta \,\longmapsto\, \dfrac{1}{2}\cdot\left\Vert\;\,y \overset{{\color{white}.}}{-} X\cdot\beta\;\right\Vert^{2}_{2}$\;,\;
	is all of \,$\Re^{p}$,\, which is a convex set.
	And, the objective function is a convex function on \,$\Re^{p}$.
\item
	The single constraint function
	\,$g : \Re^{p} \longrightarrow \Re$,\,
	\,$g(\beta) \,:=\, \Vert\;\beta\;\Vert_{1} - \tau$\,
	is convex.
\item
	Since \,$\tau \,>\, 0$,\, there exists some \,$\beta \,\in\, \Re^{p}$\, such that
	\begin{equation*}
	g(\beta)
	\;\; := \;\;
		\Vert\;\overset{{\color{white}.}}{\beta} \;\Vert_{1} \, - \, \tau
	\;\; < \;\; 0
	\end{equation*}
\end{itemize}
By Proposition 5.3.1, p.520, \cite{Bertsekas1999}, we conclude that
\begin{itemize}
\item
	Strong Duality holds (i.e. the Duality Gap is zero), and
\item
	there exists at least one geometric multiplier.
\end{itemize}
This completes the proof of the Theorem.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{Observations (equivalence of the constrained and penalized forms of the Lasso)}
\mbox{}
\vskip 0.2cm
\noindent
Define the Lagrangian function
\,$L : \Re^{p} \times [\,0,\infty) \longrightarrow \Re$\,
as follows:
\begin{equation*}
L(\beta,\lambda)
\;\; := \;\;
	\dfrac{1}{2}
	\cdot
	\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
	\; + \,
	\lambda\cdot\left(\,\Vert\,\beta\,\Vert_{1} \overset{{\color{white}.}}{-} \tau\,\right)
\end{equation*}
By Theorem \ref{LassoStrongDuality} (Strong Duality and existence of geometric multipliers)
and the Saddle Point Theorem (Proposition 5.1.6, p.499, \cite{Bertsekas1999}),
we have:
\begin{equation*}
\overset{{\color{white}1}}{\underset{\lambda\,\geq\,0}{\sup}\; L(\beta^{*},\lambda)}
\;\; = \;\;
	L(\beta^{*},\lambda^{*})
\;\; = \;\;
	\underset{\beta\,\in\,\Re^{p}}{\inf}\; L(\beta,\lambda^{*})\,,
\end{equation*}
for each (Primal Solution, Geometric Multiplier) pair \,$(\beta^{*},\lambda^{*})$.
It follows that
\begin{eqnarray*}
&&
	{\color{red}\underset{\beta\,\in\,\Re^{p}}{\inf}
	\left\{\;\;
		\left.
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\;\;\,\right\vert\;\;
		\Vert\;\beta\,\Vert_{1} \, - \, \tau \, \leq \, 0
		\;\;\right\}}
\;\; = \;\;
	\underset{\beta\,\in\,\Re^{p}}{\inf}
	\left\{\;
		\underset{\lambda\,\geq\,0}{\sup}\; L(\beta,\lambda)
		\;\right\}
\\
& = &
	\overset{{\color{white}1}}{\underset{\lambda\,\geq\,0}{\sup}\; L(\beta^{*},\lambda)}
	\;\; = \;\;
		L(\beta^{*},\lambda^{*})
	\;\; = \;\;
		\underset{\beta\,\in\,\Re^{p}}{\inf}\; L(\beta,\lambda^{*})
\\
& = &
	\underset{\beta\,\in\,\Re^{p}}{\inf}\,
	\left\{\;\,
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\; + \,
		\lambda^{*}
		\cdot
		\left(\, \Vert\;\beta\,\Vert_{1} \, \overset{{\color{white}.}}{-} \, \tau \,\right) \,\right\}
\\
& = &
	-\,\lambda^{*}\cdot\tau
	\; + \,
	{\color{red}\underset{\beta\,\in\,\Re^{p}}{\inf}\,
	\left\{\;\,
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\; + \,
		\lambda^{*} \cdot \Vert\;\beta\,\Vert_{1} 
		\,\right\}}
\end{eqnarray*}
In particular, we see that,
for each (Primal Solution, Geometric Multiplier) pair \,$(\beta^{*},\lambda^{*})$,
we have
\begin{equation*}
\beta^{*}
\;\; \in \;\;
	\underset{\beta\,\in\,\Re^{p}}{\argmin}
	\left\{\;
		\left.
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\;\;\,\right\vert\;\,
		\Vert\;\beta\,\Vert_{1} \, - \, {\color{red}\tau} \, \leq \, 0
		\;\right\}
	\;\,\bigcap\;\;
	\underset{\beta\,\in\,\Re^{p}}{\argmin}\,
	\left\{\;\,
		\dfrac{1}{2}
		\cdot
		\left\Vert\;\, y \overset{{\color{white}.}}{-} X\cdot\beta \;\right\Vert_{2}^{2}
		\; + \,
		{\color{red}\lambda^{*}} \cdot \Vert\;\beta\,\Vert_{1} 
		\,\right\}
\end{equation*}


          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
