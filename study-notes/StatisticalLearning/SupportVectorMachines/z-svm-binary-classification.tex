
\section{Support Vector Machines for Binary Classification}
\setcounter{theorem}{0}

\vskip 0.3cm
\noindent
\textbf{Reminder:}
\begin{itemize}
\item  Let $\mathbf{n}, \mathbf{z} \in \Re^{d}$, with $\mathbf{n} \neq \mathbf{0}$, be given.
          The hyperplane $H_{\mathbf{n},\mathbf{z}} \subset \Re^{d}$ with normal vector $\mathbf{n}$ and
          containing the point $\mathbf{z}$ is given by: 
          \begin{eqnarray*}
          H_{\mathbf{n},\mathbf{z}}
          & := &
          \left\{\;
          	\left.
          	\mathbf{x}\overset{{\color{white}1}}{\in}\Re^{d}
		\;\;\right\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\mathbf{n}\,\right\rangle = 0
			\;\right\}
	\;\; = \;\;
	\left\{\;
		\mathbf{x}\in\Re^{d}
		\;\left\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\frac{\mathbf{n}}{\Vert\,\mathbf{n}\,\Vert}\,\right\rangle = 0
			\right.\;\right\}
	\\
	& = &
	\left\{\;
		\left.
		\mathbf{x}\overset{{\color{white}.}}{\in}\Re^{d}
		\;\;\right\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\widehat{\mathbf{n}}\,\right\rangle = 0
		\;\right\}
	\end{eqnarray*}
	
\item
	Note that $H_{\mathbf{n},\mathbf{z}} = H_{\alpha\mathbf{n},\mathbf{z}}$, for any $\alpha \neq 0$.
\item
	Let $\mathbf{x} \in \Re^{d}$.  The distance between $\mathbf{x}$ and the hyperplane $H_{\mathbf{n},\mathbf{z}}$
	is given by:
	\begin{equation*}
	\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right)
	\;\; = \;\;
		\left\vert
		\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\dfrac{\mathbf{n}}{\Vert\mathbf{n}\Vert}\,\right\rangle
		\right\vert
	\;\; = \;\;
		\dfrac{1}{{\color{white}.}\Vert\,\mathbf{n}\,\Vert{\color{white}.}}
		\cdot
		\left\vert
		\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\overset{{\color{white}.}}{\mathbf{n}}\,\right\rangle
		\right\vert
	\end{equation*}
	%This implies:
	%\begin{equation*}
	%\Vert\,\mathbf{n}\,\Vert
	%\cdot\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right) \;\; = \;\;
	%\left\vert\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\mathbf{n}\,\right\rangle\right\vert
	%\end{equation*}
\item
	Note that
	$\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right)$ is well-defined,
	i.e. it depends only on the point $\mathbf{x}$ and the hyperplane
	$H_{\mathbf{n},\mathbf{z}}$, and is indeed independent of the particular choice
	of the normal vector $\mathbf{n}$ and the point
	$\mathbf{z} \in H_{\mathbf{n},\mathbf{z}}$. 
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.3cm
\noindent
\textbf{Linearly separable data}
\vskip 0.1cm
\noindent
A data set
\begin{equation*}
\mathcal{D}
\;\; = \;\;
	\left\{\,
		(\overset{{\color{white}-}}{\mathbf{x}}_{1},y_{1})\,,\,(\mathbf{x}_{2},y_{2})\,,\,\ldots\,,\,(\mathbf{x}_{m},y_{m})
		\,\right\},
\quad\quad
\mathbf{x}_{i} \in \Re^{d},
\quad\quad
y_{i} \in \{\,-1,\,1\,\}
\end{equation*}
is said to be \textit{linearly separable} if
\begin{equation*}
	\left\{\;\;
		(\mathbf{n},\mathbf{z}) \in \Re^{d} \times \Re^{d}
		\;\;\left\vert
		\begin{array}{c}
			\textnormal{$H_{\mathbf{n},\mathbf{z}}$ is a}
			\\
			\textnormal{separating hyperplane}
			\\
			\textnormal{for $(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$}
			\end{array}
			\right.
		\!\right\}
\;\; = \;\;
	\left\{\;
		(\mathbf{n},\mathbf{z}) \in \Re^{d} \times \Re^{d}
		\;\;\left\vert
		\begin{array}{c}
			y_{i}\cdot\langle\,\mathbf{x}_{i} - \mathbf{z}\,,\,\mathbf{n}\,\rangle > 0\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\;\; \neq \;\;
	\varemptyset
\end{equation*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Primal Problem of the linearly separable case:}
\begin{eqnarray*}
&&
	\argmax
	\left\{\;
		{\color{white}........1}
		\underset{1\leq i \leq m}{\min}\left\{\,\dist(\,\mathbf{x}_{i}\overset{{\color{white}1}}{,}H_{\mathbf{n},\mathbf{z}}\,)\,\right\}
		{\color{white}........}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			\textnormal{$H_{\mathbf{n},\mathbf{z}}$ is a separating hyperplane}
			\;
			\textnormal{for $(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}.......1}\!
		\underset{1\leq i \leq m}{\min}\left\{\,
			\dfrac{
				\vert\,\langle\,\mathbf{x}_{i}-\mathbf{z}\,,\,\mathbf{n}\,\rangle\,\vert
				}{
				\Vert\,\mathbf{n}\,\Vert
				}
			\,\right\}
		{\color{white}.......}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			y_{i}\cdot\langle\,\mathbf{x}_{i} - \mathbf{z}\,,\,\mathbf{n}\,\rangle > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}...}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			\left\vert\,\langle\,\mathbf{x}_{i}\overset{{\color{white}.}}{-}\mathbf{z}\,,\,\mathbf{n}\,\rangle\,\right\vert
			\,\right\}
		{\color{white}...}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			y_{i}\cdot\left(\langle\,\mathbf{x}_{i}\,,\,\mathbf{n}\,\rangle - \langle\,\mathbf{z}\,,\,\mathbf{n}\,\rangle\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}....}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			\left\vert\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} {\color{red}b}\,\right\vert
			\,\right\}
		{\color{white}...}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; {\color{red}b \in \Re}
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
			\,\right\}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
			\,\right\}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\\
			{\color{red}\underset{1\leq i \leq m}{\min}\left\{\,
				y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
				\,\right\}
				\; = \; 1}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;\;\,
		{\color{white}..}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		{\color{white}...}
		\;\;\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\\
			y_{i}\overset{{\color{white}.}}{\cdot}\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right)\,{\color{red}\geq}\,1\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;\;\,
		{\color{white}...}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		{\color{white}...}\!
		\;\;\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	{\color{red}\argmin}\,
	\left\{\;\;\,
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Primal Problem of the linearly non-separable case:}
\begin{eqnarray*}
	\argmin
	\left\{\;\;
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		+
		\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
		\;\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d} \,,\;\, b \in \Re \,,\;\, \xi \in \Re^{m}
			\\
			\xi_{i} \geq 0,\;\,\textnormal{and}\;\, y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1 - \xi_{i}\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Dual Problem of the linearly non-separable case:}
\vskip 0.1cm
\noindent
First, the Lagrangian function of the Primal Problem is given by
\begin{equation*}
L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)
\;\; := \;\;
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\,
		\alpha_{i}
		\cdot
		\left(\,
			1 - \xi_{i}
			-
			y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
				\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
				\,\right)
			\,\right)
	\; - \;
	\overset{m}{\underset{i = 1}{\sum}}\;
		\beta_{i}
		\cdot
		\xi_{i}
\end{equation*}
The corresponding Dual Problem is given by the right-hand-side of the following:
\begin{eqnarray*}
&&
	\inf
	\left\{\;\;
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		+
		\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
		\;\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d} \,,\;\, b \in \Re \,,\;\, \xi \in \Re^{m}
			\\
			\xi_{i} \geq 0,\;\,\textnormal{and}\;\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1 - \xi_{i}\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\underset{\alpha,\,\beta\,\in\,\Re_{\geq 0}^{m}}{\sup}
	\left\{\;
		\underset{(\mathbf{n},b,\xi)\,\in\,\Re^{d}\times\Re\times\Re^{m}}{\inf}\;\;
		L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)
		\right\},
	\quad
	\textnormal{by Strong Duality}
\\
& = &
	\underset{\alpha,\,\beta\,\in\,\Re_{\geq 0}^{m}}{\sup}
	\left\{\;
		\underset{(\mathbf{n},b,\xi)\,\in\,\Re^{d}\times\Re\times\Re^{m}}{\inf}\;
		\left\{\;
			\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
			\; + \;
			\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
			\; + \;
			\overset{m}{\underset{i = 1}{\sum}}\;\,
				\alpha_{i}
				\cdot
				\left(\,
					1 - \xi_{i}
					-
					y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
						\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
						\,\right)
					\,\right)
			\; - \;
			\overset{m}{\underset{i = 1}{\sum}}\;
				\beta_{i}
				\cdot
				\xi_{i}
			\;\right\}
		\right\}
\end{eqnarray*}
%The Karush-Kuhn-Tucker Optimality Necessary Conditions for the inner minimization problem are:
Next, we simplify the inner minimization problem.
First of all, note that the inner minimization problem is unconstrained
with a differentiable objective function; hence, the gradient 
\,$\nabla_{(\mathbf{n},b,\xi)}\,L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)$\,
of the objective function
\,$L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)$\,
of the inner minimization problem equals zero at each of its optima.
\begin{eqnarray*}
\nabla_{\mathbf{n}}\,L
& = &
	\mathbf{n} \, - \, \overset{m}{\underset{i\,=\,1}{\sum}}\;\alpha_{i}\,y_{i}\cdot\mathbf{x}_{i}
\\
\nabla_{b}\,L
& = &
	\overset{m}{\underset{i\,=\,1}{\sum}}\;\alpha_{i}\,y_{i}
\\
\nabla_{\xi}\,L
& = &
	\lambda\cdot\mathbf{1}_{m} \, - \, (\alpha \, + \, \beta)
\end{eqnarray*}
Setting the three expressions above to zero and
substituting into the objective function of the inner minimization problem yields:
\begin{eqnarray*}
&&
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\,
		\alpha_{i}
		\cdot
		\left(\,
			1 - \xi_{i}
			-
			y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
				\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
				\,\right)
			\,\right)
	\; - \;
	\overset{m}{\underset{i = 1}{\sum}}\;
		\beta_{i}
		\cdot
		\xi_{i}
\\
& = &
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\left(\,\overset{m}{\underset{i=1}{\sum}}\;(\lambda-\alpha_{i}-\beta_{i})\cdot\xi_{i}\right)
	\; - \;
	b\cdot\left(\,\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}\,y_{i}\right)
	\; + \;
	\left(\,\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}\right)
	\; - \;
	\left\langle\;\,
		\overset{m}{\underset{i = 1}{\sum}}\;
			\alpha_{i}\,y_{i}\overset{{\color{white}1}}{\cdot}
					\mathbf{x}_{i}\,
		\,,\,
		\mathbf{n}
		\;\right\rangle
\\
& = &
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\left(\,\overset{m}{\underset{i=1}{\sum}}\;(\lambda-\alpha_{i}-\beta_{i})\cdot\xi_{i}\right)
	\; - \;
	b\cdot\left(\,\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}\,y_{i}\right)
	\; + \;
	\left(\,\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}\right)
	\; - \;
	\left\langle\; \mathbf{n}\,,\mathbf{n} \,\right\rangle
\\
& = &
	-\,
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}
\;\; = \;\;
	-\,
	\dfrac{1}{2}\cdot\left\Vert\;
		\overset{m}{\underset{i\,=\,1}{\sum}}\;\alpha_{i}y_{i}\cdot\mathbf{x}_{i}
		\;\right\Vert^{2}
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}
\\
& = &
	-\;\dfrac{1}{2}\cdot
	\overset{m}{\underset{i=1}{\sum}}\,
	\overset{m}{\underset{j=1}{\sum}}\;
	\alpha_{i}\,\alpha_{j}\,y_{i}\,y_{j}\,\langle\,\mathbf{x}_{i}\,,\,\mathbf{x}_{j}\,\rangle
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}
\end{eqnarray*}
Hence, the Dual Problem simplifies to the right-hand-side of the following:
\begin{eqnarray*}
&&
	\inf
	\left\{\;\;
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		+
		\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
		\;\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d} \,,\;\, b \in \Re \,,\;\, \xi \in \Re^{m}
			\\
			\xi_{i} \geq 0,\;\,\textnormal{and}\;\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1 - \xi_{i}\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\underset{\alpha,\,\beta\,\in\,\Re_{\geq 0}^{m}}{\sup}
	\left\{\;
		\underset{(\mathbf{n},b,\xi)\,\in\,\Re^{d}\times\Re\times\Re^{m}}{\inf}\;
		\left\{\;
			\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
			\; + \;
			\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
			\; + \;
			\overset{m}{\underset{i = 1}{\sum}}\;\,
				\alpha_{i}
				\cdot
				\left(\,
					1 - \xi_{i}
					-
					y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
						\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
						\,\right)
					\,\right)
			\; - \;
			\overset{m}{\underset{i = 1}{\sum}}\;
				\beta_{i}
				\cdot
				\xi_{i}
			\;\right\}
		\right\}
\\
& = &
	\sup
	\left\{
	\left.
		-\;\dfrac{1}{2}\cdot
		\overset{m}{\underset{i=1}{\sum}}\,
		\overset{m}{\underset{j=1}{\sum}}\;
		\alpha_{i}\,\alpha_{j}\,y_{i}\,y_{j}\,\langle\,\mathbf{x}_{i}\,,\,\mathbf{x}_{j}\,\rangle
		\; + \;
		\overset{m}{\underset{i = 1}{\sum}}\;\alpha_{i}
	\;\;\right\vert
		\begin{array}{c}
			0 \leq \alpha_{i} \leq \lambda,\;\forall\;i =1,\ldots,m\,,
			\\
			%\overset{m}{\underset{i\,=\,1}{\sum}}\,\alpha_{i}\,y_{i} \,=\, 0
			\sum_{i=1}^{m}\alpha_{i}\,y_{i} \,=\, \overset{{\color{white}.}}{0}
		\end{array}
		\;\right\}
\end{eqnarray*}


