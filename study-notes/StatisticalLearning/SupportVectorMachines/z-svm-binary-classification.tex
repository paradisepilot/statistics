
\section{Support Vector Machines for Binary Classification}
\setcounter{theorem}{0}

\vskip 0.3cm
\noindent
\textbf{Reminder:}
\begin{itemize}
\item  Let $\mathbf{n}, \mathbf{z} \in \Re^{d}$, with $\mathbf{n} \neq \mathbf{0}$, be given.
          The hyperplane $H_{\mathbf{n},\mathbf{z}} \subset \Re^{d}$ with normal vector $\mathbf{n}$ and
          containing the point $\mathbf{z}$ is given by: 
          \begin{eqnarray*}
          H_{\mathbf{n},\mathbf{z}}
          & := &
          \left\{\;
          	\left.
          	\mathbf{x}\overset{{\color{white}1}}{\in}\Re^{d}
		\;\;\right\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\mathbf{n}\,\right\rangle = 0
			\;\right\}
	\;\; = \;\;
	\left\{\;
		\mathbf{x}\in\Re^{d}
		\;\left\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\frac{\mathbf{n}}{\Vert\,\mathbf{n}\,\Vert}\,\right\rangle = 0
			\right.\;\right\}
	\\
	& = &
	\left\{\;
		\left.
		\mathbf{x}\overset{{\color{white}.}}{\in}\Re^{d}
		\;\;\right\vert\;
			\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\widehat{\mathbf{n}}\,\right\rangle = 0
		\;\right\}
	\end{eqnarray*}
	
\item
	Note that $H_{\mathbf{n},\mathbf{z}} = H_{\alpha\mathbf{n},\mathbf{z}}$, for any $\alpha \neq 0$.
\item
	Let $\mathbf{x} \in \Re^{d}$.  The distance between $\mathbf{x}$ and the hyperplane $H_{\mathbf{n},\mathbf{z}}$
	is given by:
	\begin{equation*}
	\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right)
	\;\; = \;\;
		\left\vert
		\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\dfrac{\mathbf{n}}{\Vert\mathbf{n}\Vert}\,\right\rangle
		\right\vert
	\;\; = \;\;
		\dfrac{1}{{\color{white}.}\Vert\,\mathbf{n}\,\Vert{\color{white}.}}
		\cdot
		\left\vert
		\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\overset{{\color{white}.}}{\mathbf{n}}\,\right\rangle
		\right\vert
	\end{equation*}
	%This implies:
	%\begin{equation*}
	%\Vert\,\mathbf{n}\,\Vert
	%\cdot\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right) \;\; = \;\;
	%\left\vert\left\langle\,\mathbf{x}-\mathbf{z}\,,\,\mathbf{n}\,\right\rangle\right\vert
	%\end{equation*}
\item
	Note that
	$\dist\!\left(\mathbf{x},H_{\mathbf{n},\mathbf{z}}\right)$ is well-defined,
	i.e. it depends only on the point $\mathbf{x}$ and the hyperplane
	$H_{\mathbf{n},\mathbf{z}}$, and is indeed independent of the particular choice
	of the normal vector $\mathbf{n}$ and the point
	$\mathbf{z} \in H_{\mathbf{n},\mathbf{z}}$. 
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.3cm
\noindent
\textbf{Linearly separable data}
\vskip 0.1cm
\noindent
A data set
\begin{equation*}
\mathcal{D}
\;\; = \;\;
	\left\{\,
		(\overset{{\color{white}-}}{\mathbf{x}}_{1},y_{1})\,,\,(\mathbf{x}_{2},y_{2})\,,\,\ldots\,,\,(\mathbf{x}_{m},y_{m})
		\,\right\},
\quad\quad
\mathbf{x}_{i} \in \Re^{d},
\quad\quad
y_{i} \in \{\,-1,\,1\,\}
\end{equation*}
is said to be \textit{linearly separable} if
\begin{equation*}
	\left\{\;\;
		(\mathbf{n},\mathbf{z}) \in \Re^{d} \times \Re^{d}
		\;\;\left\vert
		\begin{array}{c}
			\textnormal{$H_{\mathbf{n},\mathbf{z}}$ is a}
			\\
			\textnormal{separating hyperplane}
			\\
			\textnormal{for $(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$}
			\end{array}
			\right.
		\!\right\}
\;\; = \;\;
	\left\{\;
		(\mathbf{n},\mathbf{z}) \in \Re^{d} \times \Re^{d}
		\;\;\left\vert
		\begin{array}{c}
			y_{i}\cdot\langle\,\mathbf{x}_{i} - \mathbf{z}\,,\,\mathbf{n}\,\rangle > 0\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\;\; \neq \;\;
	\varemptyset
\end{equation*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Primal Problem of the linearly separable case:}
\begin{eqnarray*}
&&
	\argmax
	\left\{\;
		{\color{white}........1}
		\underset{1\leq i \leq m}{\min}\left\{\,\dist(\,\mathbf{x}_{i}\overset{{\color{white}1}}{,}H_{\mathbf{n},\mathbf{z}}\,)\,\right\}
		{\color{white}........}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			\textnormal{$H_{\mathbf{n},\mathbf{z}}$ is a separating hyperplane}
			\;
			\textnormal{for $(\mathbf{x}_{1},y_{1}),\ldots,(\mathbf{x}_{m},y_{m})$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}.......1}\!
		\underset{1\leq i \leq m}{\min}\left\{\,
			\dfrac{
				\vert\,\langle\,\mathbf{x}_{i}-\mathbf{z}\,,\,\mathbf{n}\,\rangle\,\vert
				}{
				\Vert\,\mathbf{n}\,\Vert
				}
			\,\right\}
		{\color{white}.......}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			y_{i}\cdot\langle\,\mathbf{x}_{i} - \mathbf{z}\,,\,\mathbf{n}\,\rangle > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}...}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			\left\vert\,\langle\,\mathbf{x}_{i}\overset{{\color{white}.}}{-}\mathbf{z}\,,\,\mathbf{n}\,\rangle\,\right\vert
			\,\right\}
		{\color{white}...}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; \mathbf{z} \in \Re^{d}
			\\
			y_{i}\cdot\left(\langle\,\mathbf{x}_{i}\,,\,\mathbf{n}\,\rangle - \langle\,\mathbf{z}\,,\,\mathbf{n}\,\rangle\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		{\color{white}....}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			\left\vert\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} {\color{red}b}\,\right\vert
			\,\right\}
		{\color{white}...}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; {\color{red}b \in \Re}
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
			\,\right\}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		\cdot
		\underset{1\leq i \leq m}{\min}\left\{\,
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
			\,\right\}
		\;\;\left\vert
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\\
			{\color{red}\underset{1\leq i \leq m}{\min}\left\{\,
				y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle \overset{{\color{white}.}}{+} b\,\right)
				\,\right\}
				\; = \; 1}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;\;\,
		{\color{white}..}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		{\color{white}...}
		\;\;\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) > 0\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\\
			y_{i}\overset{{\color{white}.}}{\cdot}\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right)\,{\color{red}\geq}\,1\,,\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\argmax
	\left\{\;\;\,
		{\color{white}...}
		\dfrac{1}{\Vert\,\mathbf{n}\,\Vert}
		{\color{white}...}\!
		\;\;\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	{\color{red}\argmin}\,
	\left\{\;\;\,
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d},\; b \in \Re
			\\
			y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1\,,
			\;
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Primal Problem of the linearly non-separable case:}
\begin{eqnarray*}
	\argmin
	\left\{\;\;
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		+
		\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
		\;\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d} \,,\;\, b \in \Re \,,\;\, \xi \in \Re^{m}
			\\
			\xi_{i} \geq 0,\;\,\textnormal{and}\;\, y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1 - \xi_{i}\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
\textbf{The Dual Problem of the linearly non-separable case:}
\begin{equation*}
L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)
\;\; := \;\;
	\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
	\; + \;
	\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
	\; + \;
	\overset{m}{\underset{i = 1}{\sum}}\;\,
		\alpha_{i}
		\cdot
		\left(\,
			1 - \xi_{i}
			-
			y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
				\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
				\,\right)
			\,\right)
	\; - \;
	\overset{m}{\underset{i = 1}{\sum}}\;
		\beta_{i}
		\cdot
		\xi_{i}
\end{equation*}

\begin{eqnarray*}
&&
	\inf
	\left\{\;\;
		\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
		+
		\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
		\;\;\,\left\vert\;
		\begin{array}{c}
			\mathbf{n} \in \Re^{d} \,,\;\, b \in \Re \,,\;\, \xi \in \Re^{m}
			\\
			\xi_{i} \geq 0,\;\,\textnormal{and}\;\, y_{i}\cdot\left(\,\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b\,\right) \geq 1 - \xi_{i}\,,
			\\
			\textnormal{for each \,$i = 1,2,\ldots,m$}
			\end{array}
			\right.
		\right\}
\\
& = &
	\underset{\alpha,\beta\,\in\,\Re_{\geq 0}^{m}}{\sup}
	\left\{\;
		\underset{(\mathbf{n},b,\xi)\,\in\,\Re^{d}\times\Re\times\Re^{m}}{\inf}\;\;
		L(\,\mathbf{n},b,\xi\,;\,\alpha,\beta\,)
		\right\},
	\quad
	\textnormal{by Strong Duality}
\\
& = &
	\underset{\alpha,\beta\,\in\,\Re_{\geq 0}^{m}}{\sup}
	\left\{\;
		\underset{(\mathbf{n},b,\xi)\,\in\,\Re^{d}\times\Re\times\Re^{m}}{\inf}\;
		\left\{\;
			\dfrac{1}{2}\cdot\Vert\,\mathbf{n}\,\Vert^{2}
			\; + \;
			\lambda\cdot\overset{m}{\underset{i=1}{\sum}}\;\xi_{i}
			\; + \;
			\overset{m}{\underset{i = 1}{\sum}}\;\,
				\alpha_{i}
				\cdot
				\left(\,
					1 - \xi_{i}
					-
					y_{i}\overset{{\color{white}1}}{\cdot}\left(\,
						\langle\,\mathbf{x}_{i}\,,\mathbf{n}\,\rangle + b
						\,\right)
					\,\right)
			\; - \;
			\overset{m}{\underset{i = 1}{\sum}}\;
				\beta_{i}
				\cdot
				\xi_{i}
			\;\right\}
		\right\}
\end{eqnarray*}
%The Karush-Kuhn-Tucker Optimality Necessary Conditions for the inner minimization problem are:
Now, note that the inner minimization problem is unconstrained.
\begin{eqnarray*}
\nabla_{\mathbf{n}}\,L
& = &
	\mathbf{n} \, - \, \overset{m}{\underset{i\,=\,1}{\sum}}\;\alpha_{i}y_{i}\cdot\mathbf{x}_{i}
\\
\nabla_{b}\,L
& = &
	\overset{m}{\underset{i\,=\,1}{\sum}}\;\alpha_{i}y_{i}
\\
\nabla_{\xi}\,L
& = &
	\lambda\cdot\mathbf{1}_{m} \, - \, (\alpha \, + \, \beta)
\end{eqnarray*}


