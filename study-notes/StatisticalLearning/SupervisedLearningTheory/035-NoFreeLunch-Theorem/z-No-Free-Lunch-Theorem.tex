
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{The No Free Lunch Theorem}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{theorem}[The No Free Lunch Theorem]
\label{Thm:NoFreeLunch}
\mbox{}\vskip 0.1cm
\noindent
Suppose:
\begin{itemize}
\item
	$\mathcal{X}$ is a measurable space, i.e. $\mathcal{X}$ is a non-empty set equipped with a $\sigma$-algebra,
	and \,$\vert\,\mathcal{X}\,\vert \,\in\, \N\cup\{+\infty\}$\,.
\item
	$\mathcal{H} \; = \; \left\{\; h : \mathcal{X} \overset{{\color{white}\vert}}{\longrightarrow} \{0,1\}\;\right\}$\,
	is a hypothesis class, i.e.
	$\mathcal{H}$ is a non-empty collection of measurable $\{0,1\}$-valued functions defined on the
	measurable space $\mathcal{X}$.
\item
	$\mathcal{F}
	\;\; : = \;\;
		\left\{\;\,
			F_{n} : \left(\;\mathcal{X} \overset{{\color{white}.}}{\times} \{0,1\} \;\right)^{n}
			\; \longrightarrow \;\mathcal{H}
			\;\;\right\}_{n\in\N}$\,
	is a learning algorithm with hypothesis class \,$\mathcal{H}$.
\end{itemize}
Then, for each \,$n < \dfrac{\vert\,\mathcal{X}\,\vert}{2}$,\,
there exists a probability measure \,$\mathcal{D}$\, on
\,$\mathcal{X} \times \{0,1\}$\,
such that
\begin{enumerate}
\item
	$Y$ equals a deterministic function of $X$ $\mathcal{D}$-almost surely, i.e. there exists a
	measurable function \,$g : \mathcal{X} \longrightarrow \{0,1\} $\, ($g$ need not be in $\mathcal{H}$)\,
	such that
	\begin{equation*}
	P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,g(X) \,\overset{{\color{white}-}}{=}\, Y\,\right) = 1\,,
	%\quad\textnormal{hence,}\;\;\;
	%\underset{h\in\mathcal{H}}{\inf}\;P\!\left(\,\overset{{\color{white}.}}{h}(X) \neq Y \,\right) \;=\; 0\,,
	\end{equation*}
	and
\item
	\begin{equation*}
	P_{\,{\color{red}D_{n}}\,\sim\,\mathcal{D}^{\otimes n}}\!\left(\;
		P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,\overset{{\color{white}.}}{F}_{n}({\color{red}D_{n}})(X) \neq Y \,\right)
		\; < \;
			\dfrac{1}{8}
		\;\right)
	\;\; < \;\;
		1 \,-\, \dfrac{1}{7}
	\;\; = \;\;
		\dfrac{6}{7}\,,
	\end{equation*}
	where
	\,$D_{n} = \left((X_{1},Y_{1}),(X_{2},Y_{2}),\,\overset{{\color{white}\vert}}{\ldots}\,,(X_{n},Y_{n})\right)
		: \Omega \longrightarrow
		\left(\,\mathcal{X}\overset{{\color{white}.}}{\times}\{0,1\}\,\right)^{n}$\,
	is such that the
	$(X_{i},Y_{i})$'s are I.I.D. copies of $(X,Y)$.
\end{enumerate}
\end{theorem}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\begin{corollary}
\mbox{}\vskip 0.1cm
\noindent
Suppose:
\begin{itemize}
\item
	$\mathcal{H} \; = \; \left\{\; h : \mathcal{X} \overset{{\color{white}\vert}}{\longrightarrow} \{0,1\}\;\right\}$\,
	is a hypothesis class, where \,$\vert\,\mathcal{X}\,\vert \,\in\, \N\cup\{+\infty\}$\,, and
\item
	$\mathcal{F}
	\;\; : = \;\;
		\left\{\;\,
			F_{n} : \left(\;\mathcal{X} \overset{{\color{white}.}}{\times} \{0,1\} \;\right)^{n}
			\; \longrightarrow \;\mathcal{H}
			\;\;\right\}_{n\in\N}$\,
	is a learning algorithm with hypothesis class \,$\mathcal{H}$.
\end{itemize}
Then, for each \,$n < \dfrac{\vert\,\mathcal{X}\,\vert}{2}$,\, we have
\begin{equation*}
\inf\left\{\,
	P_{\,{\color{red}D_{n}}\,\sim\,\mathcal{D}^{\otimes n}}\!\left(\,
		P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,\overset{{\color{white}.}}{F}_{n}({\color{red}D_{n}})(X) \neq Y \,\right)
		\; < \;
			\dfrac{1}{8}
		\;\right)
	\;\;\left\vert\;
		\begin{array}{c}
		\textnormal{$\mathcal{D}$\, is a probability measure on \,$\mathcal{X} \times \{0,1\}$}
		\\
		\textnormal{such that \,$\overset{{\color{white}-}}{\exists}\;\, g : \mathcal{X} \longrightarrow \{0,1\}$}
		\\
		\textnormal{satisfying $P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,g(X)\overset{{\color{white}-}}{=}Y\,\right) \,=\, 1$}
		\end{array}
	\right.\;\right\}
\;\; \leq \;\;
	\dfrac{6}{7}
\end{equation*}
\end{corollary}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\newpage
\begin{remark}
\mbox{}\vskip 0.1cm
\noindent
Given any binary classification learning algorithm and
any \,$n \,<\, \dfrac{1}{2}\cdot\textnormal{Cardinality}(\textnormal{codomain of predictor variable})$,
there exists some underlying data-generating mechanism such that
the resulting probability (with respect to I.I.D. data sets of size $n$) of the event that
\begin{center}
the generalization error \,$<$\, $\dfrac{1}{8}$
\end{center}
is \,$\leq$\, $\dfrac{6}{7}$.
\end{remark}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\proofof Theorem \ref{Thm:NoFreeLunch}
\vskip 0.3cm
\noindent
Fix any subset $\mathcal{C} \subset \mathcal{X}$ with $\vert\,\mathcal{C}\,\vert = 2n$.
Let $\{0,1\}^{\mathcal{C}}$ be the collection of all (arbitrary) $\{0,1\}$-valued functions defined on $\mathcal{C}$.
Note that $\left\vert\,\{0,1\}^{\mathcal{C}}\right\vert \,=\, 2^{\vert\,\mathcal{C}\,\vert} \, = \, 2^{2n}$.
Let $\{0,1\}^{\mathcal{C}} = \left\{\,g_{1},\, g_{2},\, \ldots,\, g_{2^{2n}}\,\right\}$ be an enumeration of $\{0,1\}^{\mathcal{C}}$.
For each $i \in \{1,2,\ldots,2^{2n}\}$, define a probability measure $\mathcal{D}_{i}$ on $\mathcal{X} \times \{0,1\}$ via
\begin{equation*}
\mathcal{D}_{i}\!\left(\,\left\{\,(x\overset{{\color{white}\vert}}{,}y)\,\right\}\,\right)
\;\; := \;\;
	\left\{\begin{array}{cl}
		1\,/\,\vert\,C\,\vert\, \;=\; 1\,/\,2n\,, & \textnormal{if \,$x \in \mathcal{C}$\, and \,$y = g_{i}(x)$} \\
		\overset{{\color{white}\vert}}{0}, & \textnormal{otherwise}
		\end{array}\right.
\end{equation*}

\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad
For every
\,$h : \left(\,\mathcal{X}\overset{{\color{white}.}}{\times}\{0,1\}\right)^{n} \longrightarrow \,\{0,1\}^{\mathcal{X}}$\,,
we have:
\begin{equation*}
\underset{1 \,\leq\, i \,\leq\, 2^{2n}}{\max}\left\{\;
	\overset{{\color{white}\vert}}{E}_{{\color{red}D_{n}}\,\sim\,\mathcal{D}_{i}^{\otimes n}}\!\left[\;
		P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h({\color{red}D_{n}})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
		\;\right]
	\;\right\}
	\;\; \geq \;\;
		\dfrac{1}{4}\,.
\end{equation*}

\vskip 0.5cm
\noindent
\textbf{Claim 2:}\quad
For every
\,$h : \left(\,\mathcal{X}\overset{{\color{white}.}}{\times}\{0,1\}\right)^{n} \longrightarrow \,\{0,1\}^{\mathcal{X}}$\,,
there exist a function \,$g : \mathcal{X} \longrightarrow \{0,1\}$\, and
a probability measure \,$\mathcal{D}$\, on \,$\mathcal{X} \times \{0,1\}$\,
such that
\begin{equation*}
P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,Y \overset{{\color{white}-}}{=} g(X)\,\right) \; = \; 1
\;\quad\textnormal{and}\quad
\overset{{\color{white}\vert}}{E}_{{\color{red}D_{n}}\,\sim\,\mathcal{D}^{\otimes n}}\!\left[\;
	P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,h({\color{red}D_{n}})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\;\right]
\;\; \geq \;\;
	\dfrac{1}{4}
\end{equation*}

\vskip 0.5cm
\noindent
\textbf{Claim 3:}\quad
For every
\,$h : \left(\,\mathcal{C}\overset{{\color{white}.}}{\times}\{0,1\}\right)^{n} \longrightarrow \,\{0,1\}^{\mathcal{X}}$\,,
there exist a function \,$g : \mathcal{X} \longrightarrow \{0,1\}$\, and
a probability measure \,$\mathcal{D}$\, on \,$\mathcal{X} \times \{0,1\}$\,
such that
\begin{equation*}
P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,Y \overset{{\color{white}-}}{=} g(X)\,\right) \; = \; 1
\;\quad\textnormal{and}\quad
\overset{{\color{white}\vert}}{P}_{{\color{red}D_{n}}\,\sim\,\mathcal{D}^{\otimes n}}\!\left(\,
	P_{\,(X,Y)\,\sim\,\mathcal{D}}\!\left(\,h({\color{red}D_{n}})(X) \overset{{\color{white}.}}{\neq} Y\,\right) \geq \dfrac{1}{8}
	\;\right)
\;\; \geq \;\;
	\dfrac{6}{7}
\end{equation*}

\vskip 1.0cm
\noindent
Proof of Claim 1:\quad
First, note that there are exactly $(2n)^{n}$ with-replacement sequences of elements of $\mathcal{C}$
of length $n$.
Let $\left(\,\overset{{\color{white}.}}{S}_{1},\,S_{2},\,\ldots\,,\,S_{(2n)^{n}}\right)$ be a fixed enumeration
of all such sequences.
For each $k \in \{1, 2, \ldots, (2n)^{n}\}$, denote
\begin{equation*}
S_{k}
\;\; = \;\;
	\left(\, x^{(k)}_{1} ,\, x^{(k)}_{2} ,\, \ldots\, ,\, x^{(k)}_{n} \,\right)
\end{equation*}
For each \,$i \in\{1, 2, \ldots, 2^{2n}\}$\, and for each \,$k \in \{1, 2, \ldots, (2n)^{n}\}$,\, denote
\begin{equation*}
d^{(n,i)}_{k}
\;\; = \;\;
	\left(\;
		\left(x^{(k)}_{1},g_{i}(x^{(k)}_{1})\right) ,\,
		\left(x^{(k)}_{2},g_{i}(x^{(k)}_{2})\right) ,\,
		\overset{{\color{white}\textnormal{\Large$\vert$}}}{\ldots}\,,\,
		\left(x^{(k)}_{n},g_{i}(x^{(k)}_{n})\right)
	\;\right)
\end{equation*}
Then, note that
\begin{eqnarray*}
\mathcal{D}_{i}^{\otimes n}\!\left(\,d^{(n,i)}_{k}\,\right)
& = &
	\overset{n}{\underset{j\,=\,1}{\prod}}\;
	\mathcal{D}_{i}\!\left(\,\left\{\;\left(x^{(k)}_{1},g_{i}(x^{(k)}_{1})\right)\;\right\}\,\right)
\;\; = \;\;
	\overset{n}{\underset{j\,=\,1}{\prod}}\; \dfrac{1}{2n}
\\
& = &
	\dfrac{1}{(2n)^{n}}\,,
	\quad
	\textnormal{for each \,$i \in\{1, 2, \ldots, 2^{2n}\}$,\, $k \in \{1, 2, \ldots, (2n)^{n}\}$}
\end{eqnarray*}
Note also that
\begin{equation*}
\mathcal{D}_{i}^{\otimes n}\!\left(\,\left(\;(x_{1},y_{1}),(x_{2},y_{2}),\overset{{\color{white}\vert}}{\ldots},(x_{n},y_{n})\;\right)\,\right)
\;\; = \;\; 0\,,
\quad
\textnormal{if \,$\left(\;(x_{1},y_{1}),(x_{2},y_{2}),\overset{{\color{white}\vert}}{\ldots},(x_{n},y_{n})\;\right) \,\neq\, d^{(n,i)}_{k},
\;\;\forall\; k$}
\end{equation*}
In other words,
\,$\mathcal{D}^{\otimes n}_{i} : \left(\,\mathcal{X} \overset{{\color{white}.}}{\times} \{0,1\}\,\right)^{n} \longrightarrow [\,0,1\,]$\,
can be given by:
\begin{equation*}
\mathcal{D}_{i}^{\otimes n}\!\left(\,\left(\;(x_{1},y_{1}),(x_{2},y_{2}),\overset{{\color{white}\vert}}{\ldots},(x_{n},y_{n})\;\right)\,\right)
\;\; = \;\;
	\left\{\begin{array}{cl}
	\dfrac{1}{(2n)^{n}}\,, & \textnormal{if \,$\left(\;(x_{1},y_{1}),(x_{2},y_{2}),\overset{{\color{white}\vert}}{\ldots},(x_{n},y_{n})\;\right)\,=\, d^{(n,i)}_{k}$\,, for some $k$}
	\\
	\overset{{\color{white}\vert}}{0}\,, & \textnormal{otherwise}
	\end{array}\right.
\end{equation*}
Thus,
\begin{eqnarray*}
\overset{{\color{white}\vert}}{E}_{{\color{red}D_{n}}\,\sim\,\mathcal{D}_{i}^{\otimes n}}\!\!\left[\;
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h({\color{red}D_{n}})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\;\right]
& = &
	\underset{d_{n}\in\left(\mathcal{X}\overset{{\color{white}.}}{\times}\{0,1\}\right)^{n}}{\textnormal{\Large$\sum$}}
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d_{n})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\cdot
	P_{\,\mathcal{D}_{i}^{\otimes n}}(\,d_{n}\,)
\\
& = &
	\underset{d_{n}\in\left(\mathcal{X}\overset{{\color{white}.}}{\times}\{0,1\}\right)^{n}}{\textnormal{\Large$\sum$}}
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d_{n})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\cdot
	\mathcal{D}_{i}^{\otimes n}\!\left(\,d_{n}\,\right)
\\
& = &
	\dfrac{1}{(2n)^{n}}\;\,
	\overset{(2n)^{n}}{\underset{k\,=\,1}{\textnormal{\Large$\sum$}}}\;\,
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
\end{eqnarray*}
On the other hand,
\begin{eqnarray*}
&&
\underset{1\,\leq\, i \,\leq\, 2^{2n}}{\max}\left\{\;
	\dfrac{1}{(2n)^{n}}\;\,
	\overset{(2n)^{n}}{\underset{k\,=\,1}{\textnormal{\Large$\sum$}}}\;\,
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\;\right\}
\\
& \geq &
	\dfrac{1}{2^{2n}}\;\,
	\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;\left\{\;
		\dfrac{1}{(2n)^{n}}\;\,
		\overset{(2n)^{n}}{\underset{k\,=\,1}{\textnormal{\Large$\sum$}}}\;\,
		P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
		\;\right\}
\\
& = &
	\dfrac{1}{(2n)^{n}}\;\,
	\overset{(2n)^{n}}{\underset{k\,=\,1}{\textnormal{\Large$\sum$}}}\;\,\left\{\;
		\dfrac{1}{2^{2n}}\;\,
		\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
		P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
		\;\right\}
\\
& \geq &
\underset{1\,\leq\, k \,\leq\, (2n)^{n}}{\min}\left\{\;
	\dfrac{1}{2^{2n}}\;\,
	\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
	P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
	\;\right\}
\end{eqnarray*}
Now, note that Claim 1 now follows immediately from the following:

\vskip 0.5cm
\begin{center}
\begin{minipage}{6.5in}
\noindent
\underline{Claim${\color{white}\textnormal{j}}$1A:}
\begin{equation*}
\dfrac{1}{2^{2n}}\;\,
\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
\;\; \geq \;\;
	\dfrac{1}{4}\,,
\quad
\textnormal{for each \,$k \in \left\{1,2,\overset{{\color{white}\vert}}{\ldots},(2n)^{n}\right\}$}
\end{equation*}
\end{minipage}
\end{center}
\vskip 0.1cm
\underline{Proof of Claim${\color{white}\textnormal{j}}$1A:}
\vskip 0.2cm
\noindent
First, note that for each \,$\mathcal{D}_{i}$\, and
for each measurable \,$h : \mathcal{X} \longrightarrow \{0,1\}$,\, we have
\begin{eqnarray*}
P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(X) \overset{{\color{white}.}}{\neq} Y\,\right)
& = &
	\underset{(x,y)\,\in\,\mathcal{X}\times\{0,1\}}{\sum}\; \mathbf{1}_{\{h(x) \neq y\}}
	\cdot P_{\,\mathcal{D}_{i}}\!\left(\,(X,Y)\overset{{\color{white}-}}{=}(x,y)\,\right)
\\
&= &
	\underset{x\,\in\,\mathcal{C}}{\sum}\; \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}
	\cdot P_{\,\mathcal{D}_{i}}\!\left(\,(X,Y)\overset{{\color{white}-}}{=}(x,g_{i}(x))\,\right)
\\
&= &
	\underset{x\,\in\,\mathcal{C}}{\sum}\; \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}
	\cdot \dfrac{1}{{\color{white}.}\vert\,\mathcal{C}\,\vert{\color{white}.}}
	\;\; = \;\;
	\dfrac{1}{{\color{white}.}2\,n{\color{white}.}}\;
	\underset{x\,\in\,\mathcal{C}}{\sum}\; \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}
\end{eqnarray*}
Next, consider the sequence \,$S_{1}$\, of elements of \,$\mathcal{C}$\, introduced
at the beginning of the proof of Claim 1.
Let \,$\mathcal{C}\,\backslash S_{1}$\, denote the set of elements in \,$\mathcal{C}$\,
that do not appear in \,$S_{1}$. Recall that $\mathcal{C}$ has $2n$ distinct elements,
while $S_{1}$ is a with-replacement sequence of elements of $\mathcal{C}$ of length
$n$. It follows that the number \,$\vert\,\mathcal{C}\,\backslash S_{1}\,\vert$\,
of distinct elements in \,$\mathcal{C}\,\backslash S_{1}$\, must satisfy
\,$\vert\,\mathcal{C}\,\backslash S_{1}\,\vert \geq n$.
Thus,
\begin{eqnarray*}
\dfrac{1}{{\color{white}.}2n{\color{white}.}}\;
\underset{x\,\in\,\mathcal{C}}{\sum}\; \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}
& \geq &
	\dfrac{1}{{\color{white}.}2\,n{\color{white}.}}\;
	\underset{x\,\in\,\mathcal{C}\,\backslash S_{1}}{\sum} \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}\,,
	\quad
	\textnormal{(\,summands \,$\geq$\, $0$, and summing over a subset\,)}
\\
& \geq &
	\dfrac{1}{{\color{white}.}2\,\vert\,\mathcal{C}\,\backslash S_{1}\,\vert{\color{white}.}}\;
	\underset{x\,\in\,\mathcal{C}\,\backslash S_{1}}{\sum} \mathbf{1}_{\{h(x) \neq g_{i}(x)\}}\,.
\end{eqnarray*}
Hence, we see that
\begin{eqnarray*}
\dfrac{1}{2^{2n}}\;\,
\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
P_{\,(X,Y)\,\sim\,\mathcal{D}_{i}}\!\left(\,h(d^{(n,i)}_{k})(X) \overset{{\color{white}.}}{\neq} Y\,\right)
& = &
	\dfrac{1}{2^{2n}}\;\,
	\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
	\left(\;
		\dfrac{1}{{\color{white}.}2n{\color{white}.}}
		\underset{x\,\in\,\mathcal{C}}{\sum}\; \mathbf{1}_{\left\{h(d^{(n,i)}_{k})(x) \neq g_{i}(x)\right\}}
		\;\right)
\\
& \geq &
	\dfrac{1}{2^{2n}}\;\,
	\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;
	\left(\;
		\dfrac{1}{{\color{white}.}2\,\vert\,\mathcal{C}\,\backslash S_{1}\,\vert{\color{white}.}}\;
		\underset{x\,\in\,\mathcal{C}\,\backslash S_{1}}{\sum} \mathbf{1}_{\left\{(d^{(n,i)}_{k})(x) \neq g_{i}(x)\right\}}
		\;\right)
\\
& = &
	\dfrac{1}{{\color{white}.}2\,\vert\,\mathcal{C}\,\backslash S_{1}\,\vert{\color{white}.}}
	\underset{x\,\in\,\mathcal{C}\,\backslash S_{1}}{\sum}
	\left(\;
		\dfrac{1}{2^{2n}}\;\,
		\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;\,
		\mathbf{1}_{\left\{(d^{(n,i)}_{k})(x) \neq g_{i}(x)\right\}}
		\;\right)
\\
& \geq &
	\dfrac{1}{2}\,\cdot
	\underset{x\,\overset{{\color{white}.}}{\in}\,\mathcal{C}\,\backslash S_{1}}{\min}
	\left\{\;\,
		\dfrac{1}{2^{2n}}\;\,
		\overset{2^{2n}}{\underset{i\,=\,1}{\sum}}\;\,
		\mathbf{1}_{\left\{(d^{(n,i)}_{k})(x) \neq g_{i}(x)\right\}}
		\,\;\right\}
\end{eqnarray*}

\vskip 5.0cm
\noindent
This completes the proof of the Theorem.
\qed


          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
