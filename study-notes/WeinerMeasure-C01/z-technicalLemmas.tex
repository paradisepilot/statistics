
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Technical Lemmas}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

Note that
\,$X_{n}\,\overset{d}{\longrightarrow}\,X$\,
and
\,$Y_{n}\,\overset{d}{\longrightarrow}\,Y$\,
does NOT in general imply
\,$X_{n} + Y_{n}\,\overset{d}{\longrightarrow}\,X + Y$.
But the implication does hold if $X_{n}$ and $Y_{n}$
are independent for each $n \in \N$, and 
both $X$ and $Y$ are Gaussian random variables,
as the following Proposition shows.

\begin{proposition}
\label{GaussianDistributionLimit}
\quad
Let $k \in \N$ be fixed.
Suppose:
\begin{itemize}
\item	For each $n \in \N$,
		\begin{equation*}
		Y^{(n)}_{1},\, Y^{(n)}_{2},\, \ldots, Y^{(n)}_{k} \,:\,\Omega^{(n)}\,\longrightarrow\,\Re
		\end{equation*}
		are independent $\Re$-valued random variables defined on the probability space $\Omega^{(n)}$.
\item	For each $i = 1, 2, \ldots, k$,
		\begin{equation*}
		Y^{(n)}_{i} \; \overset{d}{\longrightarrow} \; N\!\left(\,\mu_{i},\,\sigma^{2}_{i}\,\right),
		\quad
		\textnormal{as \;$n \longrightarrow \infty$}.
		\end{equation*}
\end{itemize}
Then, for any $c_{1},\, c_{2},\, \ldots,\, c_{k} \,\in\, \Re$,
\begin{equation*}
\sum_{i\,=\,1}^{k}\,c_{i}\,Y^{(n)}_{i} \; \overset{d}{\longrightarrow} \;
N\!\left(\,\sum_{i\,=\,1}^{k}\,c_{i}\,\mu_{i} \;,\; \sum_{i\,=\,1}^{k}\,c_{i}^{2}\,\sigma_{i}^{2}\;\right),
\quad
\textnormal{as \;$n \longrightarrow \infty$}.
\end{equation*}
\end{proposition}
\proof
Let \,$Y^{(n)} \,:=\, \overset{k}{\underset{i\,=\,1}{\sum}}\,c_{i}\,Y^{(n)}_{i}$.\,
Let \,$\varphi_{X}$\, denote the characteristic function of a $\Re$-valued random variable $X$.
Then,
\begin{eqnarray*}
\varphi_{Y^{(n)}}(t)
&=& \varphi_{\sum_{i}^{k}c_{i}Y^{(n)}_{i}}(t)
\\
&=& \prod_{i\,=\,1}^{k}\,\varphi_{c_{i}Y^{(n)}_{i}}(t),
\quad\textnormal{since \,$Y^{(n)}_{1},\, \ldots,\, Y^{(n)}_{k}$\, are independent}
\\
&=& \prod_{i\,=\,1}^{k}\,\varphi_{Y^{(n)}_{i}}(\,c_{i}t\,)
\\
&\longrightarrow&
\prod_{i\,=\,1}^{k}\,\exp\!\left\{\;\sqrt{-1}\,\mu_{i}\,(c_{i}\,t) \;-\; \dfrac{1}{2}\,\sigma_{i}^{2}\,(\,c_{i}t\,)^{2}\;\right\}
\\
&=&
\exp\!\left\{\;
	\sqrt{-1}\left(\sum_{i\,=\,1}^{k}c_{i}\mu_{i}\right)t
	\;-\; \dfrac{1}{2}\left(\sum_{i\,=\,1}^{k}c_{i}^{2}\sigma_{i}^{2}\right)t^{2}
	\;\right\},
\quad\textnormal{as \,$n \longrightarrow \infty$},
\end{eqnarray*}
where the second and third equalities follow from the properties of
characteristic functions of random variables (see p.21, \cite{Ferguson1996}),
while the expression of the limit follows from the fact that the characteristic
function $\varphi_{Z}$ of a random variable $Z$ with distribution
$N\!\left(\,\mu,\,\sigma^{2}\,\right)$ is
\begin{equation*}
\varphi_{Z}
\;\;=\;\;
\exp\!\left\{\;\sqrt{-1}\,\mu t \;-\; \dfrac{1}{2}\,\sigma^{2}\,t^{2}\;\right\}.
\end{equation*}
The Proposition now follows immediately from
the L\'{e}vy-Cram\'{e}r Continuity Theorem (Theorem 1.9(ii), p.56, \cite{Shao2003}).
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{proposition}
\label{FiniteExtensionPreservesTightness}
\mbox{}
\vskip 0.2cm
\noindent
Suppose:
\begin{itemize}
\item	$k \in \N$ and $Q_{1},\,Q_{2},\,\ldots\,Q_{k}$ are Borel probability measures on
		$\left(\Czo\Vert\,\cdot\,\Vert_{\infty}\right)$.
\item	$\left\{\,P_{n}\,\right\}_{n\in\N}$\, is a sequence of Borel probability measures on
		$\left(\Czo\Vert\,\cdot\,\Vert_{\infty}\right)$.
\end{itemize}
Then, the following are equivalent:
\begin{enumerate}
\item	$\left\{\,P_{n}\,\right\}_{n\in\N}$\, is tight. 
\item	$\left\{\,Q_{1},\ldots,Q_{k}\,\right\}\cup\left\{\,P_{n}\,\right\}_{n\in\N}$\, is tight.
\end{enumerate}
\end{proposition}
\proof
Note that once we prove the Proposition for $k = 1$, the cases $k \geq 2$ will follow immediately by finite induction.
We now proceed to prove the Proposition for $k =1$, and we write $Q$ for $Q_{1}$.

\vskip 0.3cm
\noindent
\underline{(ii)\;$\Longrightarrow$\;(i)}\quad
This is trivial. Indeed,
\begin{eqnarray*}
&&
	\textnormal{$\left\{\;Q\;\right\}\cup\left\{\,P_{n}\,\right\}_{n\in\N}$ is tight}
\\
&\Longleftrightarrow&
	\textnormal{for each $\varepsilon > 0$},\;
	\exists\;\textnormal{compact $K\subset\Czo$ such that $1 - \varepsilon < Q(K) \leq 1$
	and $1 - \varepsilon < P_{n}(K) \leq 1$, for all $n \in \N$}
\\
&\Longrightarrow&
	\textnormal{for each $\varepsilon > 0$},\;
	\exists\;\textnormal{compact $K\subset\Czo$ such that $1 - \varepsilon < P_{n}(K) \leq 1$, for all $n \in \N$}
\\
&\Longleftrightarrow&
	\textnormal{$\left\{\,P_{n}\,\right\}_{n\in\N}$ is tight}
\end{eqnarray*}
This proves that (ii)\;$\Longrightarrow$\;(i).

\vskip 0.3cm
\noindent
\underline{(i)\;$\Longrightarrow$\;(ii)}
\vskip 0.2cm
\noindent
Let $\varepsilon > 0$ be given.
Since $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ is separable and complete,
the single Borel probability measure $Q$ on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ is tight
(Theorem 1.3, \cite{Billingsley1999}).
Thus, there exists a compact subset $K_{1} \subset \Czo$ such that $1 - \varepsilon < Q(K_{1}) \leq 1$.
On the other hand, the tightness hypothesis on $\left\{\,P_{n}\,\right\}_{n\in\N}$ implies there exists
a compact subset $K_{2} \subset \Czo$ such that
$1 - \varepsilon < P_{n}(K_{2}) \leq 1$, for each $n \in \N$.
Let $K := K_{1} \cup K_{2}$. Then, $K$ is itself a compact subset of $\Czo$, and
\begin{equation*}
Q\!\left(\,K\,\right)
\;=\; Q\!\left(\,K_{1} \cup K_{2}\,\right)
\;\geq\; Q\!\left(\,K_{1}\,\right)
\;>\;1 - \varepsilon,
\quad\textnormal{and}\quad
P_{n}\!\left(\,K\,\right)
\;=\; P_{n}\!\left(\,K_{1} \cup K_{2}\,\right)
\;\geq\; P_{n}\!\left(\,K_{2}\,\right)
\;>\;1 - \varepsilon.
\end{equation*}
This proves the tightness of
$\left\{\,Q\,\right\}\cup\left\{\,P_{n}\,\right\}_{n\in\N}$,
as required.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{theorem}[Uniqueness of weak limit of a sequence of Borel probability measures on a metric space]
\label{weakLimitUniqueness}
\vskip 0.20cm
\noindent
Suppose $S$ is a metric space and $\mathcal{B}(S)$ is its Borel $\sigma$-algebra.
If $P$, $Q$, $P_{1}, P_{2}, \ldots\,$ are Borel probability measures on
$\left(S,\mathcal{B}(S)\right)$ such that
\begin{equation*}
P_{n} \overset{d}{\longrightarrow} P
\quad\textnormal{and}\quad
P_{n} \overset{d}{\longrightarrow} Q,
\quad
\textnormal{as \;$n \longrightarrow \infty$},
\end{equation*}
then $P = Q$, as Borel probability measures on $\left(S,\mathcal{B}(S)\right)$.
\end{theorem}
\proof
Observe that, by the definition of weak convergence of measures,
for each bounded continuous $\Re$-valued function
$f : S \longrightarrow \Re$ defined on $S$, we have:
\begin{equation*}
\int_{S}\,f\,\d P
\;\; = \;\; \underset{n\rightarrow\infty}{\lim}\,\int_{S}\,f\,\d P_{n}
\;\; = \;\; \int_{S}\,f\,\d Q.
\end{equation*}
Thus, $P = Q$, as Borel probability measures on $\left(S,\mathcal{B}(S)\right)$,
by Theorem 1.2, p.8, \cite{Billingsley1999}.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
