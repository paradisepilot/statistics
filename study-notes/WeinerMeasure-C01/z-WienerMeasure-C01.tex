
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{The Wiener measure on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\newcommand{\Pitzk}{\Pi_{t_{0}t_{1}\ldots t_{k}}}
\newcommand{\pitok}{\pi_{t_{1}\ldots t_{k}}}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

\begin{definition}[Wiener measure on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$]
\mbox{}\vskip 0.2cm
\noindent
A Borel probability measure $W$ on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ is called a
\textbf{Wiener measure} if it satisfies the following two conditions:
\begin{enumerate}
\item	Its induced measure $W\circ\ev_{0}^{-1}$ on $\Re$
		via the evaluation map $\ev_{0} : \Czo \longrightarrow \Re : f \longmapsto f(0)$
		is the point-mass measure on $\Re$ concentrated at $0 \in \Re$, i.e.
		\begin{equation*}
		W\!\left(\,\ev_{0}^{-1}\!\left(\,\left\{\,0\,\right\}\,\right)\,\right)
		\;\; = \;\;
		W\!\left(\left\{\;
			f \in \Czo
			\;\left\vert\;
			f(0) \overset{{\color{white}1}}{=} 0
			\right.
		\;\right\}\right)
		\;\; = \;\;
		1\,.
		\end{equation*}
\item	For any $0 \leq t_{0} < t_{1} < t_{2} < \cdots < t_{k} \leq 1$,
		\begin{equation*}
		W \circ \Pitzk^{-1}
		\;\; = \;\;
		N\!\left(\;
		\mathbf{\mu} = \mathbf{0}\,,\,
		\overset{{\color{white}1}}{\Sigma} = \diag\!\left(\,t_{1}-t_{0},\; \ldots\; ,\; t_{k}-t_{k-1}\,\right)
		\;\right),
		\end{equation*}
		where the map \;$\Pitzk : \Czo \longrightarrow \Re^{k}$\; is defined as follows:
		\begin{equation*}
		\Pitzk \;:\; \Czo \longrightarrow \Re^{k} \;:\;
		f \;\longmapsto\; \left(\,\overset{{\color{white}.}}{f}(t_{1}) - f(t_{0}),\,f(t_{2}) - f(t_{1}),\,\ldots,\,f(t_{k}) - f(t_{k-1})\,\right).
		\end{equation*}
\end{enumerate}
\end{definition}

\begin{theorem}[Finite-dimensional distributions of the Wiener measure]
\label{WienerFiniteDimensionalDistributions}
\mbox{}\vskip 0.2cm
\noindent
Let $W$ be a Wiener measure defined on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$.
Then, for any pairwise distinct \;$0 \;\leq\; t_{1},\; t_{2}, \;\ldots\;,\; t_{k} \leq 1$,
\begin{equation*}
W \circ \pitok^{-1}
\;\; = \;\;
N\!\left(\;
\mathbf{\mu} = \mathbf{0}\,,\,
\Sigma = \left[\;\min\{\overset{{\color{white}1}}{t}_{i},t_{j}\}\;\right]_{1\leq i,j\leq k}
\;\right),
\end{equation*}
where the map \;$\pitok : \Czo \longrightarrow \Re^{k}$\; is defined as follows:
\begin{equation*}
\pitok \;:\; \Czo \longrightarrow \Re^{k} \;:\;
f \;\longmapsto\; \left(\,\overset{{\color{white}.}}{f}(t_{1}),\,f(t_{2}),\,\ldots,\,f(t_{k})\,\right).
\end{equation*}
\end{theorem}
\proof
Let $t_{0} \,:= \, 0$.
Re-labeling the $t_{i}$'s if necessary, without loss of generality, we may assume that
$t_{1} < t_{2} < \cdots < t_{k}$.
Let $\mathcal{B}$ denote the Borel $\sigma$-algebra of $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$.
Then, $\left(\Czo,\mathcal{B},W\right)$ is the probability space
obtained by equipping the measurable space $\left(\Czo,\mathcal{B}\right)$
with the Wiener measure $W$.

\vskip 0.3cm
\noindent
Define the following $\Re$-valued random variables on the probability space $\left(\Czo,\mathcal{B},W\right)$:
\begin{equation*}
\begin{array}{lclrcll}
Z_{t_{1}-t_{0}} &:& \Czo \longrightarrow \Re, & Z_{t_{1}-t_{0}}(f) & := & f(t_{1}) \\
\overset{{\color{white}1}}{Z}_{t_{i}-t_{i-1}} &:& \Czo \longrightarrow \Re, & Z_{t_{i}-t_{i-1}}(f) & := & f(t_{i}) - f(t_{i-1}), & \textnormal{for \;$i = 2, \ldots, k$} \\
\overset{{\color{white}1}}{L}_{t_{i}} &:& \Czo \longrightarrow \Re, & L_{t_{i}}(f) & := & f(t_{i}), & \textnormal{for \;$i = 1, \ldots, k$} \\
\end{array}
\end{equation*}
Then, we have
\begin{equation*}
	\left(\!
	\begin{array}{c}
	L_{t_{1}}(f) \\ \\ L_{t_{2}}(f) \\ \\ \vdots \\ \\ L_{t_{k}}(f) 
	\end{array}
	\!\right)
	\;\; = \;\;
	\left(\!
	\begin{array}{c}
	f(t_{1}) \\ \\ f(t_{2}) \\ \\ \vdots \\ \\ f(t_{k}) 
	\end{array}
	\!\right)
	\;\; = \;\;
	\underset{\textnormal{\large$T$}}{\underbrace{
	\left[
	\begin{array}{ccccccc}
	1 & 0 & 0 & \cdots & \cdots & 0 & 0 \\
	1 & 1 & 0 & \cdots & \cdots & 0 & 0 \\
	1 & 1 & 1 & \cdots & \cdots & 0 & 0 \\
	\vdots & \vdots & \vdots & \ddots & \ddots & 0 & 0 \\
	\vdots & \vdots & \vdots & \ddots & \ddots & 0 & 0 \\
	1 & 1 & 1 & \cdots & \cdots & 1 & 0 \\
	1 & 1 & 1 & \cdots & \cdots & 1 & 1 \\
	\end{array}
	\right]
	}}
	\cdot
	\left(\!
	\begin{array}{c}
	f(t_{1}) \\ \\ f(t_{2}) - f(t_{1}) \\ \\ \vdots \\ \\ f(t_{k}) - f(t_{k-1})
	\end{array}
	\!\right)
	\;\; = \;\;
	T \cdot
	\left(\!
	\begin{array}{c}
	Z_{t_{1}-t_{0}}(f) \\ \\ Z_{t_{2}-t_{1}}(f) \\ \\ \vdots \\ \\ Z_{t_{k}-t_{k-1}}(f)
	\end{array}
	\!\right)
\end{equation*}

\vskip 0.3cm
\noindent
The present Theorem will be proved once we establish that the $\Re^{k}$-valued random variable\\
$\pitok = \left(\,L_{t_{1}},\,L_{t_{2}},\,\ldots,\,L_{t_{k}}\,\right) : \Czo \longrightarrow \Re^{k}$
defined on $\left(\Czo,\mathcal{B},W\right)$ has the following multivariate Gaussian distribution:
\begin{equation*}
\pitok
\;\; = \;\;
\left(\!
\begin{array}{c}
L_{t_{1}} \\ \\ L_{t_{2}} \\ \\ \vdots \\ \\ L_{t_{k}} 
\end{array}
\!\right)
\;\; \sim \;\;
N\!\left(\;
\mathbf{\mu} = \mathbf{0}\,,\,
\Sigma = \left[\;\min\{\overset{{\color{white}1}}{t}_{i},t_{j}\}\;\right]_{1\leq i,j\leq k}
\;\right).
\end{equation*}

\vskip 0.3cm
\noindent
To this end, note that since $t_{0} := 0$, by the definition of a Wiener measure,
the $\Re^{k}$-valued random variable\\
$\left(\,Z_{t_{1}-t_{0}},\,Z_{t_{2}-t_{1}},\,\ldots,\,Z_{t_{k}-t_{k-1}}\,\right) : \Czo \longrightarrow \Re^{k}$\;
equals \;$\Pitzk$\; $W$-almost-surely (since $W\!\left(f(0)\overset{{\color{white}:}}{=}0\right)=1$).
These two $\Re^{k}$-valued random variables therefore have the same probability distribution.
By the definition of a Wiener measure again, this common distribution is the following
multivariate Gaussian distribution:
\begin{equation*}
	\left(\!
	\begin{array}{c}
	Z_{t_{1}-t_{0}} \\ \\ Z_{t_{2}-t_{1}} \\ \\ \vdots \\ \\ Z_{t_{k}-t_{k-1}}
	\end{array}
	\!\right)
	\;\; \sim \;\;
	N\!\left(\;
	\mathbf{\mu} = \mathbf{0}\,,\,
	\overset{{\color{white}1}}{\Sigma} = \diag\!\left(\,t_{1}-t_{0},\; \ldots\; ,\; t_{k}-t_{k-1}\,\right)
	\;\right).
\end{equation*}
Since the $\Re^{k}$-valued random variable
$\left(\,L_{t_{1}},\,L_{t_{2}},\,\ldots,\,L_{t_{k}}\,\right) : \Czo \longrightarrow \Re^{k}$
can be obtained from\\
$\left(\,Z_{t_{1}-t_{0}},\,Z_{t_{2}-t_{1}},\,\ldots,\,Z_{t_{k}-t_{k-1}}\,\right): \Czo \longrightarrow \Re^{k}$
via the non-singular linear transformation $T : \Re^{k} \longrightarrow \Re^{k}$,
it follows that $\left(\,L_{t_{1}},\,L_{t_{2}},\,\ldots,\,L_{t_{k}}\,\right)$ also has a
multivariate Gaussian distribution.
Since
$\left(\,Z_{t_{1}-t_{0}},\,Z_{t_{2}-t_{1}},\,\ldots,\,Z_{t_{k}-t_{k-1}}\,\right)$
has mean vector zero, so does 
$\left(\,L_{t_{1}},\,L_{t_{2}},\,\ldots,\,L_{t_{k}}\,\right)$.
It remains only to compute the covariance matrix of
$\left(\,L_{t_{1}},\,L_{t_{2}},\,\ldots,\,L_{t_{k}}\,\right)$,
which we now do: For $t_{i} < t_{j}$, we have
\begin{eqnarray*}
	\Cov\!\left(\,L_{t_{i}}\,,\,L_{t_{j}}\,\right)
	& = & \Cov\!\left(\,
		Z_{t_{1}-t_{0}} + Z_{t_{2}-t_{1}} + \cdots + Z_{t_{i} - t_{i-1}}\,,\,
		Z_{t_{1}-t_{0}} + Z_{t_{2}-t_{1}} + \cdots + Z_{t_{j} - t_{j-1}}
		\,\right)
	\\
	& = & \Cov\!\left(\,
		\sum_{a\,=\,1}^{i}\,Z_{t_{a}-\,t_{a-1}} \,,\,
		\sum_{b\,=\,1}^{j}\,Z_{t_{b}-\,t_{b-1}}
		\,\right)
	\;\; = \;\; \sum_{a\,=\,1}^{i}\,\sum_{b\,=\,1}^{j}\Cov\!\left(\,Z_{t_{a}-\,t_{a-1}}\,,\,Z_{t_{b}-\,t_{b-1}}\,\right)
	\\
	& = & \sum_{a\,=\,1}^{i}\Cov\!\left(\,Z_{t_{a}-\,t_{a-1}}\,,\,Z_{t_{a}-\,t_{a-1}}\,\right)
	\;\;=\;\; \sum_{a\,=\,1}^{i}\Var\!\left(\,Z_{t_{a}-\,t_{a-1}}\,\right)
	\;\;=\;\; \sum_{a\,=\,1}^{i}\left(\,t_{a}-\,t_{a-1}\,\right)
	\\
	& = & \left(\,t_{1}-\,t_{0}\,\right) \;+\; \left(\,t_{2}-\,t_{1}\,\right)
		\;+\; \cdots 
		\;+\; \left(\,t_{i-1}-\,t_{i-2}\,\right) \;+\; \left(\,t_{i}-\,t_{i-1}\,\right)
	\\
	& = & t_{i} \;\; = \;\; \min\!\left\{\,t_{i}\,,t_{j}\,\right\},
\end{eqnarray*}
as required.
This completes the proof of the Theorem.
\qed

\begin{theorem}[Uniqueness of the Wiener measure]
\label{WienerMeasureUniqueness}
\mbox{}\vskip 0.2cm
\noindent
Any two Wiener measures on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ must in fact be equal.
\end{theorem}
\proof
By Theorem \ref{WienerFiniteDimensionalDistributions}, the collection of finite-dimensional distributions
of a Wiener measure on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ is completely determined.
Thus, any two Wiener measures $W_{1}$ and $W_{2}$ must the exactly the same finite-dimensional distributions,
which in turn implies that $W_{1}$ and $W_{2}$ must agree on the entire collection of finite-dimensional
subsets of $\Czo$. Lastly, recall that the finite-dimensional subsets of $\Czo$ form a separating class of the
Borel $\sigma$-algebra of $\left(\Czo,w\Vert\,\cdot\,\Vert_{\infty}\right)$ (Example 1.3, p.11, \cite{Billingsley1999}).
We may now conclude that $W_{1} = W_{2}$, as Borel probability measures on
$\left(\Czo,w\Vert\,\cdot\,\Vert_{\infty}\right)$.
\qed

\begin{theorem}[Existence of the Wiener measure]
\label{WienerMeasureExistence}
\mbox{}\vskip 0.2cm
\noindent
There exists a Wiener measure on $\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$.
\end{theorem}
\proof
Let $\xi_{1}, \xi_{2}, \ldots\, : \Omega \longrightarrow \Re$ be a sequence of
independent and identically distributed standard Gaussian $\Re$-valued
random variables defined on the probability space $(\Omega,\mathcal{A},\mu)$
(i.e. with expectation value zero and common finite variance $\sigma^{2} = 1$).
Define the random variables:
\begin{equation*}
	\left\{\begin{array}{ccccll}
	S_{0}
	&:&\overset{{\color{white}1}}{\Omega} \longrightarrow \Re
	&:& \omega \;\longmapsto\; 0,
	& \textnormal{and}
	\\ \\
	S_{n}
	&:&	\Omega \longrightarrow \Re
	&:&	\omega \;\longmapsto\; \overset{n}{\underset{i=1}{\textnormal{\Large$\sum$}}}\;\xi_{i}(\omega),
	& \textnormal{for each $n \in \N$}.
	\end{array}\right.
\end{equation*}

\vskip 0.2cm
\noindent
For each $n \in \N$, define \,$X^{(n)} \,:\, \Omega \;\longrightarrow\;C[0,1]$\, as follows:
\begin{equation*}
	X^{(n)}(\omega)(t)
	\;\; := \;\;
	\dfrac{1}{\sqrt{n}}
	\left\{\;
	S_{i-1}(\omega) \;+\; n\left(t - \dfrac{i-1}{n}\right)\xi_{i}(\omega)
	\,\right\},
	\;\;
	\textnormal{for each $\omega \in \Omega$, \;$t \in \left[\frac{i-1}{n},\frac{i}{n}\right]$, \;$i = 1,2,3,\ldots,n$}.
\end{equation*}

\vskip 0.2cm
\noindent
For each $n \in \N$ and each $t \in [0,1]$, define
\;$X^{(n)}_{t} : \,\Omega \, \longrightarrow \, \Re$\;
as follows:
\begin{equation*}
	X^{(n)}_{t}(\omega) \;\; := \;\; X^{(n)}(\omega)(t),
	\quad
	\textnormal{for each $\omega \in \Omega$}.
\end{equation*}

\begin{center}
\begin{minipage}{6.5in}
\noindent
\textbf{Claim 1:}
\vskip 0.1cm
\noindent
The sequence $\left\{\,P_{X^{(n)}}\right\}_{n\in\N}$ of Borel probability measures on
$\left(\Czo,\Vert\,\cdot\,\Vert_{\infty}\right)$ induced by the $X^{(n)}$'s is tight.
\end{minipage}
\end{center}

\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
