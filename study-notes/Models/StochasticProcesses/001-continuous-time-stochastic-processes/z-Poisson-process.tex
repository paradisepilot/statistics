
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Poisson Processes}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

Suppose:
\begin{itemize}
\item
	$(\Omega,\mathcal{A},\mu)$\, is a probability space.
\item
	$\eta_{1}\,, \eta_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	form a sequence of independent and identically distributed
	exponential random variables with rate \,$\lambda > 0$\,
	defined on \,$(\Omega,\mathcal{A},\mu)$.
\item
	$\xi_{0} : \Omega \longrightarrow [\,0,\infty)$\, is the almost-surely zero function on $\Omega$,\,
	i.e. $P(\,\xi_{0} = 0\,) = 1$.
\item
	$\xi_{1}\,, \xi_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	denote the sequence of random variables on
	\,$(\Omega,\mathcal{A},\mu)$\, defined by:
	\begin{equation*}
	\xi_{n}(\omega) \; := \; \eta_{1}(\omega) + \cdots + \eta_{n}(\omega),
	\quad
	\textnormal{for each \,$n \in \N$,\, $\omega \in \Omega$}
	\end{equation*}
\end{itemize}
Define the $(\N\cup\{\,0\,\})$-valued stochastic process
\,$\left\{\,N_{t} : \Omega \overset{{\color{white}-}}{\longrightarrow} \N\cup\{0\}\,\right\}_{t\in[\,0,\infty)}$\,
as follows:
\begin{equation*}
N_{t}(\omega)
\;\; := \;\;
	\max\left\{\,\left.
		n \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{n}(\omega) \,\leq\, t
		\,\right\},
\quad
\textnormal{for each \,$t \in [\,0,\infty)$,\, $\omega \in \Omega$}
\end{equation*}
We will call \,$\{\,N_{t}\,\}_{t\in[\,0,\infty)}$\, a \textbf{Poisson process with intensity $\lambda > 0$}.

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{proposition}[At each time point, a Poisson process follows a Poisson distribution]
\mbox{}
\vskip 0.15cm
\noindent
Suppose \,$\{\,N_{t}\,\}_{t\in[\,0,\infty)}$\, is a Poisson process with intensity $\lambda > 0$.
Then, the following statements hold:
\begin{enumerate}
\item
	$P\!\left(\,\overset{{\color{white}.}}{N}_{0} = 0\,\right)\,=\,1$.
\item
	For each $t > 0$, the random variable \,$N_{t}$\,
	follows the Poisson distribution with rate $\lambda t$, i.e.
	\begin{equation*}
	P\!\left(\,\overset{{\color{white}.}}{N}_{t} = n\,\right)
	\;\; = \;\;
		\exp(-\,\lambda t)\cdot\dfrac{(\lambda\,t)^{n}}{n!}\,,
	\quad
	\textnormal{for each \,$n = 0, 1, 2, \ldots$}
	\end{equation*}
\end{enumerate}
\end{proposition}
\proof
Observe that
\begin{eqnarray*}
N_{t}(\omega) < n
& \Longleftrightarrow &
	\max\left\{\,\left.
		k \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{k}(\omega) \,\leq\, t
		\,\right\}
	\;<\; n
\\
& \Longleftrightarrow &
	n \,\notin\,
	\left\{\,\left.
		k \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{k}(\omega) \,\leq\, t
		\,\right\}
\\
& \overset{{\color{white}1}}{\Longleftrightarrow} &
	\xi_{n}(\omega) \,>\, t
\end{eqnarray*}
Hence,
\begin{eqnarray*}
P\!\left(\,N_{t} = n\,\right)
& = &
	P\!\left(\,n \,\overset{{\color{white}.}}{\leq}\, N_{t} \,<\, n+1\,\right)
\;\; = \;\;
	P\!\left(\, N_{t} \,\overset{{\color{white}.}}{<}\, n+1 \,\right)
	\; - \;
	P\!\left(\, N_{t} \,\overset{{\color{white}.}}{<}\, n \,\right)
\\
& = &
	P\!\left(\, \xi_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
	\; - \;
	P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t \,\right)
\end{eqnarray*}
Thus, the Proposition follows immediately from:
\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad
For each $n \in \N$ and $t > 0$, we have:
\begin{equation*}
P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t \,\right)
\;\; = \;\;
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;
	\dfrac{(\lambda t)^{k}}{k!}
\end{equation*}
\vskip 0.2cm
\noindent
Proof of Claim 1:\quad
We proceed by induction on $n = 1, 2, \ldots$\,.
\vskip 0.2cm
\noindent
First, for $n = 1$, note that
\,$P\!\left(\, \xi_{1} \,\overset{{\color{white}.}}{>}\, t \,\right)$
$=$ $P\!\left(\, \eta_{1} \,\overset{{\color{white}.}}{>}\, t \,\right)$
$=$ $\exp(\,-\,\lambda t\,)$.\,
Next, we assume that Claim 1 holds for some $n$ (induction hypothesis).
We establish validity of Claim 1 for $n+1$.
\begin{eqnarray*}
P\!\left(\, \xi_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
& = &
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
\;\; = \;\;
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,,\, \eta_{n+1} \,>\, t \,\right)
	\, + \,
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,,\, \eta_{n+1} \,\leq\, t \,\right)
\\
& = &
	P\!\left(\, \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
	\, + \,
	P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t - \eta_{n+1} \,,\, t \,\geq\, \eta_{n+1} \,\right)
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\int_{t-\eta}^{\infty}\; f_{\xi_{n},\,\eta_{n+1}}(\xi,\eta) \;\,\d\xi\,\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\int_{t-\eta}^{\infty}\; f_{\xi_{n}}(\xi) \cdot f_{\eta_{n+1}}(\eta) \;\,\d\xi\,\d\eta,
	\quad
	\textnormal{by independence of \,$\xi_{n}$\, and \,$\eta_{n+1}$}
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\left(\int_{t-\eta}^{\infty}\; f_{\xi_{n}}(\xi) \;\d\xi \right) \cdot f_{\eta_{n+1}}(\eta)\;\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\,P(\,\xi_{n}>t-\eta\,) \cdot f_{\eta_{n+1}}(\eta)\;\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\,
		\exp(\,-\,\lambda (t-\eta)\,)
		\cdot
		\overset{n-1}{\underset{k=0}{\sum}}\;
		\dfrac{\lambda^{k}(t-\eta)^{k}}{k!}
		\cdot
		\lambda\cdot\exp(-\lambda\eta)
		\;\d\eta,
	\;\;
	\textnormal{by induction hypothesis}
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;\;
	\dfrac{\lambda^{k+1}}{k!}
	\int_{0}^{t}\,
		(t-\eta)^{k}
		\,\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;\;
	\dfrac{\lambda^{k+1}}{k!}
	\cdot
	\dfrac{t^{k+1}}{k+1}
\\
& = &
	\cdots
\;\; = \;\;
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n}{\underset{k=0}{\sum}}\;
	\dfrac{(\lambda t)^{k}}{k!},
\end{eqnarray*}
This proves Claim 1, and completes the proof of the Proposition.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{theorem}\label{TimeTranslatedPoissonProcessIsItselfPoissonProcess}
\mbox{}
\vskip 0.15cm
\noindent
Suppose:
\begin{itemize}
\item
	$\left\{\,N_{t} : (\Omega,\mathcal{A},\mu) \overset{{\color{white}-}}{\longrightarrow} \N\cup\{0\} \;\right\}_{t \in [\,0,\infty)}$\,
	is a Poisson process.
\item
	For each fixed $t \in [\,0,\infty)$,
	$\left\{\,N^{(t)}_{s} : (\Omega,\mathcal{A},\mu) \overset{{\color{white}-}}{\longrightarrow} \Re \;\right\}_{s \in [\,0,\infty)}$\;
	is the stochastic process defined by:
	\begin{equation*}
	N^{(t)}_{s} \;\; := \;\; N_{t+s} \,-\, N_{t}\,,
	\quad
	\textnormal{for each \,$s \in [\,0,\infty)$}
	\end{equation*}
\end{itemize}
Then,
\begin{enumerate}
\item
	$\left\{\,N^{(t)}_{s}\right\}_{s \in [\,0,\infty)}$\, is a Poisson process, for each fixed $t \in [\,0,\infty)$.
	Furthermore, the probability distributions of \,$N^{(t)}_{s}$\, and \,$N_{s}$\, are equal,
	for each \,$s, t \in [\,0,\infty)$.
\item
	$N^{(t)}_{s}$\, and \,$N_{t}$\, are independent random variables, for each \,$s, t \in [\,0,\infty)$.
\end{enumerate}
\end{theorem}
\proof
Recall that
\begin{equation*}
N_{t}(\omega)
\;\; := \;\;
	\max\left\{\,\left.
		n \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{n}(\omega) \,\leq\, t
		\,\right\},
\quad
\textnormal{for each \,$t \in [\,0,\infty)$,\, $\omega \in \Omega$}
\end{equation*}
where
\begin{itemize}
\item
	$\xi_{0} : \Omega \longrightarrow [\,0,\infty)$\, is the almost-surely zero function on $\Omega$,\,
and
\item
	$\xi_{1}\,, \xi_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	denote the sequence of random variables on
	\,$(\Omega,\mathcal{A},\mu)$\, defined by:
	\begin{equation*}
	\xi_{n}(\omega) \; := \; \eta_{1}(\omega) + \cdots + \eta_{n}(\omega),
	\quad
	\textnormal{for each \,$n \in \N$,\, $\omega \in \Omega$},
	\end{equation*}
	where
	\,$\eta_{1}\,, \eta_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	form a sequence of independent and identically distributed
	exponential random variables with rate \,$\lambda > 0$\,
	defined on \,$(\Omega,\mathcal{A},\mu)$.
\end{itemize}
Define
\begin{equation*}
\eta^{(t)}_{1} \; := \; \xi_{N_{t}+1} \,-\, t\,,
\quad\textnormal{and}\quad
\eta^{(t)}_{n} \; := \; \eta_{N_{t}+n}\,,
\quad\textnormal{for \,$n = 2, 3, \ldots$}
\end{equation*}
Next, define:
\begin{equation*}
\xi^{(t)}_{n} \; := \; \eta^{(t)}_{1} \,+\, \eta^{(t)}_{2} \,+\, \cdots \,+\, \eta^{(t)}_{n}\,,
\quad\textnormal{for \,$n = 1, 2, \ldots$}
\end{equation*}

\vskip 0.5cm
\noindent
We now state and prove a series of Claims, from which the Theorem will follow readily.

\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad $N^{(t)}_{s} \; = \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}$
\vskip 0.2cm
\noindent
Proof of Claim 1:\quad
For notational convenience, we define
$M^{(t)}_{s} \; := \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}$.
We need to show that:
\begin{equation*}
\max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}
\;\; =: \;\;
	M^{(t)}_{s}
\;\; = \;\;
	N_{t+s} \,-\, N_{t}
\;\; =: \;\;
	N^{(t)}_{s}
\end{equation*}
To this end, first note that
\begin{equation}\label{xitn}
\xi^{(t)}_{n} \;\; := \;\; \xi_{N_{t}+n} \;-\; t.
\end{equation}
Indeed,
\begin{eqnarray*}
\xi^{(t)}_{n}
& := &
	\eta^{(t)}_{1} + \eta^{(t)}_{2} + \cdots + \eta^{(t)}_{n}
\;\; = \;\;
	\left(\,\xi_{N_{t}+1} \,\overset{{\color{white}.}}{-}\, t\,\right)
	\, + \,
	\eta_{N_{t}+2}
	\, + \,
	\cdots
	\, + \,
	\eta_{N_{t}+n}
\\
& = &
	\left(\,\eta_{1} + \cdots +  \eta_{N_{t}} +\eta_{N_{t}+1} \,\overset{{\color{white}.}}{-}\, t\,\right)
	\, + \,
	\eta_{N_{t}+2}
	\, + \,
	\cdots
	\, + \,
	\eta_{N_{t}+n}
\\
& = &
	\left(\,\eta_{1} \,\overset{{\color{white}.}}{+}\, \cdots \,+\,  \eta_{N_{t}}
	\,+\, \eta_{N_{t}+1} \,+\, \eta_{N_{t}+2} \,+\, \cdots\,+\, \eta_{N_{t}+n}
	\,\right)
	\, - \,
	t
\;\; = \;\;
	\xi_{N_{t}+n} \,-\, t\,,
	\quad
	\textnormal{as desired}
\end{eqnarray*}
Next, note:
\begin{eqnarray*}
M^{(t)}_{s} \; := \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}
& \Longleftrightarrow &
	\xi^{(t)}_{M^{(t)}_{s}} \;\leq\; s \;<\; \xi^{(t)}_{M^{(t)}_{s}+1}
\\
& \Longleftrightarrow &
	\xi_{N_{t}+M^{(t)}_{s}} \,-\, t \;\;\leq\;\; s \;\;<\;\; \xi_{N_{t}+M^{(t)}_{s}+1} \,-\, t\,,
	\quad
	\textnormal{by \eqref{xitn}}
\\
& \Longleftrightarrow &
	\xi_{N_{t}+M^{(t)}_{s}} \;\;\leq\;\; t + s \;\;<\;\; \xi_{N_{t}+M^{(t)}_{s}+1}
\\
& \Longleftrightarrow &
	N_{t+s}
	\;\; := \;\;
		\max\left\{\,\left.\overset{{\color{white}1}}{n}\in\N\cup\{0\}\,\;\right\vert\;\xi_{n} \leq t+s \,\right\}
	\;\; = \;\;
		N_{t} + M^{(t)}_{s}
\\
& \Longleftrightarrow &
	M^{(t)}_{s}
	\;\; = \;\;
		N_{t+s} \, - \,N_{t}
\end{eqnarray*}
This proves Claim 1.

\vskip 0.5cm
\noindent
\textbf{Claim 2:}\quad
$P\!\left(\,\left.\eta^{(t)}_{1} > s \;\,\right\vert\, N_{t} = n\,\right)$\;
$=$
\;$P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}\,\right)$,\;\;
for any \,$n = 0, 1, 2, \ldots$\,.
\vskip 0.2cm
\noindent
Proof of Claim 2:\quad
First, note that
\begin{equation*}
N_{t}\,=\,n
\quad\Longleftrightarrow\quad
	\max\left\{\,\left.
	n \overset{{\color{white}.}}{\in} \N\cup\{0\}
	\,\;\right\vert\;
	\xi_{n} \,\leq\, t
	\,\right\}
	\;=\; n
\quad\Longleftrightarrow\quad
	\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t \,<\, \xi_{n+1}
\end{equation*}
Hence,
\begin{equation*}
P(\,N_{t}\,=\,n\,)
\;\; = \;\;
	P\!\left(\; \xi_{n} \,\overset{{\color{white}.}}{\leq}\, t \,<\, \xi_{n+1} \,\right)
\end{equation*}
On the other hand,
\begin{eqnarray*}
P\!\left(\,\eta^{(t)}_{1}\,>\,s\,,\,N_{t}\,=\,n\,\right)
& = &
	P\!\left(\;
		\xi_{n+1}-t\,>\,s
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t \,<\, \xi_{n+1}
		\,\right)
\;\; = \;\;
	P\!\left(\;
		t+s\,<\,\xi_{n+1}
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,,\,
		t \,<\, \xi_{n+1}
		\,\right)
\\
& = &
	P\!\left(\;
		t+s\,<\,\xi_{n+1}
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,\right)
\;\; = \;\;
	P\!\left(\;
		t+s\,<\,\xi_{n} + \eta_{n+1}
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,\right)
\\
& = &
	P\!\left(\;
		t-\xi_{n}+s\,<\,\eta_{n+1}
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,\right)
\;\; = \;\;
	\int_{0}^{t}\int_{t-\xi+s}^{\infty}\;
		f_{\xi_{n},\eta_{n+1}}(\xi,\eta)
		\;\d\,\eta\;\d\,\xi
\\
& = &
	\int_{0}^{t}\int_{t-\xi+s}^{\infty}\;
		f_{\xi_{n}}(\xi) \cdot f_{\eta_{n+1}}(\eta)
		\;\d\,\eta\;\d\,\xi\,,
	\quad
	\textnormal{by independence of \,$\xi_{n}$\, and \,$\eta_{n+1}$}
\\
& = &
	\int_{0}^{t}
		\left(\,\int_{t-\xi+s}^{\infty}\; f_{\eta_{n+1}}(\eta) \;\d\,\eta \,\right)
		f_{\xi_{n}}(\xi)
		\;\d\,\xi
\;\; = \;\;
	\int_{0}^{t}
		P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} t-\xi+s\,\right)
		\cdot
		f_{\xi_{n}}(\xi)
		\;\d\,\xi
\\
& = &
	\int_{0}^{t}
		P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} t-\xi\,\right)
		\cdot
		P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
		\cdot
		f_{\xi_{n}}(\xi)
		\;\d\,\xi\,,
		\quad
		\textnormal{by Theorem \ref{ExponentialMemoryless}}
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	\int_{0}^{t}
		P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} t-\xi\,\right)
		\cdot
		f_{\xi_{n}}(\xi)
		\;\d\,\xi
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	\int_{0}^{t}
		\left(\,\int_{t-\xi}^{\infty}\;
		f_{\eta_{n+1}}(\eta)
		\,\d\,\eta
		\right)
		\cdot
		f_{\xi_{n}}(\xi)
		\;\d\,\xi
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	\int_{0}^{t}\int_{t-\xi}^{\infty}\;
		f_{\eta_{n+1}}(\eta) \cdot f_{\xi_{n}}(\xi)
		\;\d\,\eta\;\d\,\xi
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	\int_{0}^{t}\int_{t-\xi}^{\infty}\;
		f_{\xi_{n},\eta_{n+1}}(\xi,\eta)
		\;\d\,\eta\;\d\,\xi
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	P\!\left(\;
		t-\xi_{n}\,<\,\eta_{n+1}
		\,,\,
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,\right)
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	P\!\left(\;
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t
		\,,\,
		t\,<\,\xi_{n}+\eta_{n+1}
		\,\right)
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	P\!\left(\;
		\xi_{n} \,\overset{{\color{white}.}}{\leq}\, t \,<\,\xi_{n+1}
		\,\right)
\\
& = &
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right),
\end{eqnarray*}
which implies:
\begin{eqnarray*}
P\!\left(\,\left.\eta^{(t)}_{1}\,>\,s\;\,\right\vert\;N_{t}\,=\,n\,\right)
& = &
	\dfrac{
		P\!\left(\,\eta^{(t)}_{1}\,>\,s\,,\,N_{t}\,=\,n\,\right)
		}{
		P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right)
		}
\;\; = \;\;
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s\,\right)
\;\; = \;\;
	P\!\left(\,\eta_{1} \overset{{\color{white}.}}{>} s\,\right),
\end{eqnarray*}
where the last equality follows from the fact that the $\eta_{i}$'s
are identically distributed.
This proves Claim 2.

\vskip 0.5cm
\noindent
\textbf{Claim 3:}\quad
$P\!\left(\,\left.\eta^{(t)}_{1} > s_{1}, \,\ldots\, ,\eta^{(t)}_{k} > s_{k} \,\;\right\vert\; N_{t} = n\;\right)$\;
$=$
\;$P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)$,\;\;
for each \,$n = 0, 1, 2, \ldots$\,.
\vskip 0.2cm
\noindent
Proof of Claim 3:\quad
\begin{eqnarray*}
&&
	P\!\left(\,\eta^{(t)}_{1} > s_{1} \;,\; \eta^{(t)}_{2} > s_{2} \;,\; \ldots \;,\; \eta^{(t)}_{k} > s_{k} \;,\; N_{t} = n\,\right)
\\
&=&
	P\!\left(\,
		\xi_{n+1} - t \overset{{\color{white}.}}{>} s_{1} \;,\; N_{t} = n \;,\; \eta_{n+2} > s_{2} \;,\; \ldots \;,\; \eta_{n+k} > s_{k}
		\,\right)
\\
&=&
	P\!\left(\,
		\eta^{(t)}_{1} \overset{{\color{white}.}}{>} s_{1} \;,\; N_{t} = n
		\,\right)
	\cdot
	P\!\left(\,
		\eta_{n+2} \overset{{\color{white}.}}{>} s_{2}
		\,\right)
	\,\cdots\,
	P\!\left(\,
		\eta_{n+k} \overset{{\color{white}.}}{>} s_{k}
		\,\right)
\\
&=&
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s_{1}\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right)
	\cdot
	P\!\left(\,
		\eta_{n+2} \overset{{\color{white}.}}{>} s_{2}
		\,\right)
	\,\cdots\,
	P\!\left(\,
		\eta_{n+k} \overset{{\color{white}.}}{>} s_{k}
		\,\right),
	\quad
	\textnormal{by proof of Claim 2}
\\
&=&
	P\!\left(\,\eta_{n+1} \overset{{\color{white}.}}{>} s_{1}\,\right)
	\cdot
	P\!\left(\,
		\eta_{n+2} \overset{{\color{white}.}}{>} s_{2}
		\,\right)
	\,\cdots\,
	P\!\left(\,
		\eta_{n+k} \overset{{\color{white}.}}{>} s_{k}
		\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right)
\\
&=&
	P\!\left(\,\eta_{1} \overset{{\color{white}.}}{>} s_{1}\,\right)
	\cdot
	P\!\left(\,
		\eta_{2} \overset{{\color{white}.}}{>} s_{2}
		\,\right)
	\,\cdots\,
	P\!\left(\,
		\eta_{k} \overset{{\color{white}.}}{>} s_{k}
		\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right),
\end{eqnarray*}
from which Claim 3 immediately follows. This completes the proof of Claim 3.

\vskip 0.5cm
\noindent
\textbf{Claim 4:}\quad
For each $t \in [\,0,\infty)$,
\,$\eta^{(t)}_{1}$\, has the same probability distribution as \,$\eta_{1}$;\,
in particular, \,$\eta^{(t)}_{1}$\, follows the exponential distribution with rate $\lambda > 0$.
\vskip 0.2cm
\noindent
Proof of Claim 4:\quad
\begin{eqnarray*}
P\!\left(\,\eta^{(t)}_{1} > s\,\right)
&=&
	\overset{\infty}{\underset{n = 0}{\sum}}\;P\!\left(\,\eta^{(t)}_{1} > s\,,\,N_{t} = n\,\right)
\;\; = \;\;
	\overset{\infty}{\underset{n = 0}{\sum}}\;
	P\!\left(\,\left.\eta^{(t)}_{1} > s\,\;\right\vert\, N_{t} = n\,\right)
	\cdot
	P\!\left(\,N_{t} = n\,\right)
\\
&=&
	\overset{\infty}{\underset{n = 0}{\sum}}\;
	P\!\left(\,\eta_{1} > s\,\right)
	\cdot
	P\!\left(\,N_{t} = n\,\right),
	\quad
	\textnormal{by Claim 2}
\\
&=&
	P\!\left(\,\eta_{1} > s\,\right)
	\cdot
	\overset{\infty}{\underset{n = 0}{\sum}}\; P\!\left(\,N_{t} = n\,\right)
\;\; = \;\;
	P\!\left(\,\eta_{1} > s\,\right) \cdot 1
\;\; = \;\;
	P\!\left(\,\eta_{1} > s\,\right)
\end{eqnarray*}
This proves Claim 4.


\vskip 0.5cm
\noindent
\textbf{Claim 5:}\quad
$P\!\left(\;\eta^{(t)}_{1} > s_{1} \,,\, \ldots \,,\, \eta^{(t)}_{k} > s_{k} \,\right)$
\,$=$\,
$P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)$,\;\;
for each \,$k = 1, 2, \ldots$\,.
\vskip 0.2cm
\noindent
Proof of Claim 5:\quad
\begin{eqnarray*}
P\!\left(\;\eta^{(t)}_{1} > s_{1} \,,\, \ldots \,,\, \eta^{(t)}_{k} > s_{k} \,\right)
& = &
	\overset{\infty}{\underset{n=0}{\sum}}\;
	P\!\left(\;\eta^{(t)}_{1} > s_{1} \,,\, \ldots \,,\, \eta^{(t)}_{k} > s_{k} \,,\, N_{t} = n\;\right)
\\
& = &
	\overset{\infty}{\underset{n=0}{\sum}}\;
	P\!\left(\,\left.\eta^{(t)}_{1} > s_{1} \,,\, \ldots \,,\, \eta^{(t)}_{k} > s_{k} \,\;\right\vert\; N_{t} = n\;\right)
	\cdot
	P\!\left(\,N_{t} = n\;\right)
\\
& = &
	\overset{\infty}{\underset{n=0}{\sum}}\;
	P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)
	\cdot
	P\!\left(\,N_{t} = n\;\right),
	\quad
	\textnormal{by Claim 3}
\\
& = &
	P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)
	\cdot
	\overset{\infty}{\underset{n=0}{\sum}}\; P\!\left(\,N_{t} = n\;\right)
\\
& = &
	P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)
	\cdot 1
\\
& = &
	P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \,\cdots\, P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)
\end{eqnarray*}
This proves Claim 5.


\vskip 0.5cm
\noindent
\textbf{Claim 6:}\quad
$\eta^{(t)}_{k}$\, follows an exponential distribution of rate \,$\lambda > 0$,\,
for each \,$k \in \N$.
\vskip 0.2cm
\noindent
Proof of Claim 6:\quad
\begin{eqnarray*}
P\!\left(\;\eta^{(t)}_{k} > s \,\right)
&=&
	P\!\left(\;\eta^{(t)}_{1} > 0 \,,\, \ldots \,,\, \eta^{(t)}_{k-1} > 0 \,,\, \eta^{(t)}_{k} > s \,\right)
\\
&=&
	P\!\left(\,\eta_{1} \overset{{\color{white}.}}{>} 0\,\right)
	\,\cdots\,
	P\!\left(\,\eta_{k-1} \overset{{\color{white}.}}{>} 0\,\right)
	\,\cdot\,
	P\!\left(\,\eta_{k} \overset{{\color{white}.}}{>} s\,\right),
	\quad
	\textnormal{by Claim 5}
\\
&=&
	P\!\left(\,\eta_{k} \overset{{\color{white}.}}{>} s\,\right)
\end{eqnarray*}
Thus, \,$\eta^{(t)}_{k}$\, has the same probability distribution as \,$\eta_{k}$,\,
namely, the exponential distribution of rate \,$\lambda > 0$.\,
This proves Claim 6.

\vskip 0.5cm
\noindent
\textbf{Claim 7:}\quad
$\eta^{(t)}_{1}$,\, $\eta^{(t)}_{2}$\, $\ldots$\, are independent random variables.
\vskip 0.2cm
\noindent
Proof of Claim 7:\quad
By Claim 5 and Claim 6, we have, for any $k \in \N$,
\begin{eqnarray*}
P\!\left(\;\eta^{(t)}_{1} > s_{1} \,,\, \ldots \,,\, \eta^{(t)}_{k} > s_{k} \,\right)
&=&
	P\!\left(\,{\color{white}.} \eta_{1} {\color{white}.} > \overset{{\color{white}-}}{s}_{1}\,\right)
	\,\cdots\,
	P\!\left(\,{\color{white}.} \eta_{k} {\color{white}.} > \overset{{\color{white}-}}{s}_{k}\,\right),
	\quad
	\textnormal{by Claim 5}
\\
&=&
	P\!\left(\,\eta^{(t)}_{1} > \overset{{\color{white}-}}{s}_{1}\,\right)
	\,\cdots\,
	P\!\left(\,\eta^{(t)}_{k} > \overset{{\color{white}-}}{s}_{k}\,\right),
	\quad
	\textnormal{by Claim 6}
\end{eqnarray*}
This proves the independence of
$\eta^{(t)}_{1}$,\, $\eta^{(t)}_{2}$\, $\ldots$\,
and completes the proof of Claim 7.

\vskip 0.5cm
\noindent
\textbf{Claim 8:}\quad
$\eta^{(t)}_{1}$\,,\;$\ldots$\;, $\eta^{(t)}_{k}$\, and \,$N_{t}$\, are independent random variables,
for each \,$t \in [\,0,\infty)$\, and each \,$k \in \N$.
\vskip 0.2cm
\noindent
Proof of Claim 8:\quad
\begin{eqnarray*}
&&
	P\!\left(\,\eta^{(t)}_{1} > s_{1} \;,\; \ldots \;,\; \eta^{(t)}_{k} > s_{k} \;,\; N_{t} = n\,\right)
\\
&=&
	P\!\left(\,{\color{white}.}\eta_{1}{\color{white}.} \overset{{\color{white}.}}{>} s_{1}\,\right)
	\cdots
	P\!\left(\,{\color{white}.}\eta_{k}{\color{white}.} \overset{{\color{white}.}}{>} s_{k}\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right),
	\quad
	\textnormal{by (proof of) Claim 3}
\\
&=&
	P\!\left(\,\eta^{(t)}_{1} \overset{{\color{white}.}}{>} s_{1}\,\right)
	\cdots
	P\!\left(\,
		\eta^{(t)}_{k} \overset{{\color{white}.}}{>} s_{k}
		\,\right)
	\cdot
	P\!\left(\,N_{t} \overset{{\color{white}-}}{=} n \,\right),
	\quad
	\textnormal{by Claim 6}
\end{eqnarray*}
This proves Claim 8.

%\vskip 0.5cm
%\noindent
%\textbf{Claim 9:}\quad
%$P\!\left(\,\left.N^{(t)}_{s} = a \;\,\right\vert\, N_{t} = b\,\right)$\;
%$=$
%\;$P\!\left(\,N_{s} \overset{{\color{white}1}}{=} a \,\right)$,\;\;
%for each \,$s,\, t \in [\,0,\infty)$\, and each \,$a, b = 0, 1, 2, \ldots$\,.
%\vskip 0.2cm
%\noindent
%Proof of Claim 9:\quad

\vskip 0.5cm
\noindent
We now return the proof of the two statements of the Theorem:
\begin{enumerate}
\item
	By Claim 7, the random variables
	\;$\eta^{(t)}_{1}$, $\eta^{(t)}_{2}$, \,$\ldots$\;
	are independent.
	By Claim 6, \;$\eta^{(t)}_{k}$\; follows an exponential distribution of rate \,$\lambda > 0$,\,
	for each \,$k \in \N$.\,
	By Claim 1, we have, for each \,$t \in [\,0,\infty)$,
	\,$N^{(t)}_{s} \; = \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}$,\,
	where \,$\xi^{(t)}_{n} \,:=\, \eta^{(t)}_{1} + \cdots + \eta^{(t)}_{n}$.
	We may now conclude that
	\,$\left\{\,N^{(t)}_{s}\,\right\}_{s\in[\,0,\infty)}$\, is indeed a Poisson process
	with intensity \,$\lambda > 0$.
	In particular, the probability distributions of \,$N^{(t)}_{s}$\, and \,$N_{s}$\,
	are equal for each $s,\,t \in [\,0,\infty)$.
\item
	By Claim 1, the random variable \,$N^{(t)}_{s}$\, is a (deterministic) function
	of \,$\eta^{(t)}_{1},\,\eta^{(t)}_{2},\,\ldots$\;;
	more specifically,
	\begin{equation*}
	N^{(t)}_{s}
	\; = \;
		\max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}
	\; = \;
		\max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\
		\eta^{(t)}_{1} \,+\, \eta^{(t)}_{2} \,+\, \cdots \,+\, \eta^{(t)}_{n}
		\,\leq\,
		s\right.\,\right\}
	\end{equation*}
	On the other hand, by Claim 8, \,$N_{t}$\, and \,$\eta^{(t)}_{1},\,\eta^{(t)}_{2},\,\ldots$\;
	are all independent random variables.
	This implies in particular that \,$N^{(t)}_{s}$\, and \,$N_{t}$\, are independent random variables.
\end{enumerate}
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{theorem}
\mbox{}
\vskip 0.15cm
\noindent
Let
\,$\left\{\,N_{t} : (\Omega,\mathcal{A},\mu) \overset{{\color{white}-}}{\longrightarrow} \N\cup\{0\} \;\right\}_{t \in [\,0,\infty)}$\,
be a Poisson process.
Then, for each \,$0 = t_{0} < t_{1} < t_{2} < \cdots < t_{n} \in [\,0,\infty)$,\,
the increments
\begin{equation*}
N_{t_{1}} = N_{t_{1}} - N_{t_{0}},\;
N_{t_{2}} - N_{t_{1}},\;
\,\ldots\,,\;
N_{t_{n}} - N_{t_{n-1}}
\end{equation*}
are independent random variables, and have respectively the same probability distributions as
\begin{equation*}
N_{t_{1}},\;
N_{t_{2} - t_{1}},\;
\,\ldots\,,\;
N_{t_{n} - t_{n-1}}
\end{equation*}
\end{theorem}
\proof
First, recall that \,$N_{t_{0}} = N_{0} = 0$\, almost surely;
i.e. \,$P(\,N_{t_{0}} = 0\,) = P(\,N_{0} = 0\,) = 1$.\,
Next, by Theorem \ref{TimeTranslatedPoissonProcessIsItselfPoissonProcess},
we immediately have that:
\begin{equation*}
N_{t_{i}} - N_{t_{i-1}}
\;\;\textnormal{and}\;\;
N_{t_{i} \,-\, t_{i-1}}
\;\;\textnormal{follow the same probability distribution, for each \,$i = 2, 3, \ldots, n$}.
\end{equation*}
It remains to establish independence.
We proceed by induction on the length $n = 1, 2, 3, \ldots $ of an arbitrary initial sequence of
increments of an arbitrary Poisson process.
For $n =1$, there is nothing to prove (since there is just one increment in this case).
For $n = 2$, the required independence (of $N_{t_{2}} - N_{t_{1}}$ and $N_{t_{1}}$)
follows again from Theorem \ref{TimeTranslatedPoissonProcessIsItselfPoissonProcess}.
Next, the induction hypothesis states that
an arbitrary initial sequence of increments of length \,$n$\, of an arbitrary Poisson process
consists of independent random variables.
To complete the proof, we need to show that 
an arbitrary initial sequence of increments of length \,$n+1$
\begin{equation}\label{initialIncrementSequenceLengthNplusOne}
N_{t_{1}} = N_{t_{1}} - N_{t_{0}},\;
\quad
N_{t_{2}} - N_{t_{1}},\;
\quad
\,\ldots\,,\;
\quad
N_{t_{n}} - N_{t_{n-1}},\;
\quad
N_{t_{n+1}} - N_{t_{n}}
\end{equation}
of an arbitrary Poisson process also consists of independent random variables.
To this end, note that, for \,$i = 2, 3, \ldots, n$,
\begin{equation*}
N_{t_{i+1}} - N_{t_{i}}
\;\; = \;\;
	\left(\,N_{t_{i+1}}-N_{t_{1}}\right) \;-\; \left(\,N_{t_{i}} - N_{t_{1}}\right)
\;\; = \;\;
	N^{(t_{1})}_{t_{i+1}\,-\,t_{1}}
	\;-\;
	N^{(t_{1})}_{t_{i}\,-\,t_{1}}
\;\; = \;\;
	N^{(t_{1})}_{s_{i}}
	\;-\;
	N^{(t_{1})}_{s_{i-1}}
\end{equation*}
where \,$s_{i} \,:=\, t_{i+1} - t_{1} \,\geq 0\,$,\,
for \,$i = 1, 2, \ldots, n-1$.\,
Hence, letting \,$s_{0} \,:=\, 0$,\, we see that, by the induction hypothesis,
\begin{equation*}
N_{t_{2}} - N_{t_{1}} = N^{(t_{1})}_{s_{1}} - N^{(t_{1})}_{s_{0}}\,,\;
\quad\ldots\;\;,\quad
N_{t_{n+1}} - N_{t_{n}} = N^{(t_{1})}_{s_{n}} - N^{(t_{1})}_{s_{n-1}}
\end{equation*}
are independent random variables, since they form
an initial sequence of length $n$ of increments of
\,$\left\{\,N^{(t_{1})}_{s}\,\right\}_{s\in[\,0,\infty)}$,
which is a Poisson process,
by Theorem \ref{TimeTranslatedPoissonProcessIsItselfPoissonProcess}.
And, by the Theorem \ref{TimeTranslatedPoissonProcessIsItselfPoissonProcess} again,
\begin{equation*}
N_{t_{1}}
\quad\textnormal{and}\quad
N^{(t_{1})}_{s_{i}}
\quad
\textnormal{are independent, for each \,$i = 1,2,\ldots, n$},
\end{equation*}
which in turn implies that
\begin{equation*}
N_{t_{1}}
\quad\textnormal{and}\quad
N^{(t_{1})}_{s_{i}} - N^{(t_{1})}_{s_{i-1}}
\quad
\textnormal{are independent, for each \,$i = 1,2,\ldots, n$},
\end{equation*}
We may now conclude that all random variables in
\eqref{initialIncrementSequenceLengthNplusOne}
are indeed independent of each other.

\vskip 0.3cm
\noindent
This completes the proof by induction, as well as the proof of the Theorem.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\begin{definition}[Independence and stationarity of increments of a stochastic process]
\mbox{}
\vskip 0.1cm
\noindent
A stochastic process
\,$\left\{\,\overset{{\color{white}.}}{X}_{t} : (\Omega,\mathcal{A},\mu) \longrightarrow \Re \;\right\}_{t \in T}$\,
is said to have:
\begin{itemize}
\item
	\textbf{independent increments}, if
	\begin{equation*}
	X_{t_{1}} - X_{t_{0}}\,,\;
	X_{t_{2}} - X_{t_{1}}\,,\;
	\ldots\,,\;
	X_{t_{n}} - X_{t_{n-1}}
	\end{equation*}
	are independent, for each \,$t_{0}, t_{1}, \ldots, t_{n} \in T$\,
	with \,$t_{0} < t_{1} < \cdots < t_{n}$.
\item
	\textbf{stationary increments}, if,
	for each $t_{1},\, t_{2} \in T$, the probability distribution of
	\begin{equation*}
	X_{t_{1}+h} \,-\, X_{t_{2}+h}
	\end{equation*}
	is independent of $h$, as long as \,$t_{1} + h,\, t_{2} + h \in T$.
\end{itemize}
\end{definition}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{corollary}[Every Poisson process has independent and stationary increments]
\mbox{}
\vskip 0.15cm
\noindent
Every Poisson process has independent and stationary increments.
\end{corollary}
\proof

\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
