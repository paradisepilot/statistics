
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Poisson Processes}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

Suppose:
\begin{itemize}
\item
	$(\Omega,\mathcal{A},\mu)$\, is a probability space.
\item
	$\eta_{1}\,, \eta_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	form a sequence of independent and identically distributed
	exponential random variables with rate \,$\lambda > 0$\,
	defined on \,$(\Omega,\mathcal{A},\mu)$.
\item
	$\xi_{0} : \Omega \longrightarrow [\,0,\infty)$\, is the almost-surely zero function on $\Omega$,\,
	i.e. $P(\,\xi_{0} = 0\,) = 1$.
\item
	$\xi_{1}\,, \xi_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	denote the sequence of random variables on
	\,$(\Omega,\mathcal{A},\mu)$\, defined by:
	\begin{equation*}
	\xi_{n}(\omega) \; := \; \eta_{1}(\omega) + \cdots + \eta_{n}(\omega),
	\quad
	\textnormal{for each \,$n \in \N$,\, $\omega \in \Omega$}
	\end{equation*}
\end{itemize}
Define the stochastic process
\,$\{\,N_{t} : \Omega \longrightarrow \Re\,\}_{t\in[\,0,\infty)}$\,
as follows:
\begin{equation*}
N_{t}(\omega)
\;\; := \;\;
	\max\left\{\,\left.
		n \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{n}(\omega) \,\leq\, t
		\,\right\},
\quad
\textnormal{for each \,$t \in [\,0,\infty)$,\, $\omega \in \Omega$}
\end{equation*}
We will call \,$\{\,N_{t}\,\}_{t\in[\,0,\infty)}$\, a \textbf{Poisson process with intensity $\lambda > 0$}.

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{proposition}[At each time point, a Poisson process follows a Poisson distribution]
\mbox{}
\vskip 0.15cm
\noindent
Suppose \,$\{\,N_{t}\,\}_{t\in[\,0,\infty)}$\, is a Poisson process with intensity $\lambda > 0$.
Then, the following statements hold:
\begin{enumerate}
\item
	$P\!\left(\,\overset{{\color{white}.}}{N}_{0} = 0\,\right)\,=\,1$.
\item
	For each $t > 0$, the random variable \,$N_{t}$\,
	follows the Poisson distribution with rate $\lambda t$, i.e.
	\begin{equation*}
	P\!\left(\,\overset{{\color{white}.}}{N}_{t} = n\,\right)
	\;\; = \;\;
		\exp(-\,\lambda t)\cdot\dfrac{(\lambda\,t)^{n}}{n!}\,,
	\quad
	\textnormal{for each \,$n = 0, 1, 2, \ldots$}
	\end{equation*}
\end{enumerate}
\end{proposition}
\proof
Observe that
\begin{eqnarray*}
N_{t}(\omega) < n
& \Longleftrightarrow &
	\max\left\{\,\left.
		k \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{k}(\omega) \,\leq\, t
		\,\right\}
	\;<\; n
\\
& \Longleftrightarrow &
	n \,\notin\,
	\left\{\,\left.
		k \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{k}(\omega) \,\leq\, t
		\,\right\}
\\
& \overset{{\color{white}1}}{\Longleftrightarrow} &
	\xi_{n}(\omega) \,>\, t
\end{eqnarray*}
Hence,
\begin{eqnarray*}
P\!\left(\,N_{t} = n\,\right)
& = &
	P\!\left(\,n \,\overset{{\color{white}.}}{\leq}\, N_{t} \,<\, n+1\,\right)
\;\; = \;\;
	P\!\left(\, N_{t} \,\overset{{\color{white}.}}{<}\, n+1 \,\right)
	\; - \;
	P\!\left(\, N_{t} \,\overset{{\color{white}.}}{<}\, n \,\right)
\\
& = &
	P\!\left(\, \xi_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
	\; - \;
	P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t \,\right)
\end{eqnarray*}
Thus, the Proposition follows immediately from:
\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad
For each $n \in \N$ and $t > 0$, we have:
\begin{equation*}
P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t \,\right)
\;\; = \;\;
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;
	\dfrac{(\lambda t)^{k}}{k!}
\end{equation*}
\vskip 0.2cm
\noindent
Proof of Claim 1:\quad
We proceed by induction on $n = 1, 2, \ldots$\,.
\vskip 0.2cm
\noindent
First, for $n = 1$, note that
\,$P\!\left(\, \xi_{1} \,\overset{{\color{white}.}}{>}\, t \,\right)$
$=$ $P\!\left(\, \eta_{1} \,\overset{{\color{white}.}}{>}\, t \,\right)$
$=$ $\exp(\,-\,\lambda t\,)$.\,
Next, we assume that Claim 1 holds for some $n$ (induction hypothesis).
We establish validity of Claim 1 for $n+1$.
\begin{eqnarray*}
P\!\left(\, \xi_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
& = &
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
\;\; = \;\;
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,,\, \eta_{n+1} \,>\, t \,\right)
	\, + \,
	P\!\left(\, \xi_{n} + \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,,\, \eta_{n+1} \,\leq\, t \,\right)
\\
& = &
	P\!\left(\, \eta_{n+1} \,\overset{{\color{white}.}}{>}\, t \,\right)
	\, + \,
	P\!\left(\, \xi_{n} \,\overset{{\color{white}.}}{>}\, t - \eta_{n+1} \,,\, t \,\geq\, \eta_{n+1} \,\right)
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\int_{t-\eta}^{\infty}\; f_{\xi_{n},\,\eta_{n+1}}(\xi,\eta) \;\,\d\xi\,\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\int_{t-\eta}^{\infty}\; f_{\xi_{n}}(\xi) \cdot f_{\eta_{n+1}}(\eta) \;\,\d\xi\,\d\eta,
	\quad
	\textnormal{by independence of \,$\xi_{n}$\, and \,$\eta_{n+1}$}
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\left(\int_{t-\eta}^{\infty}\; f_{\xi_{n}}(\xi) \;\d\xi \right) \cdot f_{\eta_{n+1}}(\eta)\;\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\,P(\,\xi_{n}>t-\eta\,) \cdot f_{\eta_{n+1}}(\eta)\;\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\int_{0}^{t}\,
		\exp(\,-\,\lambda (t-\eta)\,)
		\cdot
		\overset{n-1}{\underset{k=0}{\sum}}\;
		\dfrac{\lambda^{k}(t-\eta)^{k}}{k!}
		\cdot
		\lambda\cdot\exp(-\lambda\eta)
		\;\d\eta,
	\;\;
	\textnormal{by induction hypothesis}
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;\;
	\dfrac{\lambda^{k+1}}{k!}
	\int_{0}^{t}\,
		(t-\eta)^{k}
		\,\d\eta
\\
& = &
	\exp(\,-\lambda t\,)
	\, + \,
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n-1}{\underset{k=0}{\sum}}\;\;
	\dfrac{\lambda^{k+1}}{k!}
	\cdot
	\dfrac{t^{k+1}}{k+1}
\\
& = &
	\cdots
\;\; = \;\;
	\exp(\,-\,\lambda t\,)
	\cdot
	\overset{n}{\underset{k=0}{\sum}}\;
	\dfrac{(\lambda t)^{k}}{k!},
\end{eqnarray*}
This proves Claim 1, and completes the proof of the Proposition.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{definition}[Independence and stationarity of increments of a stochastic process]
\mbox{}
\vskip 0.1cm
\noindent
A stochastic process
\,$\left\{\,\overset{{\color{white}.}}{X}_{t} : (\Omega,\mathcal{A},\mu) \longrightarrow \Re \;\right\}_{t \in T}$\,
is said to have:
\begin{itemize}
\item
	\textbf{independent increments}, if
	\begin{equation*}
	X_{t_{1}} - X_{t_{0}}\,,\;
	X_{t_{2}} - X_{t_{1}}\,,\;
	\ldots\,,\;
	X_{t_{n}} - X_{t_{n-1}}
	\end{equation*}
	are independent, for each \,$t_{0}, t_{1}, \ldots, t_{n} \in T$\,
	with \,$t_{0} < t_{1} < \cdots < t_{n}$.
\item
	\textbf{stationary increments}, if,
	for each $t_{1},\, t_{2} \in T$, the probability distribution of
	\begin{equation*}
	X_{t_{1}+h} \,-\, X_{t_{2}+h}
	\end{equation*}
	is independent of $h$, as long as \,$t_{1} + h,\, t_{2} + h \in T$.
\end{itemize}
\end{definition}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{theorem}
\mbox{}
\vskip 0.15cm
\noindent
Suppose:
\begin{itemize}
\item
	$\left\{\,N_{t} : (\Omega,\mathcal{A},\mu) \overset{{\color{white}-}}{\longrightarrow} \Re \;\right\}_{t \in [\,0,\infty)}$\,
	is a Poisson process.
\item
	For each fixed $t \in [\,0,\infty)$,
	$\left\{\,N^{(t)}_{s} : (\Omega,\mathcal{A},\mu) \overset{{\color{white}-}}{\longrightarrow} \Re \;\right\}_{s \in [\,0,\infty)}$\;
	is the stochastic process defined by:
	\begin{equation*}
	N^{(t)}_{s} \;\; := \;\; N_{t+s} \,-\, N_{t}\,,
	\quad
	\textnormal{for each \,$s \in [\,0,\infty)$}
	\end{equation*}
\end{itemize}
Then,
\begin{enumerate}
\item
	$\left\{\,N^{(t)}_{s}\right\}_{s \in [\,0,\infty)}$\, is a Poisson process.
\item
	$N^{(t)}_{s}$\, and \,$N_{t}$\, are independent random variables, for each \,$s, t \in [\,0,\infty)$.
\item
	The probability distributions of \,$N^{(t)}_{s}$\, and \,$N_{s}$\, are equal, for each \,$s, t \in [\,0,\infty)$.
\end{enumerate}
\end{theorem}
\proof
Recall that
\begin{equation*}
N_{t}(\omega)
\;\; := \;\;
	\max\left\{\,\left.
		n \overset{{\color{white}.}}{\in} \N\cup\{0\}
		\,\;\right\vert\;
		\xi_{n}(\omega) \,\leq\, t
		\,\right\},
\quad
\textnormal{for each \,$t \in [\,0,\infty)$,\, $\omega \in \Omega$}
\end{equation*}
where
\begin{itemize}
\item
	$\xi_{0} : \Omega \longrightarrow [\,0,\infty)$\, is the almost-surely zero function on $\Omega$,\,
and
\item
	$\xi_{1}\,, \xi_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	denote the sequence of random variables on
	\,$(\Omega,\mathcal{A},\mu)$\, defined by:
	\begin{equation*}
	\xi_{n}(\omega) \; := \; \eta_{1}(\omega) + \cdots + \eta_{n}(\omega),
	\quad
	\textnormal{for each \,$n \in \N$,\, $\omega \in \Omega$},
	\end{equation*}
	where
	\,$\eta_{1}\,, \eta_{2}\,, \,\ldots : \Omega \longrightarrow [\,0,\infty)$\,
	form a sequence of independent and identically distributed
	exponential random variables with rate \,$\lambda > 0$\,
	defined on \,$(\Omega,\mathcal{A},\mu)$.
\end{itemize}
Define
\begin{equation*}
\eta^{(t)}_{1} \; := \; \xi_{N_{t}+1} \,-\, t\,,
\quad\textnormal{and}\quad
\eta^{(t)}_{n} \; := \; \eta_{N_{t}+n}\,,
\quad\textnormal{for \,$n = 2, 3, \ldots$}
\end{equation*}
Next, define:
\begin{equation*}
\xi^{(t)}_{n} \; := \; \eta^{(t)}_{1} \,+\, \eta^{(t)}_{2} \,+\, \cdots \,+\, \eta^{(t)}_{n}\,,
\quad\textnormal{for \,$n = 1, 2, \ldots$}
\end{equation*}

\vskip 0.5cm
\noindent
\textbf{Claim 1:}\quad $N^{(t)}_{s} \; = \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}$
\vskip 0.2cm
\noindent
Proof of Claim 1:\quad
For notational convenience, we define
$M^{(t)}_{s} \; := \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}$.
We need to show that:
\begin{equation*}
\max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}
\;\; =: \;\;
	M^{(t)}_{s}
\;\; = \;\;
	N_{t+s} \,-\, N_{t}
\;\; =: \;\;
	N^{(t)}_{s}
\end{equation*}
To this end, first note that
\begin{equation}\label{xitn}
\xi^{(t)}_{n} \;\; := \;\; \xi_{N_{t}+n} \;-\; t.
\end{equation}
Indeed,
\begin{eqnarray*}
\xi^{(t)}_{n}
& := &
	\eta^{(t)}_{1} + \eta^{(t)}_{2} + \cdots + \eta^{(t)}_{n}
\;\; = \;\;
	\left(\,\xi_{N_{t}+1} \,\overset{{\color{white}.}}{-}\, t\,\right)
	\, + \,
	\eta_{N_{t}+2}
	\, + \,
	\cdots
	\, + \,
	\eta_{N_{t}+n}
\\
& = &
	\left(\,\eta_{1} + \cdots +  \eta_{N_{t}} +\eta_{N_{t}+1} \,\overset{{\color{white}.}}{-}\, t\,\right)
	\, + \,
	\eta_{N_{t}+2}
	\, + \,
	\cdots
	\, + \,
	\eta_{N_{t}+n}
\\
& = &
	\left(\,\eta_{1} \,\overset{{\color{white}.}}{+}\, \cdots \,+\,  \eta_{N_{t}}
	\,+\, \eta_{N_{t}+1} \,+\, \eta_{N_{t}+2} \,+\, \cdots\,+\, \eta_{N_{t}+n}
	\,\right)
	\, - \,
	t
\;\; = \;\;
	\xi_{N_{t}+n} \,-\, t\,,
	\quad
	\textnormal{as desired}
\end{eqnarray*}
Next, note:
\begin{eqnarray*}
M^{(t)}_{s} \; := \; \max\left\{\,n\in\N\cup\{0\}\;\left\vert\;\,\xi^{(t)}_{n} \leq s\right.\,\right\}
& \Longleftrightarrow &
	\xi^{(t)}_{M^{(t)}_{s}} \;\leq\; s \;<\; \xi^{(t)}_{M^{(t)}_{s}+1}
\\
& \Longleftrightarrow &
	\xi_{N_{t}+M^{(t)}_{s}} \,-\, t \;\;\leq\;\; s \;\;<\;\; \xi_{N_{t}+M^{(t)}_{s}+1} \,-\, t\,,
	\quad
	\textnormal{by \eqref{xitn}}
\\
& \Longleftrightarrow &
	\xi_{N_{t}+M^{(t)}_{s}} \;\;\leq\;\; t + s \;\;<\;\; \xi_{N_{t}+M^{(t)}_{s}+1}
\\
& \Longleftrightarrow &
	N_{t+s}
	\;\; := \;\;
		\max\left\{\,\left.\overset{{\color{white}1}}{n}\in\N\cup\{0\}\,\;\right\vert\;\xi_{n} \leq t+s \,\right\}
	\;\; = \;\;
		N_{t} + M^{(t)}_{s}
\\
& \Longleftrightarrow &
	M^{(t)}_{s}
	\;\; = \;\;
		N_{t+s} \, - \,N_{t}
\end{eqnarray*}
This proves Claim 1.

\vskip 0.5cm
\noindent
\textbf{Claim 2:}\quad
$P\!\left(\,\left.\eta^{(t)}_{1} > s \;\,\right\vert\, N_{t}\,\right)$\;
$=$
\;$P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}\,\right)$
\vskip 0.2cm
\noindent
Proof of Claim 2:\quad


\vskip 0.5cm
\noindent
\textbf{Claim 3:}\quad
$P\!\left(\,\left.\eta^{(t)}_{1} > s_{1}, \,\ldots\, ,\eta^{(t)}_{k} > s_{k} \,\;\right\vert\; N_{t}\;\right)$\;
$=$
\;$P\!\left(\,\eta_{1} > \overset{{\color{white}-}}{s}_{1}\,\right) \cdot \cdots \cdot P\!\left(\,\eta_{k} > \overset{{\color{white}-}}{s}_{k}\,\right)$
\vskip 0.2cm
\noindent
Proof of Claim 3:\quad


\begin{enumerate}
\item
\end{enumerate}
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{corollary}[Every Poisson process has independent and stationary increments]
\mbox{}
\vskip 0.15cm
\noindent
Every Poisson process has independent and stationary increments.
\end{corollary}
\proof

\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
