
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{With-replacement approximate variance estimator}

\vskip 0.2cm
First, note that every without-replacement (complex) sampling design
\textbf{\color{red}with fixed sample size} admits a with-replacement
``counterpart'' sampling design.

\vskip 0.5cm
\noindent
Indeed, let $U := \{1,2,\ldots,N\}$, and
$p : \mathcal{S} \subset \mathcal{P}(U) \longrightarrow (0,1]$
be a sampling design of fixed sample size $n$
such that, for each $i \in U$, we have
\begin{equation*}
\pi_{i}
\;\; := \;\;
	\underset{s \in \mathcal{S}}{\sum} \; p(s)\cdot I_{i}(s)
\;\; = \;\;
	\underset{s \ni i}{\sum} \; p(s)
\;\; > \;\;
	0
\end{equation*}
Then, define a probability function $p_{0} : U \longrightarrow (0,1]$ by
\begin{equation*}
p_{0}(i) \;\; := \;\; \dfrac{\pi_{i}}{n} \;\; > \;\; 0\,.
\end{equation*}
Note that $p_{0}$ is indeed a probability function on $U$ since
\begin{eqnarray*}
\underset{i\in U}{\sum}\;\,p_{0}(i)
&=&
	\underset{i\in U}{\sum}\;\,\dfrac{\pi_{i}}{n}
\;\; = \;\;
	\dfrac{1}{n} \cdot
	\underset{i\in U}{\sum}
	\left(\,\underset{s \in \mathcal{S}}{\sum} \; p(s)\cdot I_{i}(s)\right)
\;\; = \;\;
	\dfrac{1}{n} \cdot
	\underset{i\in U}{\sum}\;\,
	\underset{s \in \mathcal{S}}{\sum}\;\,
	p(s)\cdot I_{i}(s)
\;\; = \;\;
	\dfrac{1}{n} \cdot
	\underset{s \in \mathcal{S}}{\sum}\;\,
	\underset{i\in U}{\sum}\;\,
	p(s)\cdot I_{i}(s)
\\
&=&
	\dfrac{1}{n} \cdot
	\underset{s \in \mathcal{S}}{\sum}\;\,
	p(s)\cdot \left(\,\underset{i\in U}{\sum}\;\, I_{i}(s)\right)
\;\; = \;\;
	\dfrac{1}{n} \cdot
	\underset{s \in \mathcal{S}}{\sum}\;\,
	p(s)\cdot n
\;\; = \;\;
	\underset{s \in \mathcal{S}}{\sum}\;\,p(s)
\;\; = \;\;
	1
\end{eqnarray*}
Now, let \;$y : U \longrightarrow \Re$\; be a population characteristic,
and \;$t_{y} \, := \, \underset{u \in U}{\sum}\;y_{u}$\; its population total.
For \;$s \in \mathcal{S}$,\; let \;$\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)$\;
represents the Horvitz-Thompson estimate of \;$t_{y}$\, under the sampling
plan \;$p : \mathcal{S} \subset \mathcal{P}(U) \longrightarrow (0,1]$.\;

\vskip 0.5cm
\noindent
Next, observe that, although \;$s \in \mathcal{S}$\; is selected under the
without-replacement sampling design \;$p : \mathcal{S} \longrightarrow (0,1]$,\;
it could also have arisen as a selected sample under the fixed-sample-size-$n$
with-replacement sampling plan induced by \;$p_{0} : U \longrightarrow (0,1]$.\;

\vskip 0.5cm
\noindent
Next, we consider the ``with-replacement counterpart''
\,$\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}$\,
of
\;$\widehat{T}^{\,\textnormal{HT}}_{y,p}$.\,
To this end, let \,$U \times \cdots \times U$ be the $n$-fold Cartesian product of \,$U$,
equipped with the probability space structure induced by I.I.D. sampling under
the probability function \,$p_{0} : U \longrightarrow (0,1]$.
Define
\,$\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}} : U \times \cdots \times U \longrightarrow \Re$\,
by:
\begin{equation*}
\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}(u_{1},\ldots,u_{n})
\;\; := \;\;
	\dfrac{1}{n}\cdot\overset{n}{\underset{i=1}{\sum}}\;\, \dfrac{y_{u_{i}}}{p_{0}(u_{i})}
\end{equation*}
\begin{proposition}
\mbox{}\vskip 0.1cm
\begin{enumerate}
\item
	\begin{equation*}
	E\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\;\; = \;\;
		\underset{u \in U}{\sum}\; y_{u}
	\;\; = \;\;
		t_{y}
	\end{equation*}
\item
	\begin{equation*}
	\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\;\; = \;\;
		\dfrac{1}{n}\cdot
		\underset{u \in U}{\sum}\;\,
		p_{0}(u)\cdot\left(\,\dfrac{y_{u}}{p_{0}(u)}\,-\,t_{y}\,\right)^{2}
	\end{equation*}
\item
	The random variable
	\,$\widehat{V}\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right] :
	U \times \cdots \times U \longrightarrow \Re$\, defined by:
	\begin{equation*}
	\widehat{V}\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]\!(u_{1},\ldots,u_{n})
	\;\; = \;\;\,
		\dfrac{1}{n\,(n-1)}\cdot\overset{n}{\underset{i = 1}{\sum}}
		\left(\,
			\dfrac{y_{u_{i}}}{p_{0}(u_{i})}
			\,-\,
			\left(\dfrac{1}{n}\,\overset{n}{\underset{k=1}{\sum}}\,\dfrac{y_{u_{k}}}{p_{0}(u_{k})}\right)
			\right)^{2}
	\end{equation*}
	is an unbiased estimator for \,$\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]$.
\end{enumerate}
\end{proposition}
\proof
\begin{enumerate}
\item
	First, define
	\,$Z : (U,p_{0}) \longrightarrow \Re$\, by:
	\begin{equation*}
	Z(u) \;\; := \;\; \dfrac{y_{u}}{p_{0}(u)}\,,
	\quad
	\textnormal{for each \,$u \in U$}
	\end{equation*}
	Hence,
	\begin{equation*}
	E\!\left[\;Z\;\right]
	\;\; = \;\;
		\underset{u \in U}{\sum}\; Z(u) \cdot p_{0}(u)
	\;\; = \;\;
		\underset{u \in U}{\sum}\; \dfrac{y_{u}}{p_{0}(u)} \cdot p_{0}(u)
	\;\; = \;\;
		\underset{u \in U}{\sum}\; y_{u}
	\;\; = \;\;
		t_{y}
	\end{equation*}
	Next, note that
	\begin{eqnarray*}
	\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}(u_{1},\ldots,u_{n})
	&=&
		\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\;\, \dfrac{y_{u_{i}}}{p_{0}(u_{i})}
	\;\;\; = \;\;\;
		\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\; Z(u_{i})
	\end{eqnarray*}
	Since \,$\{u_{1},\ldots,u_{n}\}$\, is an I.I.D. sample from \,$(U,p_{0})$,\,
	we see that
	\begin{eqnarray*}
	\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}
	&=&
		\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\; Z_{i}\,,
	\end{eqnarray*}
	where \,$Z_{i}$\, are I.I.D. copies of $Z : U \longrightarrow \Re$.
	Consequently,
	\begin{eqnarray*}
	E\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	&=&
		E\!\left[\;
			\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\; Z_{i}
			\;\right]
	\;\;\; = \;\;\;
		\dfrac{1}{n} \cdot
		\overset{n}{\underset{i = 1}{\sum}}\,
		E\!\left[\; Z_{i} \;\right]
	\;\;\; = \;\;\;
		\dfrac{1}{n} \cdot
		\overset{n}{\underset{i = 1}{\sum}}\,
		E\!\left[\; Z \;\right]
	\;\;\; = \;\;\;
		E\!\left[\; Z \;\right]
	\;\;\; = \;\;\;
		t_{y}
	\end{eqnarray*}
\item
	\begin{eqnarray*}
	\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	& = &
		\Var\!\left[\;
			\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\; Z_{i}
			\;\right]
	\;\;\; = \;\;\;
		\dfrac{1}{n^{2}}\cdot \overset{n}{\underset{i = 1}{\sum}}\;
		\Var\!\left[\; Z_{i} \;\right]
	\;\;\; = \;\;\;
		\dfrac{1}{n^{2}}\cdot \overset{n}{\underset{i = 1}{\sum}}\;
		\Var\!\left[\; Z \;\right]
	\;\;\; = \;\;\,
		\dfrac{1}{n}\cdot \Var\!\left[\; Z \;\right]
	\\
	& = &
		\dfrac{1}{n}\cdot
		\underset{u \in U}{\sum}\;\,
		p_{0}(u)\cdot\left(\,\dfrac{y_{u}}{p_{0}(u)}\,-\,t_{y}\,\right)^{2}\,,
	\end{eqnarray*}
	where the second and third equalities follow from that fact that
	the $Z_{i}$'s are I.I.D. copies of $Z$.
\item
	Let \,$Z$\, be as defined in the proof of (i), and
	\,$Z_{1}, \ldots, Z_{n}$\, be I.I.D. copies of \,$Z$.\,
	Recall that
	\begin{eqnarray*}
	\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}
	&=&
		\dfrac{1}{n}\cdot \overset{n}{\underset{i = 1}{\sum}}\; Z_{i}
	\;\; =: \;\;
		\overline{Z}_{n}
	\end{eqnarray*}
	By standard theory,
	\begin{equation*}
	\dfrac{1}{n}\cdot\left(\;
		\dfrac{1}{n-1}\cdot\overset{n}{\underset{i=1}{\sum}} \left(Z_{i} - \overline{Z}_{n}\right)^{2}
		\;\right)
	\end{equation*}
	is an unbiased estimator for
	\,$\Var\!\left[\;\overline{Z}_{n}\;\right] \,=\, \dfrac{1}{n}\,\Var\!\left[\;Z\;\right]$.\,
	Now, observe that
	\begin{eqnarray*}
	\dfrac{1}{n}\cdot\left.\left(\;
		\dfrac{1}{n-1}\cdot\overset{n}{\underset{i=1}{\sum}} \left(Z_{i} - \overline{Z}_{n}\right)^{2}
		\;\right)\right\vert_{\,(u_{1},\ldots,u_{n})}
	& = &
		\dfrac{1}{n\,(n-1)}\cdot
		\overset{n}{\underset{i=1}{\sum}}\left(
			\overset{{\color{white}.}}{Z}_{i}(u_{i}) - \overline{Z}_{n}(u_{1},\ldots,u_{n})
			\right)^{2}
	\\
	& = &
		\dfrac{1}{n\,(n-1)}\cdot
			\overset{n}{\underset{i=1}{\sum}}\left(\;
				\dfrac{y_{u_{i}}}{p_{0}(u_{i})}
				\,-\,
				\left(\dfrac{1}{n}\,\overset{n}{\underset{k=1}{\sum}}\;\dfrac{y_{u_{k}}}{p_{0}(u_{k})}\right)
				\right)^{2}
	\\
	& =: &
		\overset{{\color{white}1}}{
			\widehat{V}\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]\!(u_{1},\ldots,u_{n})
			}
	\end{eqnarray*}
	Hence,
	\begin{equation*}
	E\!\left(\;
		\widehat{V}\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
		\;\right)
	\;\; = \;\;
		E\!\left[\;\,
			\dfrac{1}{n}\cdot\left(\;
				\dfrac{1}{n-1}\cdot\overset{n}{\underset{i=1}{\sum}} \left(Z_{i} - \overline{Z}_{n}\right)^{2}
				\;\right)
			\;\right]
	\;\; = \;\;
		\Var\!\left[\;\overline{Z}_{n}\;\right]
	\;\; = \;\;
		\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right],
	\end{equation*}
	as desired.
\end{enumerate}
This proves the present Proposition.
\qed

\vskip 0.5cm
\noindent
Inspired by the preceding Proposition, we now define
\,$\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
: \mathcal{S} \longrightarrow \Re$\,
by
\begin{eqnarray*}
\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\!(s)
& := &
	\dfrac{1}{n\,(n-1)}\cdot\overset{n}{\underset{i = 1}{\sum}}\left(\,
		\dfrac{y_{u_{i}}}{p_{0}(u_{i})}
		\, - \,
		\left(\dfrac{1}{n}\,\overset{n}{\underset{k=1}{\sum}}\,\dfrac{y_{u_{k}}}{p_{0}(u_{k})}\right)
		\right)^{2}
\\
& = &
	\dfrac{1}{n\,(n-1)}\cdot\overset{n}{\underset{i = 1}{\sum}}\left(\,
		\dfrac{y_{u_{i}}}{p_{0}(u_{i})}
		\, - \,
		\left(\,\overset{n}{\underset{k=1}{\sum}}\,\dfrac{y_{u_{k}}}{n \cdot p_{0}(u_{k})}\right)
		\right)^{2}
\\
& = &
	\dfrac{1}{n\,(n-1)}\cdot \underset{v \in s}{\sum} \left(\,
		\dfrac{y_{v}}{\pi_{v}/n}
		\, - \,
		\left(\,\underset{u \in s}{\sum}\;\dfrac{y_{u}}{\pi_{u}}\right)
		\right)^{2}
\\
& = &
	\dfrac{1}{n\,(n-1)}\cdot \underset{v \in s}{\sum} \left(\,
		\dfrac{y_{v}}{\pi_{v}/n}
		\, - \,
		\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)
		\right)^{2}
\end{eqnarray*}
where \,$s = \{u_{1},\ldots,u_{n}\}$.
We call
\;$\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
: \mathcal{S} \longrightarrow \Re$\;
the \textbf{with-replacement approximate variance estimator}
%\;$\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]$\;
of \;$\widehat{T}^{\,\textnormal{HT}}_{y,p}$.
The following Proposition gives an expression of the bias of
\,$\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]$\,
as an estimator for
\,$\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]$.

\vskip 0.5cm
\begin{proposition}
\begin{equation*}
E\!\left(\;\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\;\right)
\; - \; \Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
\;\; = \;\;
	\left(\,\dfrac{n}{n-1}\,\right)
	\cdot
	\left(\,
		\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{\color{red}0}}\;\right]
		\, - \,
		\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
		\,\right)
\end{equation*}
\end{proposition}
\proof
\vskip 0.1cm
\noindent
\underline{\textbf{Claim 1:}}
\begin{equation*}
\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\!(s)
\;\; = \;\;
	\left(\;\dfrac{n}{n-1}\cdot\underset{u \in s}{\sum}\;\dfrac{y_{u}^{2}/\pi_{u}}{\pi_{u}}\,\right)
	\,-\,
	\left(\;\dfrac{1}{n-1}\cdot\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)^{2}\,\right)
\end{equation*}
Proof of Claim 1:
\begin{eqnarray*}
\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\!(s)
& = &
	\dfrac{1}{n(n-1)}\cdot \underset{v \in s}{\sum} \left(\,
		\dfrac{y_{v}}{\pi_{v}/n}
		\, - \,
		\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)
		\right)^{2}
\\
& = &
	\dfrac{1}{n(n-1)}\cdot \underset{v \in s}{\sum} \left(\,
		\dfrac{y_{v}^{2}}{\pi_{v}^{2}/n^{2}}
		\, - \,
		2 \cdot
		\dfrac{y_{v}}{\pi_{v}/n}
		\cdot
		\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)
		\, + \,
		\widehat{T}^{\,\textnormal{HT}}_{y,p}(s)^{2}
		\right)
\\
& = &
	\dfrac{1}{n\,(n-1)} \cdot \left(\;
		n^{2} \cdot \underset{v \in s}{\sum}\;\dfrac{y_{v}^{2}}{\pi_{v}^{2}}
		\, - \,
		2\,n
		\cdot \widehat{T}^{\,\textnormal{HT}}_{y,p}(s) 
		\cdot \underset{v \in s}{\sum}\;\dfrac{y_{v}}{\pi_{v}}
		\, + \,
		n \cdot \widehat{T}^{\,\textnormal{HT}}_{y,p}(s)^{2}
		\;\right)
\\
& = &
	\left(\dfrac{n}{n-1}\cdot\underset{v \in s}{\sum}\;\dfrac{y_{v}^{2}/\pi_{v}}{\pi_{v}}\right)
	\, - \,
	\dfrac{1}{n-1} \cdot \widehat{T}^{\,\textnormal{HT}}_{y,p}(s)^{2}
\end{eqnarray*}
This proves Claim 1.

\vskip 0.8cm
\noindent
\underline{\textbf{Claim 2:}}
\begin{equation*}
E\!\left(\;\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\;\right)
\;\; = \;\;
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,-\,
	\dfrac{1}{n-1} \cdot \Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
\end{equation*}
Proof of Claim 2:
\begin{eqnarray*}
E\!\left(\;\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\;\right)
& = &
	\dfrac{n}{n-1} \cdot E\!\left(\;\underset{u \in s}{\sum}\;\dfrac{y_{u}^{2}/\pi_{u}}{\pi_{u}}\;\right)
	\,-\,
	\dfrac{1}{n-1} \cdot E\!\left(\,\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)^{2}\,\right)
\\
& = &
	\dfrac{n}{n-1} \cdot \underset{u \in U}{\sum}\;y_{u}^{2}/\pi_{u}
	\,-\,
	\dfrac{1}{n-1} \cdot
	\left(
		\Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
		+
		E\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)^{2}
		\right)
\\
& = &
	\dfrac{n}{n-1} \cdot \left(\,\underset{u \in U}{\sum}\dfrac{y_{u}^{2}}{\pi_{u}}\,\right)
	\,-\,
	\dfrac{1}{n-1} \cdot
	\left(
		\Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
		+\,
		t_{y}^{2}
		\,\right)
\end{eqnarray*}
On the other hand,
\begin{eqnarray*}
\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
& = &
	\dfrac{1}{n}\cdot
	\underset{u \in U}{\sum}\;\,
	p_{0}(u)\cdot\left(\,\dfrac{y_{u}}{p_{0}(u)}\,-\,t_{y}\,\right)^{2}
\;\; = \;\;
	\dfrac{1}{n}\cdot
	\underset{u \in U}{\sum}\;\,
	\dfrac{\pi_{u}}{n}\cdot\left(\,\dfrac{y_{u}}{\pi_{u}/n}\,-\,t_{y}\,\right)^{2}
\\
& = &
	\dfrac{1}{n}\cdot
	\underset{u \in U}{\sum}\;\,
	\dfrac{\pi_{u}}{n}\cdot\left(\,\dfrac{n\cdot y_{u}}{\pi_{u}}\,-\,t_{y}\,\right)^{2}
\;\; = \;\;
	\dfrac{1}{n}\cdot
	\underset{u \in U}{\sum}\;\,
	\dfrac{\pi_{u}}{n}\cdot\left(\,
		\dfrac{n^{2}\,y_{u}^{2}}{\pi_{u}^{2}}
		\,-\,
		2\cdot\dfrac{n\cdot y_{u}}{\pi_{u}}\cdot t_{y}
		\,+\,
		t_{y}^{2}
		\,\right)
\\
& = &
	\dfrac{1}{n}\cdot
	\underset{u \in U}{\sum}\;\,
	\dfrac{\pi_{u}}{n}\cdot\left(\,
		\dfrac{n^{2}\,y_{u}^{2}}{\pi_{u}^{2}}
		\,\right)
	\,-\,
	\dfrac{2}{n}\cdot
		\underset{u \in U}{\sum}\;\,
		\dfrac{\pi_{u}}{n}\cdot\left(\,
			\dfrac{n\cdot y_{u}}{\pi_{u}}\cdot t_{y}
			\,\right)
	\,+\,
		\dfrac{1}{n}\cdot
		\underset{u \in U}{\sum}\;\,
		\dfrac{\pi_{u}}{n}\cdot\left(\,
			t_{y}^{2}
			\,\right)
\\
& = &
	\left(\,
	\underset{u \in U}{\sum}\;
		\dfrac{y_{u}^{2}}{\pi_{u}}
		\,\right)
	\,-\,
	\dfrac{2}{n}\cdot t_{y}\cdot
		\left(\,\underset{u \in U}{\sum}\;y_{u}\,\right)
	\,+\,
		\dfrac{1}{n^{2}} \cdot t_{y}^{2} \cdot
		\left(\,\underset{u \in U}{\sum}\;\pi_{u}\right)
\\
& = &
	\left(\,
	\underset{u \in U}{\sum}\;
		\dfrac{y_{u}^{2}}{\pi_{u}}
		\,\right)
	\,-\,
	\dfrac{2}{n}\cdot t_{y}^{2}
	\,+\,
	\dfrac{1}{n} \cdot t_{y}^{2} \cdot
\;\;\; = \;\;\;
	\left(\,
	\underset{u \in U}{\sum}\;
		\dfrac{y_{u}^{2}}{\pi_{u}}
		\,\right)
	\,-\,
	\dfrac{1}{n}\cdot t_{y}^{2}
\end{eqnarray*}
Therefore,
\begin{eqnarray*}
E\!\left(\;\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\;\right)
& = &
	\dfrac{n}{n-1} \cdot \left(\,\underset{u \in U}{\sum}\dfrac{y_{u}^{2}}{\pi_{u}}\,\right)
	\,-\,
	\dfrac{1}{n-1} \cdot
	\left(
		\Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
		+\,
		t_{y}^{2}
		\,\right)
\\
& = &
	\dfrac{n}{n-1} \cdot \left(\,
		\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
		\,+\,
		\dfrac{1}{n}\cdot t_{y}^{2}
		\,\right)
	\,-\,
	\dfrac{1}{n-1} \cdot
	\left(
		\Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
		+\,
		t_{y}^{2}
		\,\right)
\\
& = &
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,+\,
	\dfrac{1}{n-1}\cdot t_{y}^{2}
	\,-\,
	\dfrac{1}{n-1} \cdot \Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
	\, +\,
	\dfrac{1}{n-1} \cdot t_{y}^{2}
\\
& = &
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,-\,
	\dfrac{1}{n-1} \cdot \Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
\end{eqnarray*}
This proves Claim 2.

\vskip 0.8cm
\noindent
The present Proposition now follows readily from Claim 2.
Indeed, by Claim 2, we have:
\begin{eqnarray*}
E\!\left(\;\widehat{V}^{\textnormal{WR}}\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]\;\right)
\; - \; \Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
& = &
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,-\,
	\dfrac{1}{n-1} \cdot \Var\!\left(\,\widehat{T}^{\,\textnormal{HT}}_{y,p}\,\right)
	\, - \,
	\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
\\
& = &
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,-\,
	\left(\,\dfrac{1}{n-1} + \dfrac{n-1}{n-1}\,\right)
		\cdot
		\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
\\
& = &
	\dfrac{n}{n-1} \cdot \Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
	\,-\,
	\left(\,\dfrac{n}{n-1}\,\right)
		\cdot
		\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
\\
& = &
	\dfrac{n}{n-1} \cdot
	\left(\;
		\Var\!\left[\;\widehat{T}^{\,\textnormal{WR}}_{y,p_{0}}\;\right]
		\,-\,
		\Var\!\left[\;\widehat{T}^{\,\textnormal{HT}}_{y,p}\;\right]
		\;\right),
\end{eqnarray*}
as desired.
The proof of the Proposition is complete.
\qed

\vskip 0.5cm
\noindent
\textbf{Advantages}
\begin{itemize}
\item
	Easy to compute
\end{itemize}

\vskip 0.5cm
\noindent
\textbf{Disdvantages}
\begin{itemize}
\item
	It is often (but not always) an over-estimate.
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
