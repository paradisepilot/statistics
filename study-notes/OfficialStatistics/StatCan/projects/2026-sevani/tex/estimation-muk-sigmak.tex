
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Estimation of
\;$\mu_{k} \;:=\, E_{Y}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]$\;
and
\;$\sigma_{k}^{2} \;:=\, \Var_{Y}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]$
}

We presented in Section \ref{sectionSEVANITheory} the underlying theory
of the SEVANI framework \cite{Beaumont2011} in a series of lemmas.
\vskip 0.2cm
\noindent
In particular, Lemma \ref{DecompositionMSETtilde} states that the the mean squared error
of a composite linear imputation estimator can be decomposed into the sum of three components:
the sampling variance component, the nonresponse variance component, and
the sampling-nonresponse covariance.
In turn, Lemma \ref{SamplingVariance}, Lemma \ref{NonresponseVariance}, and Lemma \ref{MixedVariance}
give respectively estimators for these three variance components.
\vskip 0.2cm
\noindent
The quantities
\;$\mu_{k} := E_{Y}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]$\;
and
\;$\sigma_{k}^{2} := \Var_{Y}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]$,\;
for \,$k \in s = s_{R} \sqcup s_{M}$,\,
appear in the formulas in
Lemma \ref{SamplingVariance}, Lemma \ref{NonresponseVariance}, and Lemma \ref{MixedVariance}.
The values of these quantities are unknown in practice, and must be estimated.
We give a summary of how these quantities are estimated in practice,
according to the SEVANI Methodology Guide.

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{itemize}
\item
    The selected sample
    \,$s = s_{R} \sqcup s_{M} \subset U$\,
    is divided into \,$J$\, ordered imputation classes
    during the imputation step.
\item
    A modelling method is chosen for each imputation class.
\item
    For each imputation class, the collection of \textit{modelling contributors} is determined.
    The collection of modelling contributors will be used as training data for the imputation class.
    \vskip 0.01cm
    \noindent
    The collection of modelling contributors is first initialized to the subset of respondents
    within the corresponding collection of \textit{imputation contributors}.
    (Recall that, for each imputation step, the collection of imputation contributors
    may contain nonrespondents for which the target variable has been imputed in preceding imputation steps.)
    If the collection of modelling contributors is not sufficiently large
    (to be used as training data), then it is enlarged by appropriately collapsing suitable imputation classes.
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{equation*}
E\!\left[\;
    Y^{\prime}_{k}
    \,\left\vert\;
    \mathbf{x}^{\textnormal{(obs)}}_{k}
    \right.
    \,\right]
\;\; = \;\;
    E\!\left[\;
        \left.
        \dfrac{Y_{k}}{\alpha_{k}}
        \;\right\vert\;
        \mathbf{x}^{\textnormal{(obs)}}_{k}
        \,\right]
\;\; = \;\;
    \dfrac{\mu_{k}}{\alpha_{k}}
\;\; = \;\;
    \mu^{\prime}_{k}
\end{equation*}

\begin{equation*}
\Var\!\left[\;
    Y^{\prime}_{k}
    \;\left\vert\;
    \mathbf{x}^{\textnormal{(obs)}}_{k}
    \right.
    \,\right]
\;\; = \;\;
    \Var\!\left[\;
        \left.
        \dfrac{Y_{k}}{\alpha_{k}}
        \;\right\vert\;
        \mathbf{x}^{\textnormal{(obs)}}_{k}
        \,\right]
\;\; = \;\;
    \dfrac{\sigma_{k}^{2}}{\alpha_{k}^{2}}
\;\; = \;\;
    \left(\,\sigma^{\prime}_{C(k)}\,\right)^{2}
\end{equation*}

\begin{eqnarray*}
\left(\,\widehat{\sigma}^{\prime}_{C(k)}\,\right)^{2}
& = &
    \dfrac{
        \underset{l\,\in\,C(k)}{\sum}\;
        \rho_{k}
        \left(\,y^{\prime}_{l} - \widehat{\mu}^{\prime}_{l}\,\right)^{2}
        }{
        \underset{l\,\in\,C(k)}{\sum}\;
        \rho_{l}\cdot\nu_{l}
        }
\end{eqnarray*}
where
\begin{itemize}
\item
    $\alpha_{k}$\, is the \textit{adjustment variable},
\item
    $\nu_{k}$\, ``user-specified imputation model error variance'', and
\item
    $\rho_{k}$\, is \textit{modelling weight}.
\end{itemize}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{Parametric estimation: auxiliary value imputation}

\begin{equation*}
\begin{array}{ccccc}
\widehat{\mu}_{k}
& = &
    \widehat{E_{Y}}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]
& = &
    \alpha_{k} \cdot x_{k}
\\ \\
\widehat{\sigma}_{k}^{2}
& = &
    \widehat{\Var_{Y}}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]
& = &
    \alpha_{k}^{2} \cdot x_{k}
\end{array}
\end{equation*}
where
\,$\alpha_{k}$\, is the adjustment variable.

\begin{eqnarray*}
\widehat{\sigma}_{k}^{2}
& = &
    \widehat{\Var_{Y}}\!\left[\,Y_{k}\left\vert\,\Xobs\right.\right]
\\
& = &
    \alpha_{k}^{2}\cdot\widehat{\sigma}_{a,k}^{2}
\\
& = &
    \alpha_{k}^{2}\cdot\nu_{k}\cdot\widehat{\sigma}_{c}^{2}
\\
& = &
    \alpha_{k}^{2}\cdot\nu_{k}\cdot
    \dfrac{
        \underset{l\,\in\,C(k)}{\sum}\;
        \omega^{\textnormal{MOD}}_{l}
        \left(\,\dfrac{y_{l}}{\alpha_{l}} - \dfrac{\widehat{\mu}_{l}}{\alpha_{l}}\,\right)^{2}
        }{
        \underset{l\,\in\,C(k))}{\sum}\;
        \omega^{\textnormal{MOD}}_{l}\cdot\nu_{l}
        }
\end{eqnarray*}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
