
        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Ken's derivation}

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\subsection{Probabilistic framework}

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\noindent
\textbf{Probability spaces}
\begin{itemize}
\item
    Let \,$\left(\,\Omega,\mathscr{A},\lambda\,\right)$\, a probability space.
\item
    Let
    \,$\left(\,\mathcal{P}(U)\,,\mathcal{P}(\mathcal{P}(U))\,,\overset{{\color{white}-}}{\pi}\,\right)$\,
    be the probability space induced by a sampling design, i.e.,
    a probability mass function defined on
    \,$\mathcal{P}(U) \,:=\, \mathcal{P}(\{1,2,\ldots,N\})$,\,
    where
    \,$U \,=\, \{1,2,\ldots,N\}$.
\end{itemize}

\vskip 0.3cm
\noindent
\textbf{Random variables}
\begin{itemize}
\item
    $\Ydot \,=\, (Y_{1},Y_{2},\ldots,Y_{N})^{T} : \Omega \longrightarrow \Re^{N \times 1}$\,
    is an $\Re^{N \times 1}$-valued random variable defined on \,$\Omega$,\,
    i.e., $\mathscr{A}$-measurable map).
\item
    $\mathbf{X}_{\bullet\bullet} \,=\, \left(\,\overset{{\color{white}.}}{X_{ij}}\,\right) : \Omega \longrightarrow \Re^{N \times r}$\,
    is an $\Re^{N \times r}$-valued random variable defined on \,$\Omega$.
\item
    $\Idot \,=\, (I_{1},I_{2},\ldots,I_{N})^{T} : \mathcal{P}(U) \longrightarrow \{0,1\}^{N \times 1}$\,
    is a $\{0,1\}^{N \times 1}$-valued random variable defined on \,$\mathcal{P}(U)$,\,
    i.e., $\mathcal{P}(\mathcal{P}(U))$-measurable map.
\item
    $\Rdot \,=\, (R_{1},R_{2},\ldots,R_{N})^{T} : {\color{red}\Omega \times \mathcal{P}(U)} \longrightarrow \{0,1\}^{N \times 1}$\,
    is a $\{0,1\}^{N \times 1}$-valued random variable defined on \,$\Omega \times \mathcal{P}(U)$,\,
    i.e., $\left(\mathscr{A} \overset{{\color{white}.}}{\times} \mathcal{P}(\mathcal{P}(U))\right)$-measurable map.
\end{itemize}

\vskip 0.3cm
\noindent
\textbf{Probabilistic assumptions}
\begin{itemize}
\item
    $P(\,I_{i} = 1\,) \,:=\, \pi\!\left(\,\left\{\,\left. s \overset{{\color{white}.}}{\subset} U \,\right\vert\, i \in s\,\right\}\,\right) \,>\, 0$,\,
    for each \,$i \in U$,\,
    and
    \,$w_{i} \,:=\, \dfrac{1}{P(\,I_{i} = 1\,)}$,\, for each \,$i \in U$.
\item
    $\left(\,\Ydot\,,\Xobs\,\right)$\, and \,$\Idot$\, are (unconditionally) independent.
\item
    $\Ydot$\, and \,$(\,\Idot\,,\Rdot\,)$\, are {\color{red}conditionally independent} given \,$\Xobs$.
\end{itemize}

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\subsection{Imputation estimator}

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{definition}[Imputation estimator \,$\widetilde{T}_{Y}$]
\mbox{}
\vskip 0.1cm
\noindent
\begin{eqnarray*}
\widetilde{T}_{Y}
\;\; = \;\;
    \widetilde{T}_{Y}(\,
        \Ydot,
        \Xobs,
        \Idot,
        \Rdot
        \,)
& := &
    \underset{i\,\in\,s}{\sum}\;w_{i}\,\widetilde{Y}_{i}
\;\; = \;\;
    \underset{i\,\in\,U}{\sum}\;w_{i}\,I_{i}\left(\,
        R_{i}\,Y_{i}
        \overset{{\color{white}.}}{+}
        (1-R_{i})\,Y^{*}_{i}
        \,\right)
\end{eqnarray*}
\end{definition}

\begin{lemma}[A formula for \,$\widetilde{T}_{Y}$]
\mbox{}
\vskip 0.1cm
\noindent
\begin{eqnarray*}
\widetilde{T}_{Y}
% & := &
%     \underset{i\,\in\,s}{\sum}\;w_{i}\,\widetilde{Y}_{i}
% \;\; = \;\;
%     \underset{i\,\in\,s}{\sum}\;w_{i}\left(\,
%         R_{i}\,Y_{i}
%         \overset{{\color{white}.}}{+}
%         (1-R_{i})\,Y^{*}_{i}
%         \,\right)
% \\
& = &
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
\end{eqnarray*}
\end{lemma}
\proof
\begin{eqnarray*}
\widetilde{T}_{Y}
& := &
    \underset{i\,\in\,s}{\sum}\;w_{i}\,\widetilde{Y}_{i}
\;\; = \;\;
    \underset{i\,\in\,s}{\sum}\;w_{i}\left(\,
        R_{i}\,Y_{i}
        \overset{{\color{white}.}}{+}
        (1-R_{i})\,Y^{*}_{i}
        \,\right)
\\
& = &
    \underset{i\,\in\,s}{\sum}\;w_{i}\,R_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,s}{\sum}\;w_{i}\,(1-R_{i})\,Y^{*}_{i}
\;\; = \;\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,R_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,Y^{*}_{i}
\\
& = &
    {\color{red}
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{-}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    }
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,R_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,Y^{*}_{i}
\\
& = &
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{-}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,Y^{*}_{i}
\\
& = &
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\overset{{\color{white}.}}{+}\;
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
\end{eqnarray*}
\vskip -0.5cm
\qed

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{lemma}[Overall conditional bias of \,$\widetilde{T}_{Y}$; see Equation (5.2) in \cite{Beaumont2011} and preceding paragraph]
\label{biasTtilde}
\mbox{}
\vskip 0.1cm
\noindent
Assume that
\,$Y = (Y_{1},\ldots,Y_{N})$\,
and
\,$(I,\rho) = (I_{1},\ldots,I_{N},\rho_{1},\ldots,\rho_{N})$\,
are conditionally independent given
\,$\Xobs$.\,
Then,
\begin{eqnarray*}
\bias\!\left(\;
    \left.
    \widetilde{T}_{Y}
    \;\right\vert\,
    \Xobs
    \,\right)
& = &
    E_{IR}\!\left[\;
        \underset{i\,\in\,{\color{red}s_{M}}}{\sum}\,w_{i}\,
        E_{Y}\!\left[\;
            \left.
            Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
            \;\right\vert\,
            s,s_{R},\Xobs
            \,\right]
        \,\right]
\end{eqnarray*}
\end{lemma}
%%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
\begin{remark}
\mbox{}
\vskip -0.1cm
\noindent
\begin{itemize}
\item
    In practice, we therefore would like to choose an imputation strategy such that
    \begin{equation*}
    E_{Y}\!\left[\;
        \left.
        Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
        \;\right\vert\,
        s,s_{R},\Xobs
        \,\right]
    \;\; \approx \;\;
        0,
    \quad
    \textnormal{for each \,$i \in s_{M}$}
    \end{equation*}
    See the paragraph after Equation (5.2), p.175, \cite{Beaumont2011}.
\item
    The conditioning on \,$\Xobs$\, is largely suppressed in \cite{Beaumont2011} for notational brevity;
    see the last sentence in the second paragraph of \S4, p.173, \cite{Beaumont2011}.
    We have restored it in our notation in these study notes.
\end{itemize}
\end{remark}
%%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
\proofof Lemma \ref{biasTtilde}
\vskip 0.1cm
\noindent
We prove the Lemma by establishing a series of claims.

\vskip 0.3cm
\noindent
\textbf{Claim 1:}\quad
\begin{equation*}
\bias\!\left(\,
    \left.
    \widetilde{T}_{Y}
    \;\right\vert\,
    \Xobs
    \right)
\; = \;
    E_{YIR}\!\left[\,
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
        \;\right\vert\,
        \Xobs
        \right]
    \;-\;
        \underset{i\,\in\,U}{\sum}\;
        E_{Y}\!\left[\,Y_{i}\left\vert\,\Xobs\right.\right]
    \;-\;
    E_{YIR}\!\left[\,
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
        \;\right\vert\,
        \Xobs
        \right]
\end{equation*}
\vskip 0.1cm
\noindent
Proof of Claim 1:\;\;
\begin{eqnarray*}
\bias\!\left(\;
    \left.
    \widetilde{T}_{Y}
    \;\right\vert\,
    \Xobs
    \,\right)
& := &
    E\!\left[\;
        \left.
        \widetilde{T}_{Y} - T_{Y}
        \,\right\vert\,
        \Xobs
        \,\right]
\;\; = \;\;
    E_{YIR}\!\left[\;
        \left.
        \widetilde{T}_{Y}
        \,\right\vert\,
        \Xobs
        \,\right]
    \,-\,
    E_{YIR}\!\left[\;
        \left.
        T_{Y}
        \,\right\vert\,
        \Xobs
        \,\right]
\\
& = &
    E_{YIR}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
        \;\overset{{\color{white}.}}{+}\;
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
        \,\;\right\vert\,
        \Xobs
        \,\right]
    \,-\,
    {\color{blue}
    E_{YIR}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;Y_{i}
        \;\right\vert\,
        \Xobs
        \,\right]
    }
\\
& = &
    E_{YIR}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
        \;\right\vert\,
        \Xobs
        \,\right]
    \;-\;
    {\color{blue}
    \underset{i\,\in\,U}{\sum}\;
    E_{Y}\!\left[\,Y_{i}\left\vert\,\Xobs\right.\right]
    }
\\
&&
    +\;
    E_{YIR}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
        \;\right\vert\,
        \Xobs
        \,\right]
\end{eqnarray*}
This completes the proof of Claim 1.

\vskip 0.3cm
\noindent
\textbf{Claim 2:}\quad
$
E_{YIR}\!\left[\;
    \left.
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\right\vert\,
    \Xobs
    \,\right]
\; = \;
    \underset{i\,\in\,U}{\sum}\;E\!\left[\;Y_{i}\,\left\vert\;\Xobs\right.\,\right]
$
\vskip 0.1cm
\noindent
Proof of Claim 2:\;\;
\begin{eqnarray*}
E_{YIR}\!\left[\;
    \left.
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
    \;\right\vert\,
    \Xobs
    \,\right]
& = &
    E_{YI}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
        \;\right\vert\,
        \Xobs
        \,\right],
    \;\;
    \textnormal{since \,$R_{\bullet}$\, does not appear inside the expectation}
\\
& = &
    E_{I}\!\left[\,E_{Y}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
        \;\right\vert\,
        s, s_{R}, \Xobs
        \right]\,\right]
\;\; = \;\;
    E_{I}\!\left[\,
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,
        E_{Y}\!\left[\,Y_{i}\,\left\vert\,s,s_{R},\Xobs\right.\right]
        \,\right]
\\
& = &
    E_{I}\!\left[\,
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,
        E_{Y}\!\left[\,Y_{i}\,\left\vert\,\Xobs\right.\right]
        \,\right],
    \;\;
    \textnormal{since \,$Y_{i} \perp (I_{\bullet},R_{\bullet}) \,\vert\, \Xobs$\,}
\\
& = &
    \underset{i\,\in\,U}{\sum}\;
    E_{I}\!\left[\,I_{i}\,\right]\,
    w_{i}\,
    E_{Y}\!\left[\,Y_{i}\,\left\vert\,\Xobs\right.\right]
\\
& = &
    \underset{i\,\in\,U}{\sum}\;
    E_{Y}\!\left[\,Y_{i}\,\left\vert\,\Xobs\right.\,\right],
    \;\;
    \textnormal{since \,$w_{i} \,=\, \dfrac{1}{P(I_{i}=1)} \,=\, \dfrac{1}{E_{I}[\,I_{i}\,]}$}
\end{eqnarray*}
This completes the proof of Claim 2.

\vskip 0.3cm
\noindent
\textbf{Claim 3:}\quad
$
E_{YIR}\!\left[\;
    \left.
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
    \;\right\vert\,
    \Xobs
    \,\right]
\; = \;
    E_{IR}\!\left[\;
        \underset{i\,\in\,{\color{black}s_{M}}}{\sum}\,w_{i}\,
        E_{Y}\!\left[\;
            \left.
            Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
            \;\right\vert\,
            s,s_{R},\Xobs
            \,\right]
        \,\right]
$
\vskip 0.1cm
\noindent
Proof of Claim 3:\;\;
\begin{eqnarray*}
E_{YIR}\!\left[\;
    \left.
    \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
    \;\right\vert\,
    \Xobs
    \,\right]
& = &
    E_{IR}\!\left[\;
    E_{Y}\!\left[\;
        \left.
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
        \;\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\\
& = &
    E_{IR}\!\left[\;
        \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,
        E_{Y}\!\left[\;
            \left.
            Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
            \;\right\vert\,
            s,s_{R},\Xobs
            \,\right]
        \,\right]
\\
& = &
    E_{IR}\!\left[\;
        \underset{i\,\in\,{\color{red}s_{M}}}{\sum}\,w_{i}\,
        E_{Y}\!\left[\;
            \left.
            Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
            \;\right\vert\,
            s,s_{R},\Xobs
            \,\right]
        \,\right]
\end{eqnarray*}
This completes the proof of Claim 3.

\vskip 0.5cm
\noindent
The Lemma now follows immediately from Claim 1, Claim 2, and Claim 3.
\qed

% \begin{eqnarray*}
% \bias\!\left(\;
%     \left.
%     \widetilde{T}_{Y}
%     \;\right\vert\,
%     \Xobs
%     \,\right)
% & := &
%     E\!\left[\;
%         \left.
%         \widetilde{T}_{Y} - T_{Y}
%         \,\right\vert\,
%         \Xobs
%         \,\right]
% % \;\; = \;\;
% %     E_{YIR}\!\left[\;
% %         \left.
% %         \widetilde{T}_{Y} - T_{Y}
% %         \,\right\vert\,
% %         \Xobs
% %         \,\right]
% % \\
% % & = &
% \;\; = \;\;
%     E_{YIR}\!\left[\;
%         \left.
%         \widetilde{T}_{Y}
%         \,\right\vert\,
%         \Xobs
%         \,\right]
%     \,-\,
%     E_{YIR}\!\left[\;
%         \left.
%         T_{Y}
%         \,\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
%         \;\overset{{\color{white}.}}{+}\;
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \,\;\right\vert\,
%         \Xobs
%         \,\right]
%     \,-\,
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;Y_{i}
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
%         \;\right\vert\,
%         \Xobs
%         \,\right]
%     \;-\;
%     E_{Y}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;Y_{i}
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% &&
%     +\;
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{IR}\!\left[\,E_{Y}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,Y_{i}
%         \;\right\vert\,
%         s, s_{R}, \Xobs
%         \,\right]\,\right]
%     \;-\;
%     \underset{i\,\in\,U}{\sum}\;E\!\left[\;Y_{i}\,\vert\,\Xobs\,\right]
% \\
% &&
%     +\;
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{IR}\!\left[\,
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,
%         E_{Y}\!\left[\,\left.Y_{i}\,\right\vert s,s_{R},\Xobs\,\right]
%         \,\right]
%     \;-\;
%     \underset{i\,\in\,U}{\sum}\;E\!\left[\;Y_{i}\,\vert\,\Xobs\,\right]
%     % \,+\,
%     % E_{YIR}\!\left[\;
%     %     \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%     %     \,\right]
% \\
% &&
%     +\;
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     \underset{i\,\in\,U}{\sum}\;E_{Y}\!\left[\,\left.Y_{i}\,\right\vert s,s_{R},\Xobs\,\right]
%     \;-\;
%     \underset{i\,\in\,U}{\sum}\;E\!\left[\;Y_{i}\,\vert\,\Xobs\,\right]
%     \;+\;
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     \underset{i\,\in\,U}{\sum}\;E_{Y}\!\left[\,\left.Y_{i}\,\right\vert\Xobs\,\right]
%     \;-\;
%     \underset{i\,\in\,U}{\sum}\;E\!\left[\;Y_{i}\,\vert\,\Xobs\,\right]
%     \;+\;
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{YIR}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         \Xobs
%         \,\right]
% \\
% & = &
%     E_{IR}\!\left[\;
%     E_{Y}\!\left[\;
%         \left.
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,(Y^{*}_{i}-Y_{i})
%         \;\right\vert\,
%         s,s_{R},\Xobs
%         \,\right]
%         \,\right]
% \\
% & = &
%     E_{IR}\!\left[\;
%         \underset{i\,\in\,U}{\sum}\;I_{i}\,w_{i}\,(1-R_{i})\,
%         E_{Y}\!\left[\;
%             \left.
%             Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
%             \;\right\vert\,
%             s,s_{R},\Xobs
%             \,\right]
%         \,\right]
% \\
% & = &
%     E_{IR}\!\left[\;
%         \underset{i\,\in\,{\color{red}s_{M}}}{\sum}\,w_{i}\,
%         E_{Y}\!\left[\;
%             \left.
%             Y^{*}_{i} \overset{{\color{white}.}}{-} Y_{i}
%             \;\right\vert\,
%             s,s_{R},\Xobs
%             \,\right]
%         \,\right]
% \end{eqnarray*}
% \vskip -0.8cm
% \qed

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{lemma}[Decomposition of \,$\MSE(\widetilde{T}_{Y})$; see Equation (5.3) in \cite{Beaumont2011}]
\label{DecompositionMSETtilde}
\mbox{}
\vskip 0.1cm
\noindent
Assume that
\,$Y = (Y_{1},\ldots,Y_{N})$\,
and
\,$(I,\rho) = (I_{1},\ldots,I_{N},\rho_{1},\ldots,\rho_{N})$\,
are conditionally independent given
\,$\Xobs$.\,
Then,
\begin{eqnarray*}
\MSE\!\left(\;
    \left.
    \widetilde{T}_{Y}
    \;\right\vert\,
    \Xobs
    \,\right)
& = &
    E_{Y}\!\left[\,
    \Var_{IR}\!\left(\,
        \left.
        \widehat{T}_{Y}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right)
        \,\right]
    \;+\;
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - \widehat{T}_{Y}\,)^{2}
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\\
&&
    +\;2\,
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} \,-\, \widehat{T}_{Y}\,)(\,\widehat{T}_{Y} \,-\, T_{Y}\,)
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\end{eqnarray*}
\end{lemma}
\proof
\begin{eqnarray*}
\MSE\!\left(\;
    \left.
    \widetilde{T}_{Y}
    \;\right\vert\,
    \Xobs
    \,\right)
& := &
    E\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
\;\; = \;\;
    E_{YIR}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
\\
& = &
    E_{YIR}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} \;{\color{red}-\; \widehat{T}_{Y} \;+\; \widehat{T}_{Y}} \,-\, T_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
\\
& = &
    E_{YIR}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - \widehat{T}_{Y}\,)^{2}
        \,+\,
        2\,(\,\widetilde{T}_{Y} \,-\, \widehat{T}_{Y}\,)(\,\widehat{T}_{Y} \,-\, T_{Y}\,)
        \,+\,
        (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
\\
& = &
    E_{YIR}\!\left[\,
        \left.
        (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
    \;+\;
    E_{YIR}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - \widehat{T}_{Y}\,)^{2}
        \,\right\vert\,
        \Xobs
        \,\right]
\\
&&
    +\;
    2\,E_{YIR}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} \,-\, \widehat{T}_{Y}\,)(\,\widehat{T}_{Y} \,-\, T_{Y}\,)
        \,\right\vert\,
        \Xobs
        \,\right]
\\
& = &
    E_{Y}\!\left[\,
    E_{IR}\!\left[\,
        \left.
        (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right]
        \,\right]
    \;+\;
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - \widehat{T}_{Y}\,)^{2}
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\\
&&
    +\;2\,
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} \,-\, \widehat{T}_{Y}\,)(\,\widehat{T}_{Y} \,-\, T_{Y}\,)
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\\
& = &
    E_{Y}\!\left[\,
    \Var_{IR}\!\left(\,
        \left.
        \widehat{T}_{Y}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right)
        \,\right]
    \;+\;
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} - \widehat{T}_{Y}\,)^{2}
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\\
&&
    +\;2\,
    E_{IR}\!\left[\,
    E_{Y}\!\left[\,
        \left.
        (\,\widetilde{T}_{Y} \,-\, \widehat{T}_{Y}\,)(\,\widehat{T}_{Y} \,-\, T_{Y}\,)
        \,\right\vert\,
        s,s_{R},\Xobs
        \,\right]
        \,\right]
\end{eqnarray*}
\vskip -0.5cm
\qed

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\noindent
The first term above
\,--\,
i.e.,
$
E_{Y}\!\left[\,
E_{IR}\!\left[\,
    \left.
    (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
    \,\right\vert\,
    \Ydot,
    \Xobs
    \,\right]
    \,\right]
$
\,--\,
is called the \textit{sampling variance} in \cite{Beaumont2011}.
First, note that
\begin{eqnarray*}
E_{Y}\!\left[\,
E_{IR}\!\left[\,
    \left.
    (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
    \,\right\vert\,
    \Ydot,
    \Xobs
    \,\right]
    \,\right]
& = &
    E_{Y}\!\left[\,
    \Var_{IR}\!\left(\,
        \left.
        \widehat{T}_{Y}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right)
        \,\right]
\end{eqnarray*}
It is asserted that
\begin{eqnarray*}
E_{Y}\!\left[\,
E_{IR}\!\left[\,
    \left.
    (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
    \,\right\vert\,
    \Ydot,
    \Xobs
    \,\right]
    \,\right]
& \approx &
    E_{Y}\!\left[\,
    E_{IR}\!\left[\,
        \left.
        (\,\widehat{T}_{Y} - T_{Y}\,)^{2}
        \,\right\vert\,
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \,\right]
        \,\right]
\end{eqnarray*}
See \cite{Beaumont2009} as well as Equation (5.5), p.175, \cite{Beaumont2011}.

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 0.5cm
\begin{lemma}[Formula for sampling variance; Equation (5.5) in \cite{Beaumont2011}]
\label{DecompositionMSETtilde}
\mbox{}
\vskip 0.1cm
\noindent
% Assume that
% \,$Y = (Y_{1},\ldots,Y_{N})$\,
% and
% \,$(I,\rho) = (I_{1},\ldots,I_{N},\rho_{1},\ldots,\rho_{N})$\,
% are conditionally independent given
% \,$\Xobs$.\,
% \vskip 0.1cm
% \noindent
% Let
The following statements are true:
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\mbox{}\;\;\,(\theenumi)$\quad$}
\begin{enumerate}
\item
    If
    \;$v(\,s\,;y_{\bullet}\,)$\,
    is an (arbitrary) design-unbiased estimator for the sampling variance, i.e.,
    \begin{equation*}
    E_{I}\!\left[\;
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        \Ydot,\Xobs
        \right.
        \,\right]
    \;\; = \;\;
        \Var_{IR}\!\left(\,
            \left.
            \widehat{T}_{Y}
            \,\right\vert\,
            \Ydot,
            \Xobs
            \,\right),
    \end{equation*}
    then
    \,$
    E_{Y_{M}}\!\left[\,
        v(\,s\,;y_{\bullet}\,)
        \left\vert\,
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \right]
    $\,
    is an unbiased estimator for
    \,$
    E_{Y}\!\left[\,
        \Var_{IR}\!\left(\,
            \left.
            \widehat{T}_{Y}
            \,\right\vert\,
            \Ydot,
            \Xobs
            \,\right)
    \,\right]
    $,\,
    i.e.,
    \begin{equation*}
    E_{IR}\,
    E_{Y_{R}}\,
    E_{Y_{M}}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \,\right]
    \;\; = \;\;
        E_{Y}\!\left[\,
            \Var_{IR}\!\left(\,
                \left.
                \widehat{T}_{Y}
                \,\right\vert\,
                \Ydot,
                \Xobs
                \,\right)
            \,\right]
    \end{equation*}
\item
    If
    \,$v(\,s\,;y_{\bullet}\,)$\,
    is taken to be the (design-unbiased) Horvitz-Thompson estimator for the sampling variance, i.e.,
    \begin{equation*}
    v(\,s\,;y_{\bullet}\,)
    \;\; := \;\;
        \underset{k \in s}{\sum}\,
        \underset{l \in s}{\sum}\,
        \dfrac{\pi_{kl} - \pi_{k}\pi_{l}}{\pi_{kl}}\,
        (w_{k}y_{k})\,(w_{l}y_{l})
    \end{equation*}
    then
    \,$
    E_{Y_{M}}\!\left[\,
        v(\,s\,;y_{\bullet}\,)
        \left\vert\,
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \right]
    $\,
    can be expressed as follows:
    \begin{equation*}
    E_{Y_{M}}\!\left[\,
        v(\,s\,;y_{\bullet}\,)
        \left\vert\,
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \right]
    \;\; = \;\;
        v(\,y^{\mu}_{\bullet}\,)
        \;+\;
        \underset{k\,\in\,s_{M}}{\sum}
        \left(1-\dfrac{1}{w_{k}}\right)
        w_{k}^{2}\,\sigma_{k}^{2}\,,
    \end{equation*}
    where
    \,$y^{\mu}_{\bullet} = ???$\,
\end{enumerate}
% We have:
% \begin{eqnarray*}
% E_{Y}\!\left[\,
%     \Var_{IR}\!\left(\,
%         \left.
%         \widehat{T}_{Y}
%         \,\right\vert\,
%         \Ydot,
%         \Xobs
%         \,\right)
%     \,\right]
% & \approx &
%     E_{Y_{M}}\!\left[\,
%         v(\,s\,;y_{\bullet}\,)
%         \left\vert\,
%         s,s_{R},\mathbf{Y}_{R},\Xobs
%         \right.
%         \right]
% \;\; = \;\;
%     v(\,y^{\mu}_{\bullet}\,)
%     \;+\;
%     \underset{k\,\in\,s_{M}}{\sum}
%     \left(1-\dfrac{1}{w_{k}}\right)
%     w_{k}^{2}\,\sigma_{k}^{2}\,,
% \end{eqnarray*}
% where
\end{lemma}
\proof
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\mbox{}\;\;\,(\theenumi)$\quad$}
\begin{enumerate}
\item
    We simply compute:
    \begin{eqnarray*}
    E_{IR}\,
    E_{Y_{R}}\,
    E_{Y_{M}}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \,\right]
    & = &
        E_{IR}\,
        E_{Y}\!\left[\,
            v(\,s\,;\Ydot\,)
            \,\left\vert\;
            s,s_{R},\Xobs
            \right.
            \,\right]
    \\
    & = &
        E_{Y}\,
        E_{IR}\!\left[\,
            v(\,s\,;\Ydot\,)
            \,\left\vert\;
            \Ydot,\Xobs
            \right.
            \,\right]
    \\
    & = &
        E_{Y}\,
        E_{I}\!\left[\,
            v(\,s\,;\Ydot\,)
            \,\left\vert\;
            \Ydot,\Xobs
            \right.
            \,\right]
    \\
    & = &
        E_{Y}\!\left[\,
            \Var_{IR}\!\left(\,
                \left.
                \widehat{T}_{Y}
                \,\right\vert\,
                \Ydot,
                \Xobs
                \,\right)
            \,\right],
    \;\;
    \textnormal{by hypothesis on \,$v(\,s\,;y_{\bullet}\,)$}
    \end{eqnarray*}
\item
    \begin{eqnarray*}
    E_{Y_{M}}\!\left[\,
        v(\,s\,;y_{\bullet}\,)
        \left\vert\,
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \right]
    & = &
        E_{Y_{M}}\!\left[\,
            \left.
            \underset{k \in s}{\sum}\,
            \underset{l \in s}{\sum}\,
            \dfrac{\pi_{kl} - \pi_{k}\pi_{l}}{\pi_{kl}}\,
            (w_{k}y_{k})\,(w_{l}y_{l})
            \;\right\vert\,
            s,s_{R},\mathbf{Y}_{R},\Xobs
            \right]
    \\
    & = &
        \underset{k \in s}{\sum}\,
        \underset{l \in s}{\sum}\;
        \dfrac{\pi_{kl} - \pi_{k}\pi_{l}}{\pi_{kl}}\;
        w_{k}w_{l}\;
        E_{Y_{M}}\!\left[\;
            y_{k}y_{l}
            \left\vert\,
            s,s_{R},\mathbf{Y}_{R},\Xobs
            \right.
            \right]
    \\
    & = &
        \underset{k \in s}{\sum}\,
        \underset{l \in s}{\sum}\;
        \dfrac{\pi_{kl} - \pi_{k}\pi_{l}}{\pi_{kl}}\;
        w_{k}w_{l}\;
        E_{Y_{M}}\!\left[\;
            y_{k}y_{l}
            \left\vert\,
            \mathbf{Y}_{R},\Xobs
            \right.
            \right]
    \\
    & = &
        \cdots
    \\
    & = &
        v(\,s\,;y^{\mu}_{\bullet}\,)
        \;+\;
        \underset{k\,\in\,s_{M}}{\sum}
        \left(1-\dfrac{1}{w_{k}}\right)
        w_{k}^{2}\,\sigma_{k}^{2}\,,
    \end{eqnarray*}
    \begin{equation*}
    E_{Y_{M}}\!\left[\;
        Y_{k}Y_{l}
        \,\left\vert\,
        \mathbf{Y}_{R},\Xobs
        \right.
        \right]
    \;\; = \;\;
        \left\{\begin{array}{ccl}
            \Var(Y_{k}) + E[\,Y_{k}\,]^{2}, & \textnormal{for \,$k = l \in s_{M}$}
            \\
            E[\,Y_{k}\,]\,E[\,Y_{l}\,], & \textnormal{otherwise}
            \end{array}\right.
    \end{equation*}
\end{enumerate}
The design-unbiasedness of
\,$v(\,s\,;y_{\bullet}\,)$\,
means
\begin{equation*}
E_{I}\!\left[\;\overset{{\color{white}.}}{v(\,s\,;\Ydot\,)}\,\right]
\;\; = \;\;
    E_{I}\!\left[\,
        \left.
        \overset{{\color{white}.}}{v(\,s\,;\Ydot\,)}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right]
\;\; = \;\;
    \Var_{IR}\!\left(\,
        \left.
        \widehat{T}_{Y}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right)
\end{equation*}
At this point, we use the estimator:
\begin{equation*}
\Var_{IR}\!\left(\,
    \left.
    \widehat{T}_{Y}
    \,\right\vert\,
    \Ydot,
    \Xobs
    \,\right)
\;\; \approx \;\;
    \overset{{\color{white}.}}{v(\,s\,;\Ydot\,)}
\end{equation*}


\begin{eqnarray*}
E_{Y}\!\left[\,
    \Var_{IR}\!\left(\,
        \left.
        \widehat{T}_{Y}
        \,\right\vert\,
        \Ydot,
        \Xobs
        \,\right)
    \,\right]
& \approx &
    E_{Y}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,\Xobs
        \right.
        \,\right]
\;\; = \;\;
    E_{Y}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,{\color{blue}s_{R}},\Xobs
        \right.
        \,\right]
\\
& = &
    E_{Y_{R}}\,E_{Y_{M}}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,s_{R},\Xobs
        \right.
        \,\right]
\\
& \approx &
    E_{Y_{M}}\!\left[\,
        v(\,s\,;\Ydot\,)
        \,\left\vert\;
        s,s_{R},\mathbf{Y}_{R},\Xobs
        \right.
        \,\right]
\end{eqnarray*}

\qed

        %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
