
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Gaussian Processes}
\setcounter{theorem}{0}
\setcounter{equation}{0}

\begin{definition}[Gaussian processes]
\mbox{}\vskip 0cm
\noindent
An $\Re$-valued stochastic process
$\left\{\,X_{t}:\Omega\longrightarrow\Re\,\right\}_{t \in T}$
is said to be \textbf{Gaussian} if each of its finite-dimensional distribution is a
(univariate or multivariate) Gaussian distribution.
\end{definition}

\begin{definition}[Mean and covariance functions of $\Re$-valued stochastic processes]
\mbox{}\vskip 0.1cm
\noindent
Let $\left\{\,X_{t}:\Omega\longrightarrow\Re\,\right\}_{t \in T}$ be an
$\Re$-valued stochastic process.
\begin{itemize}
\item If, for each $t \in T$, we have $E\!\left(\,X_{t}\,\right) \in \Re$, then the function
\begin{equation*}
a_{X} \,:\, T \, \longrightarrow \, \Re \, : \, t \, \longmapsto \, E\!\left(\,X_{t}\,\right)
\end{equation*}
is called the \textbf{mean} function of the $\Re$-valued stochastic process $\{\,X_{t}\,\}$.
\item In addition, if, for each $t_{1},t_{2} \in T$, we have $0 \leq \Cov\!\left(X_{t_{1}},X_{t_{2}}\right) < \infty$,
then the function
\begin{equation*}
\Sigma_{X} \,:\, T \times T \, \longrightarrow \, \Re \, : \, (t_{1},t_{2}) \, \longmapsto \, \Cov\!\left(X_{t_{1}},X_{t_{2}}\right)
\end{equation*}
is called the \textbf{covariance} function of the $\Re$-valued stochastic process $\{\,X_{t}\,\}$.
\end{itemize}
\end{definition}

\begin{theorem}
\mbox{}\vskip 0cm
\noindent
Let $T$ be an arbitrary non-empty set, $a : T \longrightarrow \Re$ an arbitrary $\Re$-valued function
defined on $T$, and $\Sigma : T \times T \longrightarrow [0,\infty)$ a non-negative $\Re$-valued function
defined on $T \times T$. Then, there exists a Gaussian process whose mean and covariance functions
are $a$ and $\Sigma$, respectively. 
\end{theorem}

\begin{theorem}
\mbox{}\vskip 0cm
\noindent
The mean and covariance functions of a Gaussian process together completely determine
its collection of finite-dimensional distributions.
\end{theorem}

\begin{definition}[Brownian motion, a.k.a. Wiener process]
\mbox{}\vskip 0.1cm
\noindent
A \textbf{Brownian motion}, or \textbf{Wiener process}, is a stochastic process
$\{\,W_{t} : \left(\Omega,\mathcal{A},\mu\right) \longrightarrow \Re\,\}_{t \geq 0}$ indexed by the non-negative real line
satisfying the following conditions:
\begin{itemize}
\item At $t = 0$, the process takes value $0$ with probability $1$; more precisely:
	\begin{equation*}
	P\!\left(\,W_{0} = 0\,\right)\; = \; \mu\!\left(\left\{\;\omega\in\Omega\;\vert\;W_{0}(\omega)=0\;\right\}\right) \; = \; 1.
	\end{equation*}
\item The process $\{\,W_{t}\,\}$ has independent increments; more precisely:
	for any $0 \leq t_{1} \leq t_{2} \leq \cdots \leq t_{n} < \infty$,
	\begin{equation*}
	W_{t_{n}} - W_{t_{n-1}}, 	\quad W_{t_{n-1}} - W_{t_{n-2}}, \quad \ldots \;\; , \quad W_{t_{2}} - W_{t_{1}}
	\; : \; \Omega \longrightarrow \Re
	\end{equation*}
	are independent random variables.
\item For $0 \leq t_{1} < t_{2} < \infty$, the increment $W_{t_{2}} - W_{t_{1}}$
	follows a Gaussian distribution with mean $0$ and variance $t_{2} - t_{1}$.
\end{itemize}
\end{definition}

\begin{definition}[Brownian bridge]
\mbox{}\vskip 0.1cm
\noindent
A \textbf{Brownian bridge} is a Gaussian process
$\{\,W^{\circ}_{t} : \left(\Omega,\mathcal{A},\mu\right) \longrightarrow \Re\,\}_{t \in [0,1]}$
indexed by the closed unit interval in $\Re$ satisfying the following conditions:
\begin{itemize}
\item For each $t \in [0,1]$, we have $E\!\left(\,W^{\circ}_{t}\,\right) = 0$.
\item For any $t_{1}, t_{2} \in [0,1]$, we have $\Cov\!\left(W^{0}_{t_{1}},W^{\circ}_{t_{2}}\right) = \min\{t_{1},t_{2}\} - t_{1}t_{2}$.
\end{itemize}
\end{definition}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
