
          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\section{Technical lemmas: uniform convergence with probability one}
\setcounter{theorem}{0}
\setcounter{equation}{0}

%\cite{vanDerVaart1996}
%\cite{Kosorok2008}

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\begin{lemma}[A generalization of the Fundamental Theorem of Calculus for $\Re^{p} \longrightarrow \Re^{p}$ functions]
\label{FTCRpRp}
\mbox{}\vskip 0.1cm
\noindent
Suppose:
\begin{itemize}
\item
	$\Theta \subset \Re^{p}$ is an open subset of \,$\Re^{p}$.
\item
	$\theta_{1}, \theta_{2} \in \Theta$ such that $(1-t) \cdot \theta_{1} + t \cdot \theta_{2} \in \Theta$, for each $t \in [0,1]$.
\item
	$f : \Theta \longrightarrow \Re^{p}$ is continuously differentiable.
\end{itemize}
Then,
\begin{equation*}
f(\theta_{2}) \, - \, f(\theta_{1})
\;\; = \;\;
	\left(\;\int_{0}^{1}\, D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) \;\d t\,\right)
	\cdot (\theta_{2} - \theta_{1})\,,
\end{equation*}
where \,$D(f) : \Theta \longrightarrow \Re^{p \times p}$\,
is the Jacobian of $f : \Theta \longrightarrow \Re^{p}$.
Furthermore, if there exists \,$M > 0$\, such that
\,$\underset{\theta\,\in\,\Theta}{\sup}\,\left\Vert\;\overset{{\color{white}.}}{D}(f)(\theta)\;\right\Vert \;\leq\; M$\,,\,
then
\begin{equation*}
\left\Vert\; f(\theta_{2}) \, \overset{{\color{white}.}}{-} \, f(\theta_{1}) \;\right\Vert
\;\; \leq \;\;
	M %\left(\;\int_{0}^{1}\, D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) \;\d t\,\right)
	\cdot
	\left\Vert\; \theta_{2} \,\overset{{\color{white}.}}{-}\, \theta_{1} \;\right\Vert\,.
\end{equation*}
\end{lemma}
\proof
Write $f = (f_{1}, \ldots , f_{p}) : \Theta \longrightarrow \Re^{p}$.
For each $i = 1, 2, \ldots, p$, define $g_{i} : [0,1] \longrightarrow \Re$ by
\begin{equation*}
g_{i}(t) \; := \; f_{i}\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2}\,\right)
\end{equation*}
Then, by the Fundamental Theorem of Calculus, we have, for each $i = 1, 2, \ldots, p$,
\begin{eqnarray*}
f_{i}(\theta_{2}) - f_{i}(\theta_{1})
& = &
	g_{i}(1) - g_{i}(0)
\;\; = \;\;
	\int_{0}^{1}\; g_{i}^{\prime}(t) \;\d t
\\
& = &
	\int_{0}^{1} \left(\;\,
		\overset{p}{\underset{j=1}{\sum}}\;\,
		\dfrac{\partial f_{i}}{\partial_{{\color{white}.}}\theta_{j}}
		\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2}\right)
		\cdot
		\left(\theta_{2} - \theta_{1}\right)_{j}
		\right)\,\d t
\\
& = &
	\overset{p}{\underset{j=1}{\sum}}\;
	\left(\;\,
		\int_{0}^{1}\,
			\dfrac{\partial f_{i}}{\partial_{{\color{white}.}}\theta_{j}}
			\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2}\right)
			\d t \;
		\right)
	\cdot
	\left(\theta_{2} - \theta_{1}\right)_{j}
\\
& = &
	\overset{p}{\underset{j=1}{\sum}}\;
	\left(\;\,
		\int_{0}^{1}\,
			D(f)_{ij}
			\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2}\right)
			\d t \;
		\right)
	\cdot
	\left(\theta_{2} - \theta_{1}\right)_{j}
\\
& = &
	\overset{p}{\underset{j=1}{\sum}}\;
	\left(\;\,
		\int_{0}^{1}\,
			D(f)
			\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2}\right)
			\d t \;
		\right)_{ij}
	\cdot
	\left(\theta_{2} - \theta_{1}\right)_{j}
\end{eqnarray*}
Rewriting the above equations in vectorial form yields:
\begin{equation*}
f(\theta_{2}) \, - \, f(\theta_{1})
\;\; = \;\;
	\left(\;\int_{0}^{1}\, D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) \;\d t\,\right)
	\cdot (\theta_{2} - \theta_{1})\,,
\end{equation*}
which proves the equality in the conclusion of the Lemma.
As for the inequality, note that
\begin{eqnarray*}
\left\Vert\; f(\theta_{2}) \, \overset{{\color{white}.}}{-} \, f(\theta_{1}) \;\right\Vert
& = &
	\left\Vert\;\,
		\left(\;\int_{0}^{1}\, D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) \;\d t\,\right)
		\cdot (\theta_{2} - \theta_{1})
		\,\;\right\Vert
\\
& \leq &
	\left\Vert\;\,
		\int_{0}^{1}\, D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) \,\d t
		\,\;\right\Vert
	\cdot 
	\left\Vert\; \theta_{2} - \theta_{1} \;\right\Vert
\\
& \leq &
	\left(\;
		\int_{0}^{1}\;
			\left\Vert\;
				D(f)\!\left(\,(1-t)\cdot \theta_{1} \overset{{\color{white}.}}{+} t \cdot \theta_{2} \,\right) 
				\,\right\Vert
			\,\d t
		\;\right)
	\cdot 
	\left\Vert\; \theta_{2} - \theta_{1} \;\right\Vert\,,
	\quad
	\textnormal{by Proposition \ref{matrixNormOfIntegralLessThanInteralOfNorm}}
\\
& \leq &
	\left(\; \int_{0}^{1}\, M \;\d t \;\right)
	\cdot
	\left\Vert\; \theta_{2} - \theta_{1} \;\right\Vert\,,
	\quad
	\textnormal{by hypothesis}
\\
& = &
	\overset{{\color{white}-}}{M} \cdot \left\Vert\; \theta_{2} - \theta_{1} \;\right\Vert\,,
\end{eqnarray*}
as required.
This completes the proof of the Lemma.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\begin{lemma}[A generalization of Theorem 7.17, p.152, \cite{Rudin1976}, from $\Re$-valued to $\Re^{p}$-valued functions]
\mbox{}\vskip 0.1cm
\noindent
Suppose:
\begin{itemize}
\item
	$\Theta \subset \Re^{p}$ is a bounded convex open subset of \,$\Re^{p}$.
\item
	For each $n\in\N$, the map $g_{n} : \Theta \longrightarrow \Re^{p}$ is continuously differentiable.
\item
	The sequence of Jacobians
	\,$D(g_{n}) : \Theta \longrightarrow \Re^{p \times p}$\,
	converges uniformly to some function
	\,$J : \Theta \longrightarrow \Re^{p \times p}$.
\item
	For some $\theta_{0} \in \Theta$, the limit
	\,$\underset{n\rightarrow\infty}{\lim}\;g_{n}(\theta_{0})$\,
	exists \,$\in \Re^{p}$.
\end{itemize}
Then, the sequence
\,$g_{n} : \Theta \longrightarrow \Re^{p}$\,
itself converges uniformly to some continuously differentiable function
\,$g : \Theta \longrightarrow \Re^{p}$\,
such that $D(g) = J$.
\end{lemma}
\proof

\vskip 0.5cm
\noindent
\textbf{Claim 1}:\quad $J : \Theta \longrightarrow \Re^{p \times p}$\, is continuous.
\vskip 0.1cm
\noindent
Proof of Claim 1:\quad
Immediate by the Uniform Limit Theorem (the uniform limit of a sequence of continuous functions is itself continuous);
see, for example, Theorem 21.6, p. 132, \cite{Munkres2000}.

\vskip 0.5cm
\noindent
\textbf{Claim 2:}\quad $g_{n}$ converges uniformly on $\Theta$.
\vskip 0.1cm
\noindent
Proof of Claim 2:\quad
We need to show that, for each \,$\varepsilon > 0$,\, there exists \,$N(\varepsilon) \in \N$\, such that
\begin{equation*}
\left\Vert\;g_{m}(\theta) \overset{{\color{white}.}}{-} g_{n}(\theta)\;\right\Vert \;\; < \;\; \varepsilon\,,
\quad
\textnormal{for each \,$\theta \,\in\, \Theta$\, and each \,$m\,,\,n \,>\, N(\varepsilon)$}\,.
\end{equation*}
First, note that, since $\Theta$ is a bounded subset of \,$\Re^{p}$, there exists $B > 0$ such that
$\Vert\,\theta_{1} - \theta_{2}\,\Vert < B$, for each $\theta_{1}, \theta_{2}\in\Theta$.
Next, since $g_{n}(\theta_{0})$ converges and $D(g_{n})$ converges uniformly on $\Theta$,
we see that for each $\varepsilon > 0$, there exists $N(\varepsilon) \in \N$ such that
\begin{equation*}
\left\Vert\;g_{m}(\theta_{0}) \overset{{\color{white}.}}{-} g_{n}(\theta_{0})\;\right\Vert \;\; < \;\; \dfrac{\varepsilon}{2}\,,
\quad
\textnormal{for each \,$m\,,\,n \,>\, N(\varepsilon)$}\,,
\end{equation*}
and
\begin{equation*}
\left\Vert\; D(g_{m} \overset{{\color{white}.}}{-} g_{n})(\zeta) \;\right\Vert
\; = \;
	\left\Vert\;D(g_{m})(\zeta) \overset{{\color{white}.}}{-} D(g_{n})(\zeta)\;\right\Vert
\; < \;
	\dfrac{\varepsilon}{2 B}\,,
\quad
\textnormal{for each \,$\zeta \,\in\, \Theta$\, and each \,$m\,,\,n \,>\, N(\varepsilon)$}\,.
\end{equation*}
By the convexity of \,$\Theta$\,,\, we may apply Lemma \ref{FTCRpRp} to \,$g_{m} - g_{n}$\,,\,
which implies
\begin{eqnarray*}
\left\Vert\; g_{m}(\theta) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta) \;\right\Vert
& \leq &
	\left\Vert\; g_{m}(\theta) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta) \, - \, g_{m}(\theta_{0}) \,+\, g_{n}(\theta_{0}) \;\right\Vert
	\; + \;
	\left\Vert\; g_{m}(\theta_{0}) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta_{0}) \;\right\Vert
\\
& < &
	\left\Vert\; (g_{m} - g_{n})(\theta) \,\overset{{\color{white}.}}{-}\, (g_{m} - g_{n})(\theta_{0}) \;\right\Vert
	\; + \;
	\dfrac{\varepsilon}{2}
	%\left\Vert\; g_{m}(\theta_{0}) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta_{0}) \;\right\Vert
\\
& = &
	\left\Vert\;
		\left(\,\int_{0}^{1}\,
			D(g_{m} - g_{n})\!\left(\,(1-t)\cdot\theta \overset{{\color{white}.}}{+} t\cdot\theta_{0}\,\right)
			\,\d t\,\right)
		\cdot
		(\theta - \theta_{0})
		\;\right\Vert
	\; + \;
	\dfrac{\varepsilon}{2}
	%\left\Vert\; g_{m}(\theta_{0}) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta_{0}) \;\right\Vert
\\
& \leq &
	\left(\,\int_{0}^{1}\,
		\left\Vert\,
			D(g_{m} - g_{n})\!\left(\,(1-t)\cdot\theta \overset{{\color{white}.}}{+} t\cdot\theta_{0}\,\right)
			\,\right\Vert
		\,\d t\,\right)
	\cdot
	\Vert\;\theta - \theta_{0}\,\Vert
	\; + \;
	\dfrac{\varepsilon}{2}
	%\left\Vert\; g_{m}(\theta_{0}) \,\overset{{\color{white}.}}{-}\, g_{n}(\theta_{0}) \;\right\Vert
\\
& < &
	\dfrac{\varepsilon}{2 B} \cdot \left\Vert\; \theta - \theta_{0} \;\right\Vert
	\; + \;
	\dfrac{\varepsilon}{2}
\\
& \leq &
	\overset{{\color{white}1}}{\varepsilon}\,,
	\quad
	\textnormal{for each \,$\theta \,\in\, \Theta$\, and each \,$m\,,\,n \,>\, N(\varepsilon)$}\,.
\end{eqnarray*}
This proves Claim 2, and establishes the uniform convergence of $g_{n}$ on $\Theta$.

\vskip 0.5cm
\noindent
By Claim 2, we may define $g : \Theta \longrightarrow \Re^{p}$ by
\begin{equation*}
g(\theta)
\;\, := \;\,
	\underset{n\rightarrow\infty}{\lim}\; g_{n}(\theta)\,,
\quad
\textnormal{for each \,$\theta \in \Theta$}\,.
\end{equation*}

\vskip 0.5cm
\noindent
\textbf{Claim 3:}\quad $g : \Theta \longrightarrow \Re^{p}$\, is differentiable, and \,$D(g) = J$.
\vskip 0.1cm
\noindent
Proof of Claim 3:\quad
By the definition of the derivative of an $\Re^{a} \longrightarrow \Re^{b}$ function,
Claim 3 is equivalent to the following statement:
\begin{equation*}
\underset{\zeta\,\rightarrow\,\theta}{\lim}\;\,
\dfrac{
	{\color{white}.}
	\left\Vert\;
		g(\zeta) \, \overset{{\color{white}.}}{-} \, g(\theta) \, - \, J(\theta)\cdot(\zeta - \theta)
		\;\right\Vert
	{\color{white}.}
	}{
	\left\Vert\;
		\zeta \, \overset{{\color{white}.}}{-} \, \theta
		\;\right\Vert
	}
\;\; = \;\;
	0\,,
\quad
\textnormal{for each \,$\theta \in \Theta$}\,,
\end{equation*}
which in turn is equivalent to:
for each $\theta \in \Theta$ and each $\varepsilon > 0$,
there exists $\delta > 0$ such that
\begin{equation*}
\dfrac{
	{\color{white}.}
	\left\Vert\;
		g(\zeta) \, \overset{{\color{white}.}}{-} \, g(\theta) \, - \, J(\theta)\cdot(\zeta - \theta)
		\;\right\Vert
	{\color{white}.}
	}{
	\left\Vert\;
		\zeta \, \overset{{\color{white}.}}{-} \, \theta
		\;\right\Vert
	}
\;\; < \;\;
	\varepsilon\,,
\quad
\textnormal{for each \,$\zeta \in B_{\delta}(\theta)\,\backslash\,\{\,0\,\}$}\,.
\end{equation*}
Now, let $\theta \in \Theta$ and $\varepsilon > 0$ be given and fixed.
Recall that by Claim 1, $J : \Theta \longrightarrow \Re^{p \times p}$ is continuous.
Consequently, there exists $\delta > 0$ such that
\begin{equation*}
\left\Vert\; J(\xi) \overset{{\color{white}.}}{-} J(\theta) \;\right\Vert
\;\; < \;\;
	\varepsilon\,,
\quad
\textnormal{for each \,$\xi \in B_{\delta}(\theta)$}
\end{equation*}
Next, observe that
\begin{eqnarray*}
g(\zeta) \, - \, g(\theta)
& = &
	\left(\,\underset{n\rightarrow\infty}{\lim}\; g_{n}(\zeta)\,\right)
	\; - \;
	\left(\,\underset{n\rightarrow\infty}{\lim}\; g_{n}(\theta)\,\right)
\;\; = \;\;
	\underset{n\rightarrow\infty}{\lim}\,
	\left\{\; g_{n}(\zeta) \, \overset{{\color{white}.}}{-} \, g_{n}(\theta) \;\right\}
\\
& = &
	\underset{n\rightarrow\infty}{\lim}\,
	\left\{\;
		\left[\;
			\int_{0}^{1}\, D(g_{n})\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right) \d t
			\;\right]
		\cdot
		(\,\zeta - \theta\,)
		\;\right\}\,,
	\quad
	\textnormal{by Lemma \ref{FTCRpRp}}
\\
& = &
	\underset{n\rightarrow\infty}{\lim}\,
	\left\{\;
		\int_{0}^{1}\, D(g_{n})\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right) \cdot (\,\zeta - \theta\,) \; \d t
		\;\right\}
\\
& = &
	\int_{0}^{1}\, 
		\left[\;
			\underset{n\rightarrow\infty}{\lim}\, D(g_{n})\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right)
			\;\right]
		\cdot (\,\zeta - \theta\,)
		\; \d t\,,
	\quad
	\textnormal{by uniform convergence of $D(g_{n})$}
\\
& = &
	\int_{0}^{1}\, 
		J\!\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right)
		\cdot (\,\zeta - \theta\,)
		\; \d t
\\
& = &
	\left[\;
		\int_{0}^{1}\, 
			J\!\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right)
			\; \d t
		\;\right]
		\cdot (\,\zeta - \theta\,)
\end{eqnarray*}
Now note that, for each $\zeta \in B_{\delta}(\theta)$, we also have
$(1-t)\cdot\zeta + t \cdot \theta \in B_{\delta}(\theta)$.
Hence, for each \,$\zeta \in B_{\delta}(\theta)\,\backslash\,\{\,0\,\}$,
the above observations together imply:
\begin{eqnarray*}
\dfrac{
	{\color{white}.}
	\left\Vert\;
		g(\zeta) \, \overset{{\color{white}.}}{-} \, g(\theta) \, - \, J(\theta)\cdot(\zeta - \theta)
		\;\right\Vert
	{\color{white}.}
	}{
	\left\Vert\;
		\zeta \, \overset{{\color{white}.}}{-} \, \theta
		\;\right\Vert
	}
& = &
	\dfrac{1}{
		{\color{white}.}
		\Vert\;
			\zeta \, \overset{{\color{white}.}}{-} \, \theta
			\;\Vert
		{\color{white}.}
		}
	\cdot
	\left\Vert\;
		\left[\;
			\int_{0}^{1}\, 
				J\!\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right) - J(\theta)
				\; \d t
		\;\right]
		\cdot (\,\zeta - \theta\,)
		\;\right\Vert
\\
& \leq &
	\left\Vert\;
		\int_{0}^{1}\, 
			J\!\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right) - J(\theta)
			\; \d t
		\;\right\Vert
\\
& \leq &
	\int_{0}^{1}\;
		\left\Vert\;
			J\!\left(\,(1-t)\cdot\zeta \overset{{\color{white}.}}{+} t \cdot \theta \,\right) - J(\theta)
			\;\right\Vert
		\; \d t
\\
& < &
	\overset{{\color{white}1}}{\varepsilon}\,,
\end{eqnarray*}
as required. This proves Claim 3

\vskip 0.5cm
\noindent
Since \,$J : \Theta \longrightarrow \Re^{p \times p}$\, is continuous and \,$D(g) = J$,\,
we see that \,$g$\, is indeed continuously differentiable.
This completes the proof of the present Lemma.
\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

\vskip 1.0cm
\begin{lemma}
\mbox{}\vskip 0.1cm
\noindent
Setting:
\begin{itemize}
\item
	$(\Omega,\mathcal{A},\mu)$ is a probability space.
\item
	$\Theta \subset \Re^{p}$ is an open subet of $\Re^{p}$.
\item
	For each $n \in \N$,
	\begin{equation*}
	G_{n} \, : \, \Omega \times \Theta \, \longrightarrow \, \Re^{p}
	\end{equation*}
	is an $\Re^{p}$-valued function such that, for each $\theta \in \Theta$,
	the induced function $G_{n}(\,\cdot\,,\theta) : \Omega \longrightarrow \Re^{p}$
	is $(\mathcal{A},\mathcal{O}(\Re^{p}))$-measurable, where
	$\mathcal{O}(\Re^{p})$ is the completion of
	the Borel $\sigma$-algebra on $\Re^{p}$.
\end{itemize}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
Suppose:
\begin{enumerate}
\item
	$\theta_{0} \in \Theta$.
\item
	\,$G_{n}(\,\cdot\,,\theta_{0}) \longrightarrow 0\in\Re^{p}$\, with probability one; more precisely,
	\begin{equation*}
	P\!\left(\;
		G_{n}(\,\cdot\,,\theta_{0}) \overset{{\color{white}-}}{\longrightarrow} 0
		\;\right)
	\;\; = \;\;
		\mu\!\left(\;\left\{\;
			\left.
			\omega \overset{{\color{white}.}}{\in} \Omega
			\;\;\right\vert\;
			\underset{n\rightarrow\infty}{\lim}\,G_{n}(\omega,\theta_{0}) = 0
			\;\right\}\;\right)
	\;\; = \;\;
		1
	\end{equation*}
\item
	There exist a bounded convex open subset \;$\Theta_{0} \subset \Theta$\, of \;$\Theta$ containing $\theta_{0}$,
	and a measurable map
	\,$J : \Theta_{0} \longrightarrow \Re^{p \times p}$\,
	such that %$J(\theta_{0}) \in \Re^{p \times p}$ is a nonsingular matrix, and
	\begin{equation*}
	\mu\!\left(\;\left\{\;\;
		\omega \in \Omega
		\;\;\left\vert\;
		\begin{array}{c}
			D_{\theta}\,G_{n}(\omega,\theta) \;\,\textnormal{exists and is continuous at each
			$\overset{{\color{white}.}}{\underset{{\color{white}.}}{\theta \in \Theta_{0}}}$}\,,\;
			\textnormal{for each \,$n\in\N$}\,,
			%\\
			%\underset{n\,\rightarrow\,\infty}{\lim}\;\;
			%\underset{\theta\,\in\,\Theta_{0}}{\sup}\,
			%\left\Vert\;{\color{white}D_{\theta}}\,G_{n}(\omega,\theta) \, \overset{{\color{white}.}}{-} \, H(\theta) \;\right\Vert
			%\; = \; 0\,,\quad\textnormal{and}
			\\
			\textnormal{and}\quad\;\;
			\underset{n\,\rightarrow\,\infty}{\lim}\;\;
			\underset{\theta\,\in\,\Theta_{0}}{\sup}\,
			\left\Vert\;D_{\theta}\,G_{n}(\omega,\theta) \, \overset{{\color{white}.}}{-} \, J(\theta) \;\right\Vert
			\; = \; 0{\color{white}\,,\quad\textnormal{and}}
		\end{array}
		\right.
		\right\}\;\right)
	\;\; = \;\; 1\,,
	\end{equation*}	
	where, for each $n \in \N$, the map
	\begin{equation*}
	D_{\theta}\,G_{n} \, : \, \Omega \times \Theta_{0} \, \longrightarrow \, \Re^{p \times p}
	\end{equation*}
	is defined as follows: For each $\omega \in \Omega$,
	\,$D_{\theta}\,G_{n}(\omega,\theta)$\, is the Jacobian of
	\;$G_{n}(\omega,\theta)$ with respect to \,$\theta \in \Theta_{0}$.
\end{enumerate}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
Then, there exists a continuously differentiable map
\,$G : \Theta_{0} \longrightarrow \Re^{p}$\,
such that \,$G(\theta_{0}) = 0 \in \Re^{p}$\,,\; and
	\begin{equation*}
	\mu\!\left(\;\left\{\;\;
		\omega \in \Omega
		\;\;\left\vert\;
		\begin{array}{c}
			\underset{n\,\rightarrow\,\infty}{\lim}\;\;
			\underset{\theta\,\in\,\Theta_{0}}{\sup}\,
			\left\Vert\;G_{n}(\omega,\theta) \, \overset{{\color{white}.}}{-} \, G(\theta) \;\right\Vert
			\; = \; 0\,,\;\;
			\textnormal{and}
			\\
			\underset{n\,\rightarrow\,\infty}{\lim}\;\;
			\underset{\theta\,\in\,\Theta_{0}}{\sup}\,
			\left\Vert\;D_{\theta}\,G_{n}(\omega,\theta) \, \overset{{\color{white}.}}{-} \, D_{\theta}G(\theta) \;\right\Vert
			\; = \; 0
		\end{array}
		\right.
		\right\}\;\right)
	\;\; = \;\; 1\,,
	\end{equation*}	
	where \,$D_{\theta}\,G : \Theta_{0} \longrightarrow \Re^{p \times p}$\,
	is the Jacobian of \,$G : \Theta_{0} \longrightarrow \Re^{p}$.
\end{lemma}
\proof

\qed

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%

%\renewcommand{\theenumi}{\alph{enumi}}
%\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\textnormal{(\theenumi)}$\;\;$}

          %%%%% ~~~~~~~~~~~~~~~~~~~~ %%%%%
